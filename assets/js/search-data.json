{
  
    
        "post0": {
            "title": "Design Machine Learning System",
            "content": "Chapter 1: Overview of Machine Learning Systems . ML is not a magic tool that can solve all problems. . | When developing an ML project, it’s critical to understand the requirements from all the stakeholders and how strict these requirements are. . | Typically, the percentiles for latency that we should look at are p90, p95, and p99. . | Fairness is a big concern when training models. . | While it’s important to pursue research, most companies cannot afford it unless it leads to short-term business applications. . | The trend shows that applications developed with the most/best data win. . | Chapter 2: Introduction to Machine learning Systems Design . Most businesses don’t care about ML metrics unless they can move business metrics. Thus, if an ML system is built for a business, it must be motivated by business objectives. | Chapter 7: Model Deployment and Prediction Service . Batch Prediction vs Online Prediction . There are three main modes of prediction: . Batch prediction - using only batch features . | Online prediction - using only batch features . | Online prediction - using both batch features and streaming features . | . Batch features: features computed from historical data, such as data in databases and data warehouses. . Streaming features: Features computed from streaming data. . Model Compression . The process makes the model smaller. This makes the models fit on edge devices. Making models smaller often makes them run faster. . ML on the Cloud and on the Edge . Running on the cloud costs a lot of money, while on edge requires a lot of optimization on the models’ sizes. . Chapter 8: Data Distribution Shifts and Monitoring . Causes of ML System Failures . Software failures . Dependency failure . | Deployment failure . | Hardware failures . | Downtime or crashing . | . ML-specific failures . Production data differing from training data . Training data and unseen data should come from a similar distribution. This assumption is incorrect in most cases. | . | Edge cases . | Degenerate feedback loops . Having visibility into how the model makes predictions - such as measuring the importance of each feature for the model can help detect the bias toward feature X in this case. | . | . Data Distribution Shifts . Data distribution shift refers to the phenomenon in supervised learning when the data a model works with changes over time, which causes the model’s predictions to become less accurate as time passes. . Covariate shift . | Label shift . | Concept shift . | . Detecting Data Distribution Shifts . Monitor the model’s accuracy-related-metrics such as accuracy, F1 score, recall, AUC-ROC, etc. . Using mean, min, max, std, etc. Check if they are different by a threshold. This method is used by TFDV. . | Using Hypothesis Testing. Let consider the data from yesterday to be the source population and the data from today to be the target population and they are statistically different, it’s likely that the underlying data distribution has shifted between yesterday and today. . | . | . Monitoring and Observability . ML-specific Metrics . There are four artifacts to monitor: . a model’s accuracy-related-metrics . This helps to decide whether a model’s performance has degraded. | . | predictions . Prediction distribution shifts are also a proxy for input distribution shifts. | . | features . Feature validation: Great Expectation | . | raw inputs . It is not easy to monitor as it can com from multiple sources in different formats, following multiple structures. . | This tasks are usually done by the data team, not ML team. . | . | . Monitoring Toolbox . Logs . | Dashboards . | Alerts . | . Observability . It helps to understand how the entire ML system, which includes ML model, works. .",
            "url": "https://minhdang241.github.io/minhdg-blog/machine_learning/2023/03/12/DesignMachineLearningSystem.html",
            "relUrl": "/machine_learning/2023/03/12/DesignMachineLearningSystem.html",
            "date": " • Mar 12, 2023"
        }
        
    
  
    
        ,"post1": {
            "title": "Dependencies",
            "content": "Semantic and syntactic Dependencies . Use cases of Dependencies . Previously, used for feature engineering in systems | Now: more useful for human-facing applications | .",
            "url": "https://minhdang241.github.io/minhdg-blog/2023/03/11/Untitled.html",
            "relUrl": "/2023/03/11/Untitled.html",
            "date": " • Mar 11, 2023"
        }
        
    
  
    
        ,"post2": {
            "title": "Chapter 6 - Partitioning",
            "content": "Chapter 6: Partitioning . partition == shard in MongoDB, Elasticsearch, and SolrCloud == region in HBase == tablet in Bigtable == a vnode in Cassandra and Riak == vBucket in CouchBase. . Purpose . Partitioning helps to improve scalability. A large dataset can be stored across many disks and the query load can be executed by multiple processors. . Partitioning of Key-Value Data . A Hot spot: A partition with a disproportionately high load. . Partitioning by Key Range . Assign a range of sorted keys to a partition. . Note: . Sorting helps to improve the performance of range queries. Yet, the key should be chosen with caution to avoid hot spots in case the application often accesses the data with close keys in the sorted order. . Partitioning by Hash of Key . Assign a range of hash values (hashing keys) to a partition. . Note: . This approach makes sure that keys are distributed evenly across partitions since it destroys the key order - after hashing, two similar keys will no longer close in the sorted order. . Skewed Workloads and Relieving Hot Spots . In either case, there is still a chance to suffer the celebrity issue since it does not depend on the key ranges but the key itself. To solve this problem, we can add a random element to the key. For example, adding a 2-digit decimal to the key will make the data for that key split into 100 keys. Yet, this solution comes with a performance degradation when read since we have to request data from 100 keys instead of 1. Also, not all the key needs to be split, optimally, we should detect which key has high throughput and split it. . Partitioning and Secondary Indexes . The secondary index is used to search for occurrences of a particular value. . The problem with secondary indexes is that they don’t neatly map to partitions. . Partitioning Secondary Indexes by Document . . In this approach, we create local indexes for each partition. In order words, each partition maintains its secondary indexes, covering only the documents available in that partition. . For example, after we create the secondary index on color. When a red car with ID 306 is added to the database, the database partition of partition 0 automatically adds the ID of 306 to the list of document IDs for the index entry color:red. . This approach adds up complexity on read. Whenever we need to query a list of cars using color, we need to send a request to all the partitions, retrieve all the data and then combine it to generate the result. . Partitioning Secondary Indexes by Term . . In this approach, we apply the same mechanism as partitioning by key range or partitioning by hash of key. We create a global index covering all the data across the partitions. The global index will be partitioned by the range and stored across partitions. Now, instead of each partition maintaining a list of document IDs for the index entry color:red, only partition 0 maintains it. This helps to improve the performance when we need to scan a range of values using the color attribute. Yet, this approach adds up the complexity when writing, when we have multiple secondary indexes and each index partition, is placed on different partitions. . Rebalancing Partitions . No matter what rebalancing schemes are used, they should meet the following requirements: . After rebalancing, the load queries should be distributed evenly across nodes. . | While rebalancing is happening, the database should still accept reads and writes. . | No more data than necessary should be moved between nodes to reduce network and disk I/O loads. . | . Rebalancing Strategies . Strategies to assign partitions to nodes. . Hash Mod N . Hash the partition key and mod the value by N to decide the target node. . Caveat: . When adding new a node or reducing a failed node, most of the key will need to move to another node, which is expensive. . Fixed number of partitions . Define a fixed number of partitions at the beginning and distributed the partitions evenly to nodes. Whenever, the number of nodes changes, the number of partitions on each node will be changed, either increasing when removing a node or decreasing when adding a node. . Caveat: . It is hard to choose the “just right” number of partitions at the beginning. . Dynamic number of partitions . We config the min and max sizes of the partitions and use these numbers as the boundaries. Whenever the size of a partition is out of this boundary, we either split the partitions or merge them. In case of splitting, when a large dataset is split into 2 halves, one half will be sent to another node in the cluster. The advantage of this approach is that the number of partitions adapts to the total data volume. . Caveat: . The database is started with a single partition. Yet, it can be overcome by pre-splitting. . Partitioning proportionally to nodes . The number of partitions stays unchanged when the number of nodes remains. Yet, it increases or decreases when we add a new node or remove a failed node respectively. . Request Routing . . In general, there are three approaches to routing a request to the correct node. No matter what approach we choose, the key challenge is how can we update the knowledge of partitions when the partitions move from one node to another node. Many distributed database systems rely on third-party coordination services like ZooKeeper to keep track of cluster metadata. . . All the nodes and their partition mappings are registered in ZooKeeper. When there is a change in the mapping, ZooKeeper will notify the routing tier so that it can keep the routing information up to date. . Glossary: . Shared-nothing architecture == horizontal scaling == scaling out . In this architecture, each machine of the virtual machine running the database software is called a node. Each node uses its CPUs, RAM, and disks independently. Any coordination between nodes is done at the software level, using a conventional network. .",
            "url": "https://minhdang241.github.io/minhdg-blog/markdown/ddia/2023/01/29/DDIA-C6-Partitioning.html",
            "relUrl": "/markdown/ddia/2023/01/29/DDIA-C6-Partitioning.html",
            "date": " • Jan 29, 2023"
        }
        
    
  
    
        ,"post3": {
            "title": "Job recommendation system for CS/IT program.",
            "content": "Overview: . Taxonomy of recommender systems: A framework to classify and analyze a particular recommendation system.The system is described by the following dimensions: . 1. domain 2. purpose 3. context 4. personalize level 5. whose opinions 6. privacy and trustworthiness 7. interfaces 8. algorithms . Domain: Type of content recommended. The domain of Netflix is movies and TV series. . Purpose: What is the purpose of the system, both for the end user and for the provider? . Context: The environment which the consumer recieves a recommendation. . Personalization Levels: . None personalized | Semi/Segment personalized | Personalized recommendation is based on data about the current user than indicates how the user has interacted with the system previously. | Algorithms: Content-based filtering uses the metadata having on the items in the catalog. Depending on the specific algorithm, the system can calculate recommendations either by taking the items the user has liked and finding similar content, by comparing the items and user profiles, or if there&#39;s no user involved, by finding similar content between items. . Setup . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Mounted at /content/drive . import pandas as pd pd.set_option(&#39;display.max_columns&#39;, None) # or 1000 pd.set_option(&#39;display.max_rows&#39;, None) # or 1000 pd.set_option(&#39;display.max_colwidth&#39;, None) # or 199 . %%capture !pip install transformers !pip install beautifulsoup4 !python -m spacy download en_core_web_md !pip install -U sentence-transformers !pip install Unidecode !pip install symspellpy !pip install contractions . Load dataset . course_df = pd.read_csv(&quot;/content/drive/MyDrive/Colab Notebooks/Text Classification/datasets/job_recommendation/dataset.csv&quot;) job_df = pd.read_csv(&quot;/content/drive/MyDrive/Colab Notebooks/Text Classification/datasets/job_recommendation/job_dataset.csv&quot;) . Preprocess data . # df = job_df df = course_df . # df = course_df # df.drop([67], inplace=True) . # df[&#39;long_description&#39;] =df[&#39;description&#39;] # df[&#39;description&#39;] = df[&#39;short_description&#39;] # df = df.dropna(axis=0, subset=[&#39;description&#39;, &#39;long_description&#39;]) . Step 1: Remove HTML tags . from bs4 import BeautifulSoup . def remove_html_tags(text): soup = BeautifulSoup(text, &#39;html.parser&#39;) stripped_text = soup.get_text() return stripped_text . df[&#39;no_html&#39;] = df[&#39;description&#39;].apply(remove_html_tags) . /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy &#34;&#34;&#34;Entry point for launching an IPython kernel. . Step 2: Add space . 2.1 Normalize space rules . import re def add_spaces(text): # Space after punc. Only apply to !.,;:? # Eg: Dislike.However =&gt; Dislike. However text = re.compile(r&quot;([!.,;:?])([A-Z])&quot;).sub(r&quot; 1 2&quot;, text) # Space before open bracket # Eg: Dislike(sth) =&gt; Dislike (sth) text = re.sub(r&quot;([A-za-z])([ ( { [])&quot;, r&#39; 1 2&#39;, text) # Space after close bracket # Eg: (such as)I like =&gt; (such as) I like text = re.sub(r&quot;([ ) } ]])([A-Za-z])&quot;, r&#39; 1 2&#39;, text) # Space between word and - or + # Eg: I like it because-fast -pretty =&gt; I like it because - fast - pretty # Eg: I like mac-book =&gt; keep the same text = re.sub(r&quot;([A-Za-z])([-+])( s)&quot;, r&#39; 1 2 &#39;, text) return text . df[&#39;add_space&#39;] = df[&#39;no_html&#39;].apply(add_spaces) . /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy &#34;&#34;&#34;Entry point for launching an IPython kernel. . temp_df = df[df.no_html != df.add_space][[&quot;no_html&quot;, &quot;add_space&quot;]] print(&quot;Impacted row&quot;, len(temp_df)) temp_df.sample() . Impacted row 2 . no_html add_space . 53 Experience in Agile. development methodologies. Integration of user-facing elements developed by a back-end developer with server- side logic | Experience in Agile. development methodologies. Integration of user-facing elements developed by a back-end developer with server - side logic | . 2.2 Add space and remove listing number . import string def handle_listing_number(text): &quot;&quot;&quot; Only remove if it is listing numbers such as 1. 2. 3. &quot;&quot;&quot; listing = [] def remove_listing_number(match_obj): listing_number = match_obj.group(0).strip() result = &quot;&quot; if match_obj.start() == 0 and listing_number[0] == &quot;1&quot;: return &quot;&quot; for c in listing_number: if c.isdigit(): # save to listing if it is digit listing.append(int(c)) break result += c if not any(c in string.punctuation for c in result): result += &quot;.&quot; return result + &quot; &quot; new_text = re.sub(r&quot; b([ . ; : ! ? D]*)([1-9]) . s&quot;, remove_listing_number, text.strip()) if len(listing) &gt; 1: listing_copy = listing[:] listing_copy.sort() # if listing is sorted if listing_copy == listing: return new_text return text . df[&quot;add_space2&quot;] = df[&#39;add_space&#39;].apply(handle_listing_number) . /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy &#34;&#34;&#34;Entry point for launching an IPython kernel. . temp_df = df[df.add_space2 != df.add_space][[&quot;add_space&quot;, &quot;add_space2&quot;]] print(&quot;Impacted row&quot;, len(temp_df)) temp_df . Impacted row 0 . add_space add_space2 . Step 3: Expand contractions . from symspellpy import SymSpell, Verbosity, helpers import contractions def expand_contractions(text): &quot;&quot;&quot; expand shortened words, e.g. don&#39;t to do not contractions library does not keep character case =&gt; need to transfer casing from origin text to fixed text &quot;&quot;&quot; expanded_text = helpers.transfer_casing_for_similar_text(text, contractions.fix(text)) # uppercase I return re.sub(r&quot; bi b&quot;, &quot;I&quot;, expanded_text) . df[&quot;expand_contractions&quot;] = df[&quot;add_space2&quot;].apply(expand_contractions) . /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy &#34;&#34;&#34;Entry point for launching an IPython kernel. . Step 4: Remove redundant elements . def remove_redundant_elements(text): # remove urls text = re.sub(r&quot;http S+&quot;, &quot; &quot;, text) # remove phone text = re.sub(r&quot;[ +]?[(]?[0-9]{3}[)]?[- s .]?[0-9]{3}[- s .]?[0-9]{4,6}&quot;, &quot; &quot;, text) # remove email text = re.sub(r&quot;[ w.+-]+@[ w-]+ .[ w.-]+&quot;, &quot; &quot;, text) # remove newline table = str.maketrans(&quot; n t r&quot;, &quot; &quot;) text = text.translate(table) # remove redundant whitespaces text = &quot; &quot;.join(text.split()) return text . df[&quot;no_redundant&quot;] = df[&quot;expand_contractions&quot;].apply(remove_redundant_elements) . /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy &#34;&#34;&#34;Entry point for launching an IPython kernel. . Step 5: Remove emojies . %%capture !pip install emoji . import emoji def remove_emoji(text): return emoji.get_emoji_regexp().sub(r&quot; &quot;, text) . df[&quot;no_emoji&quot;] = df[&quot;no_redundant&quot;].apply(remove_emoji) . /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy &#34;&#34;&#34;Entry point for launching an IPython kernel. . Step 6: Removing accented characters . import unidecode def remove_accented_chars(text): text = unidecode.unidecode(text) return text . df[&quot;no_accented&quot;] = df[&quot;no_emoji&quot;].apply(remove_accented_chars) . /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy &#34;&#34;&#34;Entry point for launching an IPython kernel. . Step 7: Collapse duplicated punctuation . from itertools import groupby def collapse_duplicated_punctuations(text): &quot;&quot;&quot; collapse duplicated punctations because we added space to separate punc and word in step 3, no need to append &quot; &quot; after punc &quot;&quot;&quot; newtext = [] for k, g in groupby(text): if k in string.punctuation: newtext.append(k) else: newtext.extend(g) return &#39;&#39;.join(newtext) . df[&quot;no_duplicated_punc&quot;] = df[&quot;no_accented&quot;].apply(collapse_duplicated_punctuations) . /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy &#34;&#34;&#34;Entry point for launching an IPython kernel. . Step 8: Remove consecutive spaces . df[&quot;no_consecutive_spaces&quot;] = df.no_duplicated_punc.replace({&quot; s+&quot;:&quot; &quot;},regex=True) . /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy &#34;&#34;&#34;Entry point for launching an IPython kernel. . df[&quot;no_consecutive_spaces&quot;] = df.no_consecutive_spaces.str.strip() . /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy . Step 9: Lower case . df[&#39;lower_case&#39;] = df[&quot;no_consecutive_spaces&quot;].str.lower() . /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy &#34;&#34;&#34;Entry point for launching an IPython kernel. . df[&#39;lower_case&#39;].iloc[0] . &#39;participate in all. development activities. write high-quality code to implement. features or fix bugs and implement unit test&#39; . Step 9: Remove stopwords . import spacy nlp = spacy.load(&#39;en_core_web_md&#39;) . def remove_stop_words(text): doc = nlp(text) no_stop_words = [] for token in doc: if not token.is_stop: no_stop_words.append(token.text) return &#39; &#39;.join(no_stop_words) . df[&#39;no_sw&#39;] = df[&#39;lower_case&#39;].apply(remove_stop_words) . /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy &#34;&#34;&#34;Entry point for launching an IPython kernel. . df[&#39;no_sw&#39;][10] . &#39;chance work talented developers , following high standard . development practices ci / cd processes&#39; . Load preprocessed datasets (If it is availabel) . job_df = pd.read_csv(&quot;job_df.csv&quot;) course_df = pd.read_csv(&quot;course_df.csv&quot;) . Implement the Recommender . We will develop the recommender, which is used to suggest jobs based on learned courses. . To recommend the jobs based on courses we leverage 2 models via 2 steps: . Step 1: Firstly, we use sentence transformer model to calculate the vector embeddings for chosen courses and jobs. Then we compare the the similarity score (cosine score) between them and filter the top 10. . Step 2: Secondly, we use the NER model to extract the skills from chosen courses and courses. Then we calculate the score for each job by counting the matching skills with chosen courses. That score will be used to sort the jobs to produce the final order. . Load the NER model . checkpoint = &quot;mrm8488/codebert-base-finetuned-stackoverflow-ner&quot; . from transformers import AutoTokenizer, AutoModelForTokenClassification tokenizer = AutoTokenizer.from_pretrained(checkpoint) model = AutoModelForTokenClassification.from_pretrained(checkpoint) . from transformers import pipeline classifier = pipeline(&quot;token-classification&quot;, model=model, tokenizer=tokenizer) . Load the sentence transformer . from sentence_transformers import SentenceTransformer, util sent_model = SentenceTransformer(&#39;paraphrase-MiniLM-L12-v2&#39;) . Define helpers functions . import torch import ast from collections import defaultdict def add_space(ent): ent[&#39;word&#39;] = ent[&#39;word&#39;].replace(&#39;Ġ&#39;, &#39; &#39;) return ent def merge_B_I_entities(ents): results = [] i = 0 N = len(ents) while i &lt; N: ent = ents[i] ent = add_space(ent) if i &lt; N - 1 and ent[&#39;entity&#39;][:2] == &#39;B-&#39;: i += 1 next_ent = ents[i] while i &lt; N and next_ent[&#39;entity&#39;][:2] == &#39;I-&#39;: ent[&#39;word&#39;] += add_space(next_ent)[&#39;word&#39;] i += 1 if i &lt; N: next_ent = ents[i] else: break i -= 1 ent[&#39;end&#39;] = ents[i][&#39;end&#39;] ent[&#39;word&#39;] = ent[&#39;word&#39;].strip().lower() results.append(ent) i += 1 return results def merge_entity(ent1, ent2): if ent1[&#39;end&#39;] == ent2[&#39;start&#39;]: ent = {&#39;start&#39;: ent1[&#39;start&#39;], &#39;end&#39;: ent2[&#39;end&#39;], &#39;entity&#39;: ent1[&#39;entity&#39;], &#39;word&#39;: (ent1[&#39;word&#39;]+ent2[&#39;word&#39;]).strip().lower()} return ent def merge_similar_entities(ents): results = [] hash_map = defaultdict(list) for ent in ents: hash_map[ent[&#39;entity&#39;]].append(ent) for k, v in hash_map.items(): new_ents = [] merge_ent = v[0] i = 0 while i &lt; len(v) - 1: temp = merge_entity(merge_ent, v[i + 1]) if temp: merge_ent = temp else: new_ents.append(merge_ent) merge_ent = v[i + 1] i+=1 merge_ent[&#39;word&#39;] = merge_ent[&#39;word&#39;].strip().lower() new_ents.append(merge_ent) results += new_ents words = [ent[&#39;word&#39;] for ent in results] return results def extract_skills(desc): ents = classifier(desc) results = merge_B_I_entities(ents) results = merge_similar_entities(results) skills = set() for ent in results: skills.add(ent[&#39;word&#39;]) return list(skills) def get_skills_from_course_titles(course_titles): course_skills = set() for skills in course_df[course_df[&#39;title&#39;].isin(course_titles)][&#39;skills&#39;]: course_skills.update(ast.literal_eval(skills)) return course_skills def show_results(results): for res in results: print(res) . Define Recommender class . from collections import defaultdict from dataclasses import dataclass from typing import List import ast import torch def get_skills_from_course_titles(course_titles): course_skills = set() for skills in course_df[course_df[&#39;title&#39;].isin(course_titles)][&#39;skills&#39;]: course_skills.update(ast.literal_eval(skills)) return course_skills class Recommender: def __init__(self, ner_classifier, sent_model, course_df, setup=True): self.classifier = ner_classifier self.sent_model = sent_model self.course_info = course_df if setup: self._setup(course_df) def _setup(self, course_df): self.course_info = course_df.copy(deep=True) self.course_info[&#39;skills&#39;] = self.course_info[&#39;extract_skills&#39;].apply(self.extract_skills) def extract_skills(self, desc): ents = self.classifier(desc) results = Recommender.merge_B_I_entities(ents) results = Recommender.merge_similar_entities(results) skills = set() for ent in results: skills.add(ent[&#39;word&#39;]) return list(skills) def recommend(self, course_titles, job_info, topk: int = None) -&gt; List[Job]: c_embed = self.sent_model.encode(list(self.course_info[self.course_info[&#39;title&#39;].isin(course_titles)][&#39;no_sw&#39;]), convert_to_tensor=True) c_avg_embed = torch.mean(c_embed, axis=0) job_descs = list(job_info[&#39;no_sw&#39;]) job_embeds = self.sent_model.encode(job_descs, convert_to_tensor=True) results = Recommender.compare_embeds(c_avg_embed, job_embeds, job_info) skill_list = [set(res[2]) for res in results] my_skills = Recommender.get_skills_from_course_titles(course_titles) scores = [] # calculate similar skills scores for skills in skill_list: mutual = my_skills.intersection(skills) if len(my_skills) != 0: scores.append(len(mutual)/len(my_skills)) else: scores.append(0) for i, res in enumerate(results): final_score = res[-1] * 0.6 + 0.4 * scores[i] res[-1] = final_score results.sort(key=lambda x: x[-1], reverse=True) if topk: results = results[:topk] return results @staticmethod def get_skills_from_course_titles(course_titles): course_skills = set() for skills in course_df[course_df[&#39;title&#39;].isin(course_titles)][&#39;skills&#39;]: course_skills.update(ast.literal_eval(skills)) return course_skills @staticmethod def add_space(ent): ent[&#39;word&#39;] = ent[&#39;word&#39;].replace(&#39;Ġ&#39;, &#39; &#39;) return ent @staticmethod def merge_B_I_entities(ents): results = [] i = 0 N = len(ents) while i &lt; N: ent = ents[i] ent = add_space(ent) if i &lt; N - 1 and ent[&#39;entity&#39;][:2] == &#39;B-&#39;: i += 1 next_ent = ents[i] while i &lt; N and next_ent[&#39;entity&#39;][:2] == &#39;I-&#39;: ent[&#39;word&#39;] += add_space(next_ent)[&#39;word&#39;] i += 1 if i &lt; N: next_ent = ents[i] else: break i -= 1 ent[&#39;end&#39;] = ents[i][&#39;end&#39;] ent[&#39;word&#39;] = ent[&#39;word&#39;].strip().lower() results.append(ent) i += 1 return results @staticmethod def merge_entity(ent1, ent2): if ent1[&#39;end&#39;] == ent2[&#39;start&#39;]: ent = {&#39;start&#39;: ent1[&#39;start&#39;], &#39;end&#39;: ent2[&#39;end&#39;], &#39;entity&#39;: ent1[&#39;entity&#39;], &#39;word&#39;: (ent1[&#39;word&#39;]+ent2[&#39;word&#39;]).strip().lower()} return ent @staticmethod def merge_similar_entities(ents): results = [] hash_map = defaultdict(list) for ent in ents: hash_map[ent[&#39;entity&#39;]].append(ent) for k, v in hash_map.items(): new_ents = [] merge_ent = v[0] i = 0 while i &lt; len(v) - 1: temp = Recommender.merge_entity(merge_ent, v[i + 1]) if temp: merge_ent = temp else: new_ents.append(merge_ent) merge_ent = v[i + 1] i+=1 merge_ent[&#39;word&#39;] = merge_ent[&#39;word&#39;].strip().lower() new_ents.append(merge_ent) results += new_ents words = [ent[&#39;word&#39;] for ent in results] return results @staticmethod def compare_embeds(c_embed: List, job_embeds: List[List], job_info): results = [] for i, job_embed in enumerate(job_embeds): score = util.pytorch_cos_sim(c_embed, job_embed) results.append([job_info.index[i], job_info[&#39;title&#39;].iloc[i], job_info[&#39;skills&#39;].iloc[i], score.item()]) results.sort(key=lambda x: x[-1], reverse=True) return results @staticmethod def post_process(self, outputs): return outputs . Inference . course_df[&#39;skills&#39;] = course_df[&#39;description&#39;].apply(extract_skills) job_df[&#39;skills&#39;] = job_df[&#39;long_description&#39;].apply(extract_skills) . my_recommender = Recommender(classifier, sent_model, course_df, setup=False) . course_titles = [&#39;Artificial Intelligence&#39;, &#39;Machine Learning&#39;, &#39;Mathematics for Computing 2&#39;, &#39;Foundations of Artificial Intelligence for STEM&#39;] results = my_recommender.recommend(course_titles, job_df, 10) . show_results(results) . [77, &#39;Software Engineer in Data Science&#39;, &#34;[&#39;google deepmind&#39;, &#39;autopilot&#39;, &#39;autopilot ai&#39;, &#39;vinai&#39;, &#39;python&#39;, &#39;v&#39;, &#39;gpus&#39;, &#39;ai tooling.&#39;, &#39;dashboards&#39;, &#39;numpy&#39;, &#39;vinai autopilot&#39;, &#39;pandas&#39;, &#39;h&#39;, &#39;vin b&#39;]&#34;, 0.34073367118835446] [74, &#39;All-round Engineer&#39;, &#34;[&#39;ue&#39;, &#39;laravel engine&#39;, &#39;agile&#39;, &#39;js&#39;, &#39;search engine&#39;, &#39;php&#39;, &#39;python&#39;, &#39;4&#39;, &#39;batch&#39;]&#34;, 0.32163201570510863] [92, &#39;Software Engineer, Observability&#39;, &#34;[&#39;react&#39;, &#39;grab&#39;, &#39;elk&#39;, &#39;jaeger&#39;, &#39;python&#39;, &#39;nodejs&#39;, &#39;prometheus&#39;, &#39;amazon web services&#39;, &#39;observability&#39;, &#39;go&#39;, &#39;java&#39;, &#39;aws&#39;, &#39;unified observability&#39;, &#39;reduxflow&#39;, &#39;angular&#39;, &#39;golang&#39;]&#34;, 0.3089586853981018] [127, &#39;AI Engineer, Kobiton&#39;, &#34;[&#39;js&#39;, &#39;backend&#39;, &#39;mobiles&#39;, &#39;vietnam&#39;, &#39;java&#39;, &#39;mobile&#39;, &#39;desktops&#39;, &#39;postgredb&#39;, &#39;nguyen&#39;, &#39;ptim&#39;, &#39;k8s&#39;, &#39;golang&#39;, &#39;ghn express&#39;, &#39;docker&#39;, &#39;tablets&#39;, &#39;node&#39;, &#39;0906738&#39;, &#39;mob&#39;, &#39;restful api&#39;, &#39;back&#39;, &#39;telegram&#39;, &#39;mongodb&#39;, &#39;p&#39;]&#34;, 0.30338029861450194] [138, &#39;AI Engineer, Kobiton&#39;, &#34;[&#39;rbvh&#39;, &#39;hcmc&#39;, &#39;c++&#39;, &#39;c&#39;, &#39;sap&#39;, &#39;python union&#39;, &#39;robert bosch gmbh&#39;, &#39;jav&#39;, &#39;robert bosch&#39;, &#39;matlab&#39;, &#39;microcontroller&#39;]&#34;, 0.30338029861450194] [129, &#39;Fresh Software Engineer&#39;, &#34;[&#39;orm&#39;, &#39;win&#39;, &#39;client&#39;, &#39;kms&#39;, &#39;c#&#39;, &#39;javascript&#39;, &#39;19&#39;, &#39;.net&#39;, &#39;wp&#39;, &#39;upstar labs&#39;, &#39;scrum&#39;, &#39;mysql&#39;, &#39;entity&#39;, &#39;cov&#39;, &#39;sql&#39;, &#39;asp.net mvc&#39;, &#39;nhibernate&#39;, &#39;microsoft sql server&#39;, &#39;qasymph&#39;, &#39;winform&#39;, &#39;web api&#39;]&#34;, 0.26918667554855347] [89, &#39;Bridge Software Engineer (BSE)&#39;, &#34;[&#39;c++&#39;, &#39;ho&#39;, &#39;c&#39;, &#39;.net&#39;, &#39;project manager&#39;, &#39;java&#39;, &#39;ha&#39;]&#34;, 0.2661460340023041] [79, &#39;Full Stack Software Engineer (.NET, C#)&#39;, &#34;[&#39;reactjs&#39;, &#39;html&#39;, &#39;asp.net core&#39;, &#39;vs&#39;, &#39;8:00 âģĵ 10: 00 am&#39;, &#39;azure devops&#39;, &#39;c#&#39;, &#39;javascript&#39;, &#39;git&#39;, &#39;hub&#39;, &#39;sql&#39;, &#39;.net&#39;, &#39;dan&#39;, &#39;agile&#39;, &#39;angular&#39;]&#34;, 0.26532386541366576] [0, &#39;Fresher Python Software Engineer&#39;, &#34;[&#39;client&#39;, &#39;kms&#39;, &#39;19&#39;, &#39;cov-&#39;, &#39;k&#39;, &#39;upstar labs&#39;]&#34;, 0.2651121497154236] [113, &#39;[ECM] Test Engineer&#39;, &#34;[&#39;vuejs&#39;, &#39;loopback&#39;, &#39;react&#39;, &#39;ui-ux&#39;, &#39;kms&#39;, &#39;express&#39;, &#39;nodejs&#39;, &#39;kobiton&#39;, &#39;tricentis&#39;, &#39;angularjs&#39;, &#39;19emic&#39;, &#39;katalon&#39;, &#39;k&#39;, &#39;($100m&#39;, &#39;mobile&#39;, &#39;covid&#39;, &#39;koa&#39;, &#39;qasymphony&#39;]&#34;, 0.26384042501449584] . course_titles = [&#39;Peer-to-Peer Networks&#39;,&#39;Distributed Systems&#39;] results = my_recommender.recommend(course_titles, job_df, 10) . show_results(results) . [92, &#39;Software Engineer, Observability&#39;, &#34;[&#39;react&#39;, &#39;grab&#39;, &#39;elk&#39;, &#39;jaeger&#39;, &#39;python&#39;, &#39;nodejs&#39;, &#39;prometheus&#39;, &#39;amazon web services&#39;, &#39;observability&#39;, &#39;go&#39;, &#39;java&#39;, &#39;aws&#39;, &#39;unified observability&#39;, &#39;reduxflow&#39;, &#39;angular&#39;, &#39;golang&#39;]&#34;, 0.29281051754951476] [78, &#39;SOFTWARE ENGINEER (HCM)&#39;, &#34;[&#39;$700&#39;, &#39;devops&#39;, &#39;data engineer&#39;, &#39;15000000.&#39;, &#39;vue.js&#39;, &#39;relational&#39;, &#39;java&#39;, &#39;. 40000000&#39;, &#39;c¦ung&#39;, &#39;data analyst&#39;, &#39;angular.js&#39;, &#39;ch&#39;, &#39;v&#39;, &#39;24-09-2021&#39;, &#39;yãĭu&#39;, &#39;sql&#39;, &#39;jvm&#39;, &#39;$2000&#39;, &#39;python&#39;, &#39;react.js&#39;, &#39;scala&#39;]&#34;, 0.2801404237747192] [36, &#39;System/Network Engineer_Freshers&#39;, &#34;[&#39;hypervisors&#39;, &#39;3 switch&#39;, &#39;shell&#39;, &#39;jun&#39;, &#39;super computer&#39;, &#39;vmware&#39;, &#39;qemui&#39;, &#39;vlan&#39;, &#39;linux&#39;, &#39;kvm&#39;, &#39;hyper-v&#39;, &#39;l&#39;, &#39;hpc&#39;]&#34;, 0.2568916082382202] [113, &#39;[ECM] Test Engineer&#39;, &#34;[&#39;vuejs&#39;, &#39;loopback&#39;, &#39;react&#39;, &#39;ui-ux&#39;, &#39;kms&#39;, &#39;express&#39;, &#39;nodejs&#39;, &#39;kobiton&#39;, &#39;tricentis&#39;, &#39;angularjs&#39;, &#39;19emic&#39;, &#39;katalon&#39;, &#39;k&#39;, &#39;($100m&#39;, &#39;mobile&#39;, &#39;covid&#39;, &#39;koa&#39;, &#39;qasymphony&#39;]&#34;, 0.2493357181549072] [77, &#39;Software Engineer in Data Science&#39;, &#34;[&#39;google deepmind&#39;, &#39;autopilot&#39;, &#39;autopilot ai&#39;, &#39;vinai&#39;, &#39;python&#39;, &#39;v&#39;, &#39;gpus&#39;, &#39;ai tooling.&#39;, &#39;dashboards&#39;, &#39;numpy&#39;, &#39;vinai autopilot&#39;, &#39;pandas&#39;, &#39;h&#39;, &#39;vin b&#39;]&#34;, 0.24794490337371825] [103, &#39;Software Engineer&#39;, &#34;[&#39;5&#39;, &#39;html&#39;, &#39;client&#39;, &#39;cocos creator&#39;, &#39;cocos&#39;, &#39;javascript&#39;, &#39;css&#39;, &#39;2dx&#39;, &#39;restful api&#39;, &#39;unity&#39;, &#39;mobile&#39;, &#39;type&#39;]&#34;, 0.24549003839492797] [47, &#39;Fullstack Software Engineer (ReactJS/NodeJS/Go)&#39;, &#34;[&#39;n&#39;, &#39;svn&#39;, &#39;webpack&#39;, &#39;javascript&#39;, &#39;git&#39;, &#39;es&#39;, &#39;6&#39;, &#39;bower&#39;, &#39;reactjs&#39;, &#39;golang&#39;, &#39;babel&#39;, &#39;chotot&#39;, &#39;docker&#39;, &#39;web browser&#39;, &#39;nodejs&#39;, &#39;mac&#39;, &#39;json&#39;, &#39;grunt&#39;, &#39;full stack&#39;]&#34;, 0.2437905728816986] [18, &#39;Software Engineer (Golang/Java)&#39;, &#34;[&#39;server&#39;, &#39;backend&#39;, &#39;tidb&#39;, &#39;java&#39;, &#39;container&#39;, &#39;javascript&#39;, &#39;rdbms&#39;, &#39;git&#39;, &#39;css&#39;, &#39;angularjs&#39;, &#39;reactjs&#39;, &#39;golang&#39;, &#39;html&#39;, &#39;docker&#39;, &#39;mysql&#39;, &#39;redis&#39;, &#39;kafka&#39;, &#39;nosql&#39;, &#39;zalopay&#39;, &#39;frontend&#39;, &#39;jquery&#39;]&#34;, 0.24373272657394407] [34, &#39;Automation Test Engineer&#39;, &#34;[&#39;mocha&#39;, &#39;kms&#39;, &#39;appium&#39;, &#39;testng&#39;, &#39;kms labsasymph&#39;, &#39;nightwatch&#39;, &#39;jasmine&#39;, &#39;scrum&#39;, &#39;selenium&#39;]&#34;, 0.23755048513412474] [104, &#39;Software Engineer&#39;, &#34;[&#39;microsoft .net&#39;, &#39;sql server&#39;]&#34;, 0.23728473186492918] . my_skills = get_skills_from_course_titles(course_titles) my_skills .",
            "url": "https://minhdang241.github.io/minhdg-blog/implementation/2021/08/30/NLP_12_Job_Recommendation_for_CS_IT.html",
            "relUrl": "/implementation/2021/08/30/NLP_12_Job_Recommendation_for_CS_IT.html",
            "date": " • Aug 30, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Extract aspects from sentence using denpendency parsing and POS tags",
            "content": "from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Mounted at /content/drive . Install required modules . %%capture !pip install pyvi !pip install https://github.com/trungtv/vi_spacy/raw/master/packages/vi_spacy_model-0.2.1/dist/vi_spacy_model-0.2.1.tar.gz !pip install spacy==2.1.4 . Note: In this post, we will use spacy version 2 since in version it changes the way to load model, and I don&#39;t know how to make it work for the vi_spacy_model :). . import pandas as pd import numpy as np import spacy from string import punctuation . pd.set_option(&quot;display.max_colwidth&quot;, None) . Load dataset . df = pd.read_csv(&quot;/content/drive/MyDrive/SLSOPS/dataset/vietnamese/spacy.csv&quot;) . df.head() . db_id raw tokenized_spacy spacy_no_sw star_rating . 0 1 | Shipper giao đúng hẹn, tận tình mang vào đến cửa căn hộ chung cư. | shipper giao đúng hẹn tận_tình mang vào đến cửa căn_hộ chung_cư | shipper giao hẹn tận_tình cửa căn_hộ chung_cư | 5 | . 1 1 | Nhân viên lắp đặt thân thiện, làm việc tốt, tuy nhiên hơi làm dơ tường và đồ đạc trong nhà. | nhân_viên lắp_đặt thân_thiện làm_việc tốt tuy_nhiên hơi làm dơ tường và đồ_đạc trong nhà | nhân_viên lắp_đặt thân_thiện làm_việc tốt hơi dơ tường đồ_đạc | 5 | . 2 1 | Sản phẩm đẹp, giá cạnh tranh. | sản_phẩm đẹp giá cạnh_tranh | sản_phẩm đẹp giá cạnh_tranh | 5 | . 3 1 | Nhưng giá Tiki bán là ko tặng vật tư giống ở ngoài bán. | nhưng giá tiki bán là không tặng_vật_tư giống ở ngoài bán | giá tiki tặng_vật_tư | 5 | . 4 1 | Lúc máy mình lắp xong thì giá vật tư là khoảng hơn 1 triệu. | lúc máy mình lắp xong thì giá vật_tư là khoảng hơn 1 triệu | máy lắp xong giá vật_tư 1 triệu | 5 | . Extract Aspects using NER and POS . from dataclasses import dataclass @dataclass class AsOp: aspect: Any = None opinion: Any = None adv: Any = None verb: Any = None negative: bool = False aspect_compound: Any = None @dataclass class Aspect_Opinion: aspect: str = None opinion: str = None verb: str = None negative: bool = False . import spacy nlp = spacy.load(&#39;vi_spacy_model&#39;) doc = nlp(&#39;Cộng đồng xử lý ngôn ngữ tự nhiên&#39;) for token in doc: print(token.text, token.tag_, token.dep_) . Cộng_đồng N nsubj xử_lý V ROOT ngôn_ngữ N obj tự_nhiên A compound . data = list(df[&#39;spacy_no_sw&#39;]) data[0] . &#39;shipper giao hẹn tận_tình cửa căn_hộ chung_cư&#39; . from spacy import displacy # module for visualize the denpendency parsing displacy.render(nlp(df[&#39;tokenized_spacy&#39;][2]), style=&quot;dep&quot;, jupyter=True) . sản_phẩm X đẹp X giá X cạnh_tranh X amod compound xcomp displacy.render(nlp(sentences[20]), style=&quot;dep&quot;, jupyter=True) . tiền X nào X của X nấy X nhưng X âm_thanh X ồn_ào X như X động_cơ X bezen X ầm_ầm X thế X này X thì X chịu X rồi X nsubj det case nmod cc amod cc nsubj compound ccomp obj det cc conj advmod Rules . We check 2 cases: . The token POS is N (Noun) and the Dependency tag is not nsubj. | The token POS is N (Noun) and the Dependency tag is nsubj. | Note: I come up with these rules by trying with many samples =)) No magic behind it. . aspects = [] doc = nlp(sentences[25]) print(doc) for i, token in enumerate(doc): # Case 1: if token.tag_ == &quot;N&quot; and token.dep_ != &quot;nsubj&quot;: aspect = token.text for child in token.children: if child.dep_ == &quot;compound&quot;: if child in token.lefts: aspect = f&quot;{child.text} {aspect}&quot; elif child in token.rights: aspect = f&quot;{aspect} {child.text}&quot; elif child.dep_ == &quot;amod&quot;: opinion = child.text for gchild in child.children: if gchild.dep_ == &quot;advmod&quot;: if gchild in child.lefts: opinion = f&quot;{gchild.text} {opinion}&quot; elif gchild in child.rights: opinion = f&quot;{opinion} {gchild.text}&quot; asp_obj = AsOp(aspect=aspect, opinion=opinion) aspects.append(asp_obj) elif child.dep_ == &quot;conj&quot;: asp_obj = None if child.tag_ == &quot;N&quot;: aspect = child.text opinion = &quot;&quot; for gchild in child.rights: if gchild.dep_ == &quot;xcomp&quot; and gchild.tag_ == &quot;A&quot;: opinion = gchild.text if opinion: asp_obj = AsOp(aspect=aspect, opinion=opinion) elif child.tag_ == &quot;A&quot;: asp_obj = AsOp(aspect=aspect, opinion=child.text) if asp_obj: aspects.append(asp_obj) # Case 2: elif token.tag_ == &quot;N&quot; and token.dep_ == &quot;nsubj&quot;: opinion = &quot;&quot; if token.head.tag_ == &quot;A&quot;: opinion = token.head.text for child in token.head.children: if child.text == token.text: continue elif child.tag_ == &quot;A&quot; or child.tag_ == &quot;R&quot;: if opinion: if child in token.head.lefts: opinion = f&quot;{child.text} {opinion}&quot; else: opinion = f&quot;{opinion} {child.text}&quot; else: opinion = child.text for gchild in child.children: if gchild.dep_ == &quot;advmod&quot;: if gchild in child.lefts: opinion = f&quot;{gchild.text} {opinion}&quot; elif gchild in child.rights: opinion = f&quot;{opinion} {gchild.text}&quot; asp_obj = AsOp(aspect=token.text, opinion=opinion) aspects.append(asp_obj) print(aspects) . đến chán giờ cứ sử_dụng là bị cúp nguồn điện thì ai dám bật [] . from dataclasses import dataclass from typing import Any @dataclass class AsOp: aspect: Any = None opinion: Any = None . from pyvi import ViTokenizer, ViPosTagger sentence = df[&#39;tokenized_spacy&#39;][6] # print(sentence) sentences = list(df[&#39;tokenized_spacy&#39;])[:100] aspects = [] cnt = 0 for sentence in sentences: try: doc = nlp(sentence) for i, token in enumerate(doc): if token.tag_ == &quot;N&quot; and token.dep_ != &quot;nsubj&quot;: aspect = token.text for child in token.children: if child.dep_ == &quot;compound&quot;: if child in token.lefts: aspect = f&quot;{child.text} {aspect}&quot; elif child in token.rights: aspect = f&quot;{aspect} {child.text}&quot; elif child.dep_ == &quot;amod&quot;: opinion = child.text for gchild in child.children: if gchild.dep_ == &quot;advmod&quot;: if gchild in child.lefts: opinion = f&quot;{gchild.text} {opinion}&quot; elif gchild in child.rights: opinion = f&quot;{opinion} {gchild.text}&quot; asp_obj = AsOp(aspect=aspect, opinion=opinion) aspects.append(asp_obj) elif child.dep_ == &quot;conj&quot;: asp_obj = None if child.tag_ == &quot;N&quot;: aspect = child.text opinion = &quot;&quot; for gchild in child.rights: if gchild.dep_ == &quot;xcomp&quot; and gchild.tag_ == &quot;A&quot;: opinion = gchild.text if opinion: asp_obj = AsOp(aspect=aspect, opinion=opinion) elif child.tag_ == &quot;A&quot;: asp_obj = AsOp(aspect=aspect, opinion=child.text) if asp_obj: aspects.append(asp_obj) elif token.tag_ == &quot;N&quot; and token.dep_ == &quot;nsubj&quot;: opinion = &quot;&quot; if token.head.tag_ == &quot;A&quot;: opinion = token.head.text for child in token.head.children: if child.text == token.text: continue elif child.tag_ == &quot;A&quot; or child.tag_ == &quot;R&quot;: if opinion: if child in token.head.lefts: opinion = f&quot;{child.text} {opinion}&quot; else: opinion = f&quot;{opinion} {child.text}&quot; else: opinion = child.text for gchild in child.children: if gchild.dep_ == &quot;advmod&quot;: if gchild in child.lefts: opinion = f&quot;{gchild.text} {opinion}&quot; elif gchild in child.rights: opinion = f&quot;{opinion} {gchild.text}&quot; asp_obj = AsOp(aspect=token.text, opinion=opinion) aspects.append(asp_obj) except: print(sentence) cnt += 1 . aspects . [AsOp(aspect=&#39;shipper&#39;, opinion=&#39;vào&#39;), AsOp(aspect=&#39;nhân_viên&#39;, opinion=&#39;tốt&#39;), AsOp(aspect=&#39;sản_phẩm&#39;, opinion=&#39;đẹp&#39;), AsOp(aspect=&#39;giá&#39;, opinion=&#39;không tặng_vật_tư&#39;), AsOp(aspect=&#39;giá&#39;, opinion=&#39;không tặng_vật_tư giống&#39;), AsOp(aspect=&#39;giá&#39;, opinion=&#39;khoảng&#39;), AsOp(aspect=&#39;giá&#39;, opinion=&#39;hơn khoảng&#39;), AsOp(aspect=&#39;giá&#39;, opinion=&#39;hơn&#39;), AsOp(aspect=&#39;tiền&#39;, opinion=&#39;hơn&#39;), AsOp(aspect=&#39;tiền&#39;, opinion=&#39;không hơn&#39;), AsOp(aspect=&#39;hàng&#39;, opinion=&#39;đúng&#39;), AsOp(aspect=&#39;tiki giao_nhận&#39;, opinion=&#39;tốt&#39;), AsOp(aspect=&#39;máy&#39;, opinion=&#39;tốt&#39;), AsOp(aspect=&#39;máy&#39;, opinion=&#39;rất êm&#39;), AsOp(aspect=&#39;hàng&#39;, opinion=&#39;nhanh&#39;), AsOp(aspect=&#39;hàng&#39;, opinion=&#39;nhanh ổn&#39;), AsOp(aspect=&#39;sản_phẩm&#39;, opinion=&#39;tạm&#39;), AsOp(aspect=&#39;hàng&#39;, opinion=&#39;nhanh&#39;), AsOp(aspect=&#39;máy_lạnh&#39;, opinion=&#39;chưa&#39;), AsOp(aspect=&#39;máy_lạnh&#39;, opinion=&#39;chưa được&#39;), AsOp(aspect=&#39;máy&#39;, opinion=&#39;chỉ&#39;), AsOp(aspect=&#39;tiền&#39;, opinion=&#39;ồn_ào&#39;), AsOp(aspect=&#39;âm_thanh&#39;, opinion=&#39;ồn_ào&#39;), AsOp(aspect=&#39;hàng&#39;, opinion=&#39;mới&#39;), AsOp(aspect=&#39;hàng&#39;, opinion=&#39;cũ&#39;), AsOp(aspect=&#39;điện&#39;, opinion=&#39;cực_kỳ tốt&#39;), AsOp(aspect=&#39;điện&#39;, opinion=&#39;cực_kỳ tốt liên_tục&#39;), AsOp(aspect=&#39;sản_phẩm&#39;, opinion=&#39;cùng&#39;), AsOp(aspect=&#39;thực_tế&#39;, opinion=&#39;gần&#39;), AsOp(aspect=&#39;tiếng&#39;, opinion=&#39;to&#39;), AsOp(aspect=&#39;tiếng&#39;, opinion=&#39;không êm&#39;), AsOp(aspect=&#39;pin&#39;, opinion=&#39;không&#39;), AsOp(aspect=&#39;đội_ngũ&#39;, opinion=&#39;rất&#39;), AsOp(aspect=&#39;giá&#39;, opinion=&#39;thêm&#39;), AsOp(aspect=&#39;người&#39;, opinion=&#39;xanh&#39;), AsOp(aspect=&#39;tiki&#39;, opinion=&#39;rẻ&#39;), AsOp(aspect=&#39;máy&#39;, opinion=&#39;đúng đúng&#39;), AsOp(aspect=&#39;máy&#39;, opinion=&#39;khá to&#39;), AsOp(aspect=&#39;máy&#39;, opinion=&#39;khá to êm&#39;), AsOp(aspect=&#39;máy&#39;, opinion=&#39;khá to êm lại&#39;), AsOp(aspect=&#39;khi&#39;, opinion=&#39;sẽ êm&#39;), AsOp(aspect=&#39;máy&#39;, opinion=&#39;quá ồn&#39;), AsOp(aspect=&#39;bạn&#39;, opinion=&#39;dễ_thương&#39;), AsOp(aspect=&#39;bạn&#39;, opinion=&#39;dễ_thương lắm&#39;), AsOp(aspect=&#39;hàng&#39;, opinion=&#39;nhanh&#39;), AsOp(aspect=&#39;độ&#39;, opinion=&#39;nhiều&#39;), AsOp(aspect=&#39;độ&#39;, opinion=&#39;bền&#39;), AsOp(aspect=&#39;ngày&#39;, opinion=&#39;hợp_lý&#39;), AsOp(aspect=&#39;đội&#39;, opinion=&#39;nhiều&#39;), AsOp(aspect=&#39;điều&#39;, opinion=&#39;hòa&#39;), AsOp(aspect=&#39;sản_phẩm&#39;, opinion=&#39;không&#39;), AsOp(aspect=&#39;sản_phẩm&#39;, opinion=&#39;mới không&#39;), AsOp(aspect=&#39;sản_phẩm&#39;, opinion=&#39;mới không ra&#39;), AsOp(aspect=&#39;sản_phẩm&#39;, opinion=&#39;mới không ra rồi&#39;), AsOp(aspect=&#39;điểm&#39;, opinion=&#39;vô_cùng&#39;), AsOp(aspect=&#39;điều&#39;, opinion=&#39;hòa&#39;), AsOp(aspect=&#39;điều&#39;, opinion=&#39;hòa&#39;), AsOp(aspect=&#39;điều&#39;, opinion=&#39;cũ&#39;), AsOp(aspect=&#39;phí&#39;, opinion=&#39;không&#39;), AsOp(aspect=&#39;lần&#39;, opinion=&#39;cuối_cùng&#39;), AsOp(aspect=&#39;chiều&#39;, opinion=&#39;dài&#39;), AsOp(aspect=&#39;cái màng&#39;, opinion=&#39;lọc&#39;), AsOp(aspect=&#39;biên_độ&#39;, opinion=&#39;nóng&#39;), AsOp(aspect=&#39;biên_độ&#39;, opinion=&#39;lạnh&#39;), AsOp(aspect=&#39;biên_độ&#39;, opinion=&#39;cao&#39;), AsOp(aspect=&#39;tổng_chi_phí&#39;, opinion=&#39;hết&#39;), AsOp(aspect=&#39;bao&#39;, opinion=&#39;gôm&#39;), AsOp(aspect=&#39;lòng&#39;, opinion=&#39;thật buồn&#39;), AsOp(aspect=&#39;giá&#39;, opinion=&#39;rẻ&#39;), AsOp(aspect=&#39;giá&#39;, opinion=&#39;rât&#39;), AsOp(aspect=&#39;giá&#39;, opinion=&#39;hợp_lý&#39;), AsOp(aspect=&#39;7tr&#39;, opinion=&#39;tròn&#39;), AsOp(aspect=&#39;cục&#39;, opinion=&#39;không&#39;), AsOp(aspect=&#39;cục&#39;, opinion=&#39;không có&#39;), AsOp(aspect=&#39;máy&#39;, opinion=&#39;hơi lạnh&#39;), AsOp(aspect=&#39;cảm_giác&#39;, opinion=&#39;rất dễ_chịu&#39;), AsOp(aspect=&#39;cục&#39;, opinion=&#39;lạnh&#39;), AsOp(aspect=&#39;cục&#39;, opinion=&#39;nóng khoảng&#39;), AsOp(aspect=&#39;cánh_quạt&#39;, opinion=&#39;không&#39;), AsOp(aspect=&#39;cánh_quạt&#39;, opinion=&#39;không được&#39;), AsOp(aspect=&#39;cục&#39;, opinion=&#39;nóng&#39;), AsOp(aspect=&#39;máy_lạnh&#39;, opinion=&#39;rất tận_tình&#39;), AsOp(aspect=&#39;máy_lạnh&#39;, opinion=&#39;rất tận_tình kém&#39;), AsOp(aspect=&#39;nhân_viên&#39;, opinion=&#39;rất tận_tình&#39;), AsOp(aspect=&#39;nhân_viên&#39;, opinion=&#39;rất tận_tình kém&#39;), AsOp(aspect=&#39;dịch_vụ&#39;, opinion=&#39;rất kém&#39;), AsOp(aspect=&#39;máy_lạnh&#39;, opinion=&#39;tạm ổn&#39;), AsOp(aspect=&#39;máy_lạnh&#39;, opinion=&#39;tạm ổn êm&#39;), AsOp(aspect=&#39;cục&#39;, opinion=&#39;nóng rất&#39;), AsOp(aspect=&#39;dịch_vụ&#39;, opinion=&#39;khá ổn&#39;), AsOp(aspect=&#39;máy&#39;, opinion=&#39;lạnh&#39;), AsOp(aspect=&#39;mát&#39;, opinion=&#39;lạnh&#39;), AsOp(aspect=&#39;sản_phẩm&#39;, opinion=&#39;mới&#39;), AsOp(aspect=&#39;hàng&#39;, opinion=&#39;nhanh&#39;), AsOp(aspect=&#39;máy&#39;, opinion=&#39;êm&#39;), AsOp(aspect=&#39;máy&#39;, opinion=&#39;êm ít&#39;), AsOp(aspect=&#39;máy&#39;, opinion=&#39;đẹp&#39;), AsOp(aspect=&#39;máy&#39;, opinion=&#39;tốt&#39;), AsOp(aspect=&#39;cục&#39;, opinion=&#39;dễ&#39;), AsOp(aspect=&#39;thiết_kế&#39;, opinion=&#39;trang_nhã&#39;), AsOp(aspect=&#39;cục&#39;, opinion=&#39;mạnh_mẽ&#39;), AsOp(aspect=&#39;cục&#39;, opinion=&#39;cứng_cáp&#39;), AsOp(aspect=&#39;tính_năng&#39;, opinion=&#39;nhiều&#39;), AsOp(aspect=&#39;máy&#39;, opinion=&#39;không&#39;), AsOp(aspect=&#39;tốc_độ gió&#39;, opinion=&#39;phù_hợp&#39;), AsOp(aspect=&#39;kích_thước&#39;, opinion=&#39;khác&#39;), AsOp(aspect=&#39;chức_năng&#39;, opinion=&#39;đầy_đủ&#39;)] . Discussion . The quality of this approach depends on the accuracy of the dependecy parsing and POS model. . Tags . A - Adjective C - Coordinating conjunction E - Preposition I - Interjection L - Determiner M - Numeral N - Common noun Nc - Noun Classifier Ny - Noun abbreviation Np - Proper noun Nu - Unit noun P - Pronoun R - Adverb S - Subordinating conjunction T - Auxiliary, modal words V - Verb X - Unknown F - Filtered out (punctuation) . ccomp: functions like an object of the verb, or adjective. . xcomp: if the subject of the clausal complement is controlled (that is, must be the same as the higher subject or object, with no other possible interpretation) . predicative: a part of a sentence containing a verb that makes a statement about the subject of the verb, such as went home in John went home. .",
            "url": "https://minhdang241.github.io/minhdg-blog/implementation/2021/08/18/NLP_11_Extract_aspects_from_sentence_using_denpendency_parsing_and_POS_tags.html",
            "relUrl": "/implementation/2021/08/18/NLP_11_Extract_aspects_from_sentence_using_denpendency_parsing_and_POS_tags.html",
            "date": " • Aug 18, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "AIVIVN Product Review Sentiment Analysis [Pytorch Lightning Sample]",
            "content": "from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Mounted at /content/drive . Install required packages . %%capture !pip install pytorch-lightning !pip install torchmetrics !pip install pyvi !pip install torch-summary . Import required packages . import re import copy from pathlib import Path from typing import Any, Dict, List, Optional, Tuple, Union from os.path import abspath import torchmetrics import pandas as pd . Have a closer look at the dataset . The data contains user&#39;s reviews following two categories: &quot;positive&quot; and &quot;negative&quot;. There are 27068 sentences in total. . Train: 16087 sentences | Test: 10981 sentences (public: 5454 sentences, private: 5527 sentences) | Labels: 0 (positive), 1 (negative) | . You can download the dataset here. . train_path = &quot;/content/drive/MyDrive/SLSOPS/dataset/Aivivn_vietnamese_dataset/train.crash&quot; test_path = &quot;/content/drive/MyDrive/SLSOPS/dataset/Aivivn_vietnamese_dataset/test.crash&quot; . def split_array(arr, condition): if len(arr) == 0: return [] result = [] accumulated = [arr[0]] for ele in arr[1:]: if condition(ele): result.append(copy.deepcopy(accumulated)) accumulated = [copy.deepcopy(ele)] else: accumulated.append(copy.deepcopy(ele)) result.append(copy.deepcopy(accumulated)) return result def read_file(file_path, is_train=True): file_path = abspath(file_path) data_lines = list( filter(lambda x: x != &#39;&#39;, open(file_path).read().split(&#39; n&#39;))) pattern = (&#39;train&#39; if is_train else &#39;test&#39;) + &#39;_[0-9]{5}&#39; datas = split_array(data_lines, lambda x: bool(re.match(pattern, x))) if is_train: result_array = list(map( lambda x: [x[0], &#39; &#39;.join(x[1:-1]), int(x[-1])], datas)) else: result_array = list(map(lambda x: [x[0], &#39; &#39;.join(x[1:])], datas)) columns = [&#39;name&#39;, &#39;text&#39;, &#39;label&#39;] if is_train else [&#39;name&#39;, &#39;text&#39;] return pd.DataFrame(result_array, columns=columns) . train_df = read_file(train_path) test_df = read_file(test_path, is_train=False) . train_df.head() . name text label . 0 train_000000 | &quot;Dung dc sp tot cam on shop Đóng gói sản phẩm... | 0 | . 1 train_000001 | &quot; Chất lượng sản phẩm tuyệt vời . Son mịn nhưn... | 0 | . 2 train_000002 | &quot; Chất lượng sản phẩm tuyệt vời nhưng k có hộp... | 0 | . 3 train_000003 | &quot;:(( Mình hơi thất vọng 1 chút vì mình đã kỳ v... | 1 | . 4 train_000004 | &quot;Lần trước mình mua áo gió màu hồng rất ok mà ... | 1 | . test_df.head() . name text . 0 test_000000 | &quot;Chưa dùng thử nên chưa biết&quot; | . 1 test_000001 | &quot; Không đáng tiềnVì ngay đợt sale nên mới mua ... | . 2 test_000002 | &quot;Cám ơn shop. Đóng gói sản phẩm rất đẹp và chắ... | . 3 test_000003 | &quot;Vải đẹp.phom oki luôn.quá ưng&quot; | . 4 test_000004 | &quot;Chuẩn hàng đóng gói đẹp&quot; | . Define dataset and dataloader classes . from typing import List, Tuple import torchtext from collections import Counter, OrderedDict from torch.nn.utils.rnn import pad_sequence from torchtext.vocab import Vectors, Vocab class Tokenizer(): def __init__(self, tokenizer: Any): self.counter = Counter([&#39;&lt;pad&gt;&#39;, &#39;&lt;unk&gt;&#39;]) self.tokenizer = tokenizer self.vocab = None self.update_vocab() def update_vocab(self): # sorted_by_freq_tuples = sorted(self.counter.items()[2:], key=lambda x: x[1], reverse=True) ordered_dict = OrderedDict(self.counter.items()) self.vocab = torchtext.vocab.vocab(ordered_dict, min_freq=1) def fit_on_texts(self, texts: List[str]): &quot;&quot;&quot; Updates internal vocabulary based on a list of texts. &quot;&quot;&quot; for text in texts: tokens = [t.text for t in self.tokenizer(text)] self.counter.update(tokens) self.update_vocab() def texts_to_sequences(self, texts: List[str], tensor: bool=True) -&gt; List[int]: word2idx = self.vocab.get_stoi() sequences = [] for text in texts: seq = [word2idx.get(token.text, word2idx[&#39;&lt;unk&gt;&#39;]) for token in self.tokenizer(text)] if tensor: seq = torch.tensor(seq) sequences.append(seq) return sequences def _load_data_from(data_path: Union[str, Path]): df = read_file(data_path) sents = list(df[&#39;text&#39;].str.strip().str.lower()) sentiments = list(df[&#39;label&#39;]) return sents, sentiments def _save_to_csv(file_path: Union[str, Path], data): sents, sentiments = data df = pd.DataFrame({ &quot;text&quot;: sents, &quot;label&quot;: sentiments, }) df.to_csv(file_path, index=False) return file_path def _preprocess_data(data: Tuple[List[str], List[str]], tokenizer: Tokenizer): sentences, sentiments = data sequences = tokenizer.texts_to_sequences(sentences) sentiment_tensor = torch.tensor(sentiments) # pad sequences sequences = pad_sequence(sequences, batch_first=True) assert len(sequences) == len(sentiments) all_data = [] for i in range(len(sentiments)): sample = { &#39;sequence&#39;: sequences[i], &#39;sentiment&#39;: sentiment_tensor[i] } all_data.append(sample) return all_data def build_vocab(tokenizer, data): sentences = data[0] tokenizer.fit_on_texts(sentences) . from gensim.models import KeyedVectors from gensim.test.utils import datapath import numpy as np def load_pretrained_word_embeddings(w2v_path: str): return KeyedVectors.load_word2vec_format(datapath(w2v_path), binary=False) def create_embedding_matrix(w2v_model, vocab: Vocab, path: Union[str, Path]): if os.path.exists(path): print(f&#39;loading embedding matrix from {path}&#39;) embedding_matrix = pickle.load(open(path, &#39;rb&#39;)) else: # Calculate vector for OOV token OOV_vec = torch.from_numpy(np.mean(w2v_model.vectors, axis=0)) embedding_matrix = torch.zeros((len(vocab), w2v_model.vector_size), dtype=torch.float) # words that are not availabel in the pretrained word embeddings will be zeros for word, index in vocab.get_stoi().items(): if word in w2v_model.vocab: embedding_matrix[index] = torch.from_numpy(w2v_model[word]) else: if word == &quot;&lt;pad&gt;&quot;: continue embedding_matrix[index] = OOV_vec # save embedding matrix pickle.dump(embedding_matrix, open(path, &#39;wb&#39;)) return embedding_matrix . Now we create the datamodule class for the dataset using Pytorch-Lightning Framework. You can read more here. . import torch from torch.utils.data import DataLoader, Dataset, random_split import pytorch_lightning as pl class AIVIVNDataset(Dataset): def __init__(self, data): self.data = data def __len__(self): return len(self.data) def __getitem__(self, idx): return self.data[idx] class AIVIVN(pl.LightningDataModule): def __init__(self, tokenizer, opts: Dict[str, Any]): super().__init__() self.tokenizer = tokenizer self.batch_size = opts[&#39;batch_size&#39;] self.num_workers = opts[&#39;num_workers&#39;] self.on_gpu = opts[&#39;on_gpu&#39;] self.train_ds = None self.val_ds = None self.mapping = {&quot;negative&quot;: 1, &quot;positive&quot;: 0} self.inverse_mapping = {v: k for k, v in enumerate(self.mapping)} def prepare_data(self, *args, **kwargs) -&gt; None: self.train_path = &#39;/content/drive/MyDrive/SLSOPS/dataset/Aivivn_vietnamese_dataset/train.crash&#39; def setup(self, stage: str = None) -&gt; None: if stage == &quot;fit&quot; or stage is None: # Load data from files train_data = _load_data_from(self.train_path) preprocessed_data = _preprocess_data(train_data, self.tokenizer) dataset = AIVIVNDataset(preprocessed_data) lengths = [int(len(dataset)*0.85), len(dataset) - int(len(dataset)*0.85)] self.train_ds, self.val_ds = random_split(dataset, lengths) def train_dataloader(self): return DataLoader( self.train_ds, shuffle=True, batch_size=self.batch_size, num_workers=self.num_workers, pin_memory=self.on_gpu ) def val_dataloader(self): return DataLoader( self.val_ds, shuffle=False, batch_size=self.batch_size, num_workers=self.num_workers, pin_memory=self.on_gpu, ) def __repr__(self): basic = f&quot;AIVIVN Product Review Dataset nNum classes: {len(self.mapping)} nMapping: {self.mapping} n&quot; if self.train_ds is None and self.val_ds is None: return basic batch = next(iter(self.train_dataloader())) sequences, sentiments = batch[&#39;sequence&#39;], batch[&#39;sentiment&#39;] data = ( f&quot;Train/val sizes: {len(self.train_ds)}, {len(self.val_ds)} n&quot; f&quot;Batch sequences stats: {(sequences.shape, sequences.dtype)} n&quot; f&quot;Batch sentiments stats: {(sentiments.shape, sentiments.dtype)} n&quot; ) return basic + data . Implementation (TextCNN) . import torch.nn as nn import torch.nn.functional as F class ConvPool(nn.Module): def __init__(self, in_channels, out_channels, conv_kernel_sz, pool_kernel_sz): super(ConvPool, self).__init__() self.conv = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=conv_kernel_sz) self.pool = nn.MaxPool1d(pool_kernel_sz) def forward(self, x): out = self.conv(x) out = F.relu(out) out = self.pool(out) return out class TextCNN(pl.LightningModule): def __init__(self, embeddings, num_classes=2, batch_first=True, lr=1e-3, dropout=0, l2reg=0.01): super().__init__() embedding_dim = embeddings.shape[1] self.embedding = nn.Embedding.from_pretrained(embeddings) kernel_sizes = [3,4,5] self.filters = nn.ModuleList([ConvPool(embedding_dim, 128, conv_kernel_sz=conv_kernel_size, pool_kernel_sz=5) for conv_kernel_size in kernel_sizes]) self.conv_pool1 = ConvPool(128, 128, 5, 5) self.conv_pool2 = ConvPool(128, 128, 5, 30) self.flatten = nn.Flatten(start_dim=1) self.linear1 = nn.Linear(256, 128) self.linear2 = nn.Linear(128, num_classes) self.lr = lr self.l2reg = l2reg self.train_acc = torchmetrics.Accuracy() self.val_acc = torchmetrics.Accuracy() self.val_f1 = torchmetrics.F1(num_classes=2, average=&#39;macro&#39;) self.test_acc = torchmetrics.Accuracy() self.test_f1 = torchmetrics.F1(num_classes=2, average=&#39;macro&#39;) def configure_optimizers(self): optim = torch.optim.Adam(self.parameters(), lr=self.lr) return optim def forward(self, input): sequences = input[&#39;sequence&#39;] # BxS embeds = self.embedding(sequences).permute(0, 2, 1) # BxSxH out_1 = self.filters[0](embeds) out_2 = self.filters[1](embeds) out_3 = self.filters[2](embeds) out = torch.cat((out_1, out_2, out_3), dim=2) out = self.conv_pool1(out) out = self.conv_pool2(out) out = self.flatten(out) out = self.linear1(out) out = F.relu(out) logit = self.linear2(out) return logit def training_step(self, batch, batch_idx): sentiments = batch[&#39;sentiment&#39;] logits = self.forward(batch) loss = F.cross_entropy(logits, sentiments) scores = F.softmax(logits, dim=-1) self.train_acc(scores, sentiments) self.log(&#39;train_loss&#39;, loss, on_step=True, on_epoch=True, prog_bar=True) self.log(&#39;train_acc&#39;, self.train_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True) return loss def validation_step(self, batch, batch_idx): # pylint: disable=unused-argument sentiments = batch[&#39;sentiment&#39;] logits = self.forward(batch) scores = F.softmax(logits, dim=-1) self.val_acc(scores, sentiments) self.val_f1(scores, sentiments) self.log(&#39;val_loss&#39;, loss, on_step=True, on_epoch=True, prog_bar=True) self.log(&#39;val_acc&#39;, self.val_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True) self.log(&#39;val_f1&#39;, self.val_f1, on_step=False, on_epoch=True, prog_bar=True, logger=True) def test_step(self, batch, batch_idx): # pylint: disable=unused-argument sentiments = batch[&#39;sentiment&#39;] logits = self.forward(batch) scores = F.softmax(logits, dim=-1) self.test_acc(scores, sentiments) self.test_f1(scores, sentiments) self.log(&#39;test_acc&#39;, self.test_acc, on_step=False, on_epoch=True, logger=True) self.log(&#39;test_f1&#39;, self.test_f1, on_step=False, on_epoch=True, logger=True) . nn.ModuleList does not have a forward() method because it does not define any neural network, that is, there is no connection between each of the nn.Module&#39;s that it stores. You may use it to store nn.Module&#39;s, just like you use Python lists to store other types of objects (integers, strings, etc). . The advantage of using nn.ModuleList instead of using conventional Python lists to store nn.Module&#39;s is that Pytorch is “aware” of the existence of the nn.Module&#39;s inside an nn.ModuleList, which is not the case for Python lists. When using a Python list instead of a nn.ModuleList, the optimizer() will raise the error saying that the model has no parameters. This is because PyTorch does not see the parameters of the layers stored in a Python list. If you use a nn.ModuleList instead, you’ll get no error. . Training . w2v_path = &quot;/content/drive/MyDrive/SLSOPS/pretrained_w2v/word2vec_vi_words_100dims.txt&quot; w2v_model = load_pretrained_word_embeddings(w2v_path) . train_path = &#39;/content/drive/MyDrive/SLSOPS/dataset/Aivivn_vietnamese_dataset/train.crash&#39; train_data = _load_data_from(train_path) . from spacy.lang.vi import Vietnamese nlp = Vietnamese() tokenizer = Tokenizer(nlp) # Build vocabulary build_vocab(tokenizer, [train_data[0]]) . import os import pickle # Create embedding matrix from pretrained w2v embedding_matrix = create_embedding_matrix(w2v_model, tokenizer.vocab, &quot;embedding_matrix.dat&quot;) . options = { &quot;on_gpu&quot;: True, &quot;batch_size&quot;: 16, &quot;num_workers&quot;: 2 } . datamodule = AIVIVN(tokenizer, options) . from pytorch_lightning.callbacks import ModelCheckpoint checkpoint_callback = ModelCheckpoint( monitor=&#39;val_acc&#39;, # save the model with the best validation accuracy dirpath=&#39;checkpoints&#39;, mode=&#39;max&#39;, ) # Set hyper-parameters lr = 1e-3 num_epochs = 20 l2reg = 1e-5 dropout = 0.0 trainer = pl.Trainer(gpus=1, max_epochs=num_epochs, callbacks=[checkpoint_callback], deterministic=True) # trainer = pl.Trainer(fast_dev_run=True, gpus=1) #Debug # trainer = pl.Trainer(overfit_batches=0.1, max_epochs=num_epochs, gpus=1) #Debug model = TextCNN(embedding_matrix, lr=lr, l2reg=l2reg, dropout=dropout) trainer.fit(model, datamodule) . GPU available: True, used: True TPU available: False, using: 0 TPU cores IPU available: False, using: 0 IPUs LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params 0 | embedding | Embedding | 1.2 M 1 | filters | ModuleList | 153 K 2 | conv_pool1 | ConvPool | 82.0 K 3 | conv_pool2 | ConvPool | 82.0 K 4 | flatten | Flatten | 0 5 | linear1 | Linear | 32.9 K 6 | linear2 | Linear | 258 7 | train_acc | Accuracy | 0 8 | val_acc | Accuracy | 0 9 | val_f1 | F1 | 0 351 K Trainable params 1.2 M Non-trainable params 1.6 M Total params 6.283 Total estimated model params size (MB) . Save model and tokenizer for inference . new_model = TextCNN.load_from_checkpoint(&#39;/content/checkpoints/epoch=1-step=1709.ckpt&#39;, embeddings=embedding_matrix) . trainer.test(my_model, datamodule.val_dataloader()) . /usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:424: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup. f&#34;DataModule.{name} has already been called, so it will not be called again. &#34; LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] . -- DATALOADER:0 TEST RESULTS {&#39;test_acc&#39;: 0.8881524205207825, &#39;test_f1&#39;: 0.8867566585540771} -- . /usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:424: LightningDeprecationWarning: DataModule.teardown has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.teardown. f&#34;DataModule.{name} has already been called, so it will not be called again. &#34; . [{&#39;test_acc&#39;: 0.8881524205207825, &#39;test_f1&#39;: 0.8867566585540771}] . import pickle with open(&#39;tokenizer.pkl&#39;, &#39;wb&#39;) as outp: pickle.dump(tokenizer, outp, pickle.HIGHEST_PROTOCOL) . torch.save(new_model, &quot;model&quot;) . Inference . To do the inference, we have to do 2 steps: . Loading model and the tokenizer. | Define the preprocessing function to preprocess the input before feeding into the model. | (Optional) Convert the predictions to labels. | import torch.nn.functional as F inputs = [&quot;:(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...&quot;, &quot;Chất lượng sản phẩm tuyệt vời nhưng k có hộp k có dây giày đen k có tất&quot;] # preprocess input def _preprocess_data_for_inference(sentences: List[str], tokenizer: Tokenizer): sequences = tokenizer.texts_to_sequences(sentences, tensor=True) # pad sequences sequences = torch.stack([F.pad(seq, (0, 557 - len(seq)), &#39;constant&#39;, 0) for seq in sequences]) return {&quot;sequence&quot;: sequences} input_data = _preprocess_data_for_inference(inputs, tokenizer) new_model.eval() predictions = new_model(input_data) . torch.argmax(predictions, axis=-1) . tensor([1, 0]) . train_df.iloc[3][&#39;text&#39;] . &#39;&#34;:(( Mình hơi thất vọng 1 chút vì mình đã kỳ vọng cuốn sách khá nhiều hi vọng nó sẽ nói về việc học tập của cách sinh viên trường Harvard ra sao những nỗ lực của họ như thế nào 4h sáng? tại sao họ lại phải thức dậy vào thời khắc đấy? sau đó là cả một câu chuyện ra sao. Cái mình thực sự cần ở đây là câu chuyện ẩn dấu trong đó để tự bản thân mỗi người cảm nhận và đi sâu vào lòng người hơn. Còn cuốn sách này chỉ đơn thuần là cuốn sách dạy kĩ năng mà hầu như sách nào cũng đã có. BUồn...&#34;&#39; . Debug . A = embedding_matrix[tokenizer.vocab.get_stoi()[&#39;ăn_nằm&#39;]] B = w2v_model[&quot;ăn_nằm&quot;] np.array_equal(A,B) . Lesson Learned . Make sure to check the train datamodule when debugging the model. | Don&#39;t just copy the code from previous code. Make sure to read through it before using to mitigate hard-to-see bugs. In this post, the bug lies in the way we load the pretrained word embeddings. | .",
            "url": "https://minhdang241.github.io/minhdg-blog/implementation/2021/08/17/NLP_10_Aivivn_Product_Review_Sentiment_Analysis.html",
            "relUrl": "/implementation/2021/08/17/NLP_10_Aivivn_Product_Review_Sentiment_Analysis.html",
            "date": " • Aug 17, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "Content based recommendation system for movies [Baby Version]",
            "content": "from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(&#34;/content/drive&#34;, force_remount=True). . Overview about recommendation system and its application . Recommendation system is popular nowadays. They are used to predict the &quot;rating&quot; or &quot;preference&quot; that users would give to an item. Those information can be used to provide users useful suggestions. For example, Amazon uses it to suggest products to customes, while Nexflix uses it to recommend videos based on user&#39;s favor. . Main types of recommendation system . Generally, there are three types of recommendation system: . Simple recommenders: provide recommendation based on items&#39; popularity or ratings. For example, the movies in IDMB top 250. | Content-based recommenders: suggest items based on other item properties. The system assumes that if a person likes a particular item, he or she will also like an item which is similar to it. For example, Netflix suggests new movies based on the user&#39;s history. | Collaborative filtering engines: predict the rating or preference that a user would give an item based on past ratings and preferences of other users. | In this post, we will build a content-based recommendation system for movies using the MovieLens Dataset. Since the dataset is large (26 miliion ratings and 750,000 tag applications), we only use a subset of it for fast development. . Load dataset . You can download the dataset here. . import pandas as pd metadata = pd.read_csv(&quot;/content/drive/MyDrive/Colab Notebooks/dataset/archive/movies_metadata.csv&quot;, low_memory=False) metadata.head(3) . adult belongs_to_collection budget genres homepage id imdb_id original_language original_title overview popularity poster_path production_companies production_countries release_date revenue runtime spoken_languages status tagline title video vote_average vote_count . 0 False | {&#39;id&#39;: 10194, &#39;name&#39;: &#39;Toy Story Collection&#39;, ... | 30000000 | [{&#39;id&#39;: 16, &#39;name&#39;: &#39;Animation&#39;}, {&#39;id&#39;: 35, &#39;... | http://toystory.disney.com/toy-story | 862 | tt0114709 | en | Toy Story | Led by Woody, Andy&#39;s toys live happily in his ... | 21.946943 | /rhIRbceoE9lR4veEXuwCC2wARtG.jpg | [{&#39;name&#39;: &#39;Pixar Animation Studios&#39;, &#39;id&#39;: 3}] | [{&#39;iso_3166_1&#39;: &#39;US&#39;, &#39;name&#39;: &#39;United States o... | 1995-10-30 | 373554033.0 | 81.0 | [{&#39;iso_639_1&#39;: &#39;en&#39;, &#39;name&#39;: &#39;English&#39;}] | Released | NaN | Toy Story | False | 7.7 | 5415.0 | . 1 False | NaN | 65000000 | [{&#39;id&#39;: 12, &#39;name&#39;: &#39;Adventure&#39;}, {&#39;id&#39;: 14, &#39;... | NaN | 8844 | tt0113497 | en | Jumanji | When siblings Judy and Peter discover an encha... | 17.015539 | /vzmL6fP7aPKNKPRTFnZmiUfciyV.jpg | [{&#39;name&#39;: &#39;TriStar Pictures&#39;, &#39;id&#39;: 559}, {&#39;na... | [{&#39;iso_3166_1&#39;: &#39;US&#39;, &#39;name&#39;: &#39;United States o... | 1995-12-15 | 262797249.0 | 104.0 | [{&#39;iso_639_1&#39;: &#39;en&#39;, &#39;name&#39;: &#39;English&#39;}, {&#39;iso... | Released | Roll the dice and unleash the excitement! | Jumanji | False | 6.9 | 2413.0 | . 2 False | {&#39;id&#39;: 119050, &#39;name&#39;: &#39;Grumpy Old Men Collect... | 0 | [{&#39;id&#39;: 10749, &#39;name&#39;: &#39;Romance&#39;}, {&#39;id&#39;: 35, ... | NaN | 15602 | tt0113228 | en | Grumpier Old Men | A family wedding reignites the ancient feud be... | 11.7129 | /6ksm1sjKMFLbO7UY2i6G1ju9SML.jpg | [{&#39;name&#39;: &#39;Warner Bros.&#39;, &#39;id&#39;: 6194}, {&#39;name&#39;... | [{&#39;iso_3166_1&#39;: &#39;US&#39;, &#39;name&#39;: &#39;United States o... | 1995-12-22 | 0.0 | 101.0 | [{&#39;iso_639_1&#39;: &#39;en&#39;, &#39;name&#39;: &#39;English&#39;}] | Released | Still Yelling. Still Fighting. Still Ready for... | Grumpier Old Men | False | 6.5 | 92.0 | . Our recommendation system will be based on the similarity between the movie overviews. Specifically, we will compute the pairwise cosine similarity scores for all movies and suggest the movies based on this score. . First of all, we have to transform the raw text to vector form sincewe cannot compute the similarity score directly from the raw text. In this post, we will compute the Term Frequency-Inverse Document Frequency (TF-IDF) vectors for each document. . from sklearn.feature_extraction.text import TfidfVectorizer # Create a TF-IDF object and remove all english stop words in the document # before producing vector representation tfidf = TfidfVectorizer(stop_words=&#39;english&#39;) . metadata[&#39;overview&#39;] = metadata[&#39;overview&#39;].fillna(&#39;&#39;) tfidf_matrix = tfidf.fit_transform(metadata[&#39;overview&#39;]) . tfidf_matrix.shape . (45466, 75827) . From the shape of the matrix we can see that the vector has length of 75827 and we have 45466 movie overview in total. . tfidf.get_feature_names()[5000:5010] . [&#39;avails&#39;, &#39;avaks&#39;, &#39;avalanche&#39;, &#39;avalanches&#39;, &#39;avallone&#39;, &#39;avalon&#39;, &#39;avant&#39;, &#39;avanthika&#39;, &#39;avanti&#39;, &#39;avaracious&#39;] . After generating vector for each movie overview, we can start computing the similarity score between them. There are many ways to do that besides cosine similarity, such as the manhantatan, euclidean, the Pearson, etc. There is no right or wrong answer to which score is the best. Different scores will work well in different situations. It is always encouraged to experiment with different metrics and choose the best. . from sklearn.metrics.pairwise import linear_kernel cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix) . cosine_sim.shape . (45466, 45466) . cosine_sim[1] . array([0.01504121, 1. , 0.04681953, ..., 0. , 0.02198641, 0.00929411]) . indices = pd.Series(metadata.index, index=metadata[&#39;title&#39;]).drop_duplicates() . def get_recommendations(title, cosine_sim=cosine_sim): idx = indices[title] sim_scores = list(enumerate(cosine_sim[idx])) sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True) sim_scores = sim_scores[1:11] movie_indices = [i[0] for i in sim_scores] return metadata[&#39;title&#39;].iloc[movie_indices] . get_recommendations(&#39;The Dark Knight Rises&#39;) . 45464 Satan Triumphant 45463 Betrayal 45462 Century of Birthing 45461 Subdue 45460 Robin Hood 45459 Caged Heat 3000 45458 The Burkittsville 7 45457 Shadow of the Blair Witch 45456 House of Horrors 45455 St. Michael Had a Rooster Name: title, dtype: object . get_recommendations(&#39;The Godfather&#39;) . 1178 The Godfather: Part II 44030 The Godfather Trilogy: 1972-1990 1914 The Godfather: Part III 23126 Blood Ties 11297 Household Saints 34717 Start Liquidation 10821 Election 38030 A Mother Should Be Loved 17729 Short Sharp Shock 26293 Beck 28 - Familjen Name: title, dtype: object . Discussion . Here we will discuss a bit the motivation behind TF-IDF . Term frequency Give a set of English text documents, we want to rank them by which document is more relevant to the query, for example, &quot;the excellent student&quot;. Firstly, we can simply filter out the documents that do not contain all 3 words - &quot;the&quot;, &quot;excellent&quot; and &quot;student&quot;. However, there are still many documents left. To further distinguish them, we might count the frequency of those 3 words in each document and rank them by corresponding frequencies. That frequency is called the term frequency. Since the length of the document may vary significantly, we often normalize the frequency of each word by the length of the document. . Inverse document frequency Some terms are more common than the other. For example, the term &quot;the&quot; is more popular than the word &quot;excellent&quot;. Term frequency tends to incorrectly emphasize documents which happen to use the word &quot;the&quot; more frequently, without giving enough weight to more meaningful terms such as &quot;excellent&quot; and &quot;student&quot;. Yet, the term &quot;the&quot; is not a good key word to distinguish the relevant and non-relevant documents. The inverse document frequency is used to diminished the weight of terms that occur very frequently in the document set and increases the weight of terms that occur rarely. .",
            "url": "https://minhdang241.github.io/minhdg-blog/implementation/2021/08/15/NLP_9_Content_Based_Recommendation_System_For_Movies_-Baby_Version.html",
            "relUrl": "/implementation/2021/08/15/NLP_9_Content_Based_Recommendation_System_For_Movies_-Baby_Version.html",
            "date": " • Aug 15, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "Text Processing & Labelling [Part2]",
            "content": "The full notebook is available here. . import pandas as pd pd.set_option(&#39;display.max_colwidth&#39;, None) # Set to display full-width dataframe . Labelling . df = pd.read_csv(&quot;preprocessed.csv&quot;) . You can download the dataset here. . filtered_df = df[df.lang == &quot;en&quot;] . Step 1: Segment Document into Sentences . We want to decrease the complexity when there are multiple sentences with different polarities in a doc. Therefore, instead of making prediction on a doc, we do for a sentence. . Note: This way also does not guarantee that we will not have a sentence with 2 conflict polarities. Yet, it reduces the proability of that situation. . def segment_review(df): reviews = list(df[&quot;review&quot;]) ratings = list(df[&quot;star_rating&quot;]) new_reviews = [] new_ratings = [] for i in range(len(reviews)): doc = nlp(reviews[i]) rating = ratings[i] for sent in doc.sents: new_reviews.append(str(sent)) new_ratings.append(rating) return new_reviews, new_ratings . doc_df = pd.DataFrame({&quot;review&quot;: filtered_df[&quot;lower_case&quot;], &quot;star_rating&quot;: filtered_df[&quot;star_rating&quot;]}) . df[&quot;star_rating&quot;].isnull().sum() . 0 . new_texts, new_ratings = segment_review(doc_df) . segmented_df = pd.DataFrame({&quot;review&quot;: new_texts, &quot;star_rating&quot;: new_ratings}) . print(&quot;Number of data after segmenting:&quot;, len(segmented_df)) . Number of data after segmenting: 35448 . segmented_df.to_csv(&quot;segmented_df.csv&quot;, index=False) . Step 2: Add labels using rating and pretrained-models&#39; predictions . label_df = segmented_df.copy(deep=True) . Rating Label . def rating2label(rating): if rating == 3: return &quot;Neutral&quot; elif rating &lt; 3: return &quot;Negative&quot; else: return &quot;Positive&quot; def score2label(score): if score == 1: return &quot;Positive&quot; else: return &quot;Negative&quot; . label_df[&quot;rating_label&quot;] = label_df[&quot;star_rating&quot;].apply(rating2label) . BERT Label . %%capture !pip install transformers . from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer def get_classifier(model_name, **kwargs): id2label = kwargs.get(&quot;id2label&quot;) if id2label: model = AutoModelForSequenceClassification.from_pretrained(model_name, id2label=id2label) else: model = AutoModelForSequenceClassification.from_pretrained(model_name) tokenizer = AutoTokenizer.from_pretrained(model_name) classifier = pipeline(&quot;text-classification&quot;, model=model, tokenizer=tokenizer) return classifier . Model 1: nlptown/bert-base-multilingual-uncased-sentimen . model_name = &quot;nlptown/bert-base-multilingual-uncased-sentiment&quot; classifier = get_classifer(model_name) . def get_prediction(text): rating = int(classifier(text)[0][&#39;label&#39;].split()[0]) return rating2label(rating) . label_df[&quot;nlptown_bert_label&quot;] = label_df[&#39;review&#39;].apply(get_prediction) . label_df.head() . label_df.to_csv(&quot;label_df.csv&quot;, index=False) . get_prediction(label_df[&#39;review&#39;][0]) . label_df[label_df[&quot;nlptown_bert_label&quot;] == &quot;Neutral&quot;][[&quot;review&quot;]] . Model 2: cardiffnlp/twitter-roberta-base-sentiment . from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer model_name = &quot;cardiffnlp/twitter-roberta-base-sentiment&quot; id2label = {0: &quot;Negative&quot;, 1: &quot;Neutral&quot;, 2: &quot;Positive&quot;} classifier = get_classifier(model_name, id2label=id2label) . {&#39;id2label&#39;: {0: &#39;Negative&#39;, 1: &#39;Neutral&#39;, 2: &#39;Positive&#39;}} . def get_prediction(text): return classifier(text)[0][&#39;label&#39;] . label_df[&quot;twitter-robert_label&quot;] = label_df[&#39;review&#39;].apply(get_prediction) . label_df.head() . review star_rating rating_label nlptown_bert_label twitter-robert_label . 0 i love my new laptop! | 5 | Positive | Positive | Positive | . 1 best computer i have ever own! | 5 | Positive | Positive | Positive | . 2 this computer forces me to be productive. | 5 | Positive | Positive | Positive | . 3 i used to wait around for this spinning wheel to stop, | 5 | Positive | Negative | Neutral | . 4 and now i can do everything so quickly | 5 | Positive | Positive | Positive | . label_df[&quot;review&quot;] = label_df[&quot;review&quot;].str.strip() . label_df.to_csv(&quot;label_df_full.csv&quot;, index=False) . Model 3: LSTM (Optional) . from allennlp.predictors.predictor import Predictor predictor = Predictor.from_path(&quot;https://storage.googleapis.com/allennlp-public-models/basic_stanford_sentiment_treebank-2020.06.09.tar.gz&quot;) lstm_label = list() for i, review in enumerate(new_df[&#39;review&#39;]): label = score2label(int(predictor.predict(review)[&#39;label&#39;])) lstm_label.append(label) . Plugin allennlp_models could not be loaded: No module named &#39;nltk.translate.meteor_score&#39; . label_df[&quot;LSTM_label&quot;] = lstm_label . Analyze labels and conflicts . %%capture !python -m pip install -U matplotlib # The code requires to use the lastest version of matplotlib . label_df = pd.read_csv(&quot;./label_df_full.csv&quot;) . import seaborn as sns def draw_bar_graph(data, title=None ,x_label=None, y_label=None): sns.set_theme(style=&quot;white&quot;) y_values = [float(v) for v in data.values()] ax = sns.barplot(x=list(data.keys()), y=y_values) ax.bar_label(ax.containers[0]) ax.set_ylim([0,max(y_values) + 2000]) ax.set_title(title, fontsize=16) ax.set_xlabel(x_label) ax.set_ylabel(y_label) . conflict_rating_nlptown = label_df[~(label_df[&#39;rating_label&#39;] == label_df[&#39;nlptown_bert_label&#39;])] . conflict_nlptown_roberta = list(label_df[~(label_df[&#39;twitter-robert_label&#39;] == label_df[&#39;nlptown_bert_label&#39;])][&#39;review&#39;]) . conflict_rating_roberta = list(label_df[~(label_df[&#39;twitter-robert_label&#39;] == label_df[&#39;rating_label&#39;])][&#39;review&#39;]) . conflicts = {&quot;rating-roberta&quot;: len(conflict_rating_roberta), &quot;rating-nlptown&quot;: len(conflict_rating_nlptown), &quot;nlptown-roberta&quot;: len(conflict_nlptown_roberta)} . draw_bar_graph(conflicts, title=&quot;Conflicts between labels&quot;, y_label=&quot;Number of samples&quot;) . non_neutral = conflict_rating_nlptown[conflict_rating_nlptown[&#39;nlptown_bert_label&#39;] != &quot;Neutral&quot;] character_exist = non_neutral[non_neutral[&#39;review&#39;].str.lower().str.islower()] len(character_exist) . 7344 . neutral = conflict_rating_nlptown[conflict_rating_nlptown[&#39;nlptown_bert_label&#39;] == &quot;Neutral&quot;] neutral_2_bert_conflict = neutral[neutral[&quot;nlptown_bert_label&quot;] != neutral[&quot;twitter-robert_label&quot;]] len(neutral_2_bert_conflict) . 2348 . review = [] rating_label = [] nlptown_bert_label = [] twitter_robert_label = [] review += list(character_exist[&quot;review&quot;]) + list(neutral_2_bert_conflict[&quot;review&quot;]) rating_label += list(character_exist[&quot;rating_label&quot;]) + list(neutral_2_bert_conflict[&quot;rating_label&quot;]) nlptown_bert_label += list(character_exist[&quot;nlptown_bert_label&quot;]) + list(neutral_2_bert_conflict[&quot;nlptown_bert_label&quot;]) twitter_robert_label += list(character_exist[&quot;twitter-robert_label&quot;]) + list(neutral_2_bert_conflict[&quot;twitter-robert_label&quot;]) . conflict = {&quot;review&quot;: review, &quot;rating_label&quot;: rating_label, &quot;nlptown_bert_label&quot;: nlptown_bert_label, &quot;twitter-bert_label&quot;: twitter_robert_label} . conflict_df = pd.DataFrame(conflict) . conflict_df.head() . review rating_label nlptown_bert_label twitter-bert_label . 0 i used to wait around for this spinning wheel to stop, | Positive | Negative | Neutral | . 1 ha ha. | Positive | Negative | Neutral | . 2 i do not have time to get coffee anymore. | Positive | Negative | Negative | . 3 i had an issue with my laptop. | Positive | Negative | Negative | . 4 the battery life drained fast | Positive | Negative | Negative | . conflict_df.to_csv(&quot;conflict_df.csv&quot;, index=False) . print(&quot;Total numbers of samples we need to label is: &quot;, len(conflict_df)) . Total numbers of samples we need to label is: 9692 . Label Rules . Accept the label if the rating_label, nlptown_bert_label both agree on the label. I don&#39;t take in to account the twitter-robert_label in this situation since it is trained using tweets, not product review, which is not reliable compared to the nlptown_bert_label. Because of the human resource, it is not always to produce the perfect label for the dataset. Yet, the dataset sill can be improved later using Active Learning. | Accept the Neutral label if both nlptown_bert_label and twitter-robert_label both agree on the label. The resonale for this is that when we do the sentence segmentation, some sentences from the positive/negative documents (labeled by star) have neutral sentiments, but still get labeled as positive or negative due to the rating_label. | Accept sample which review has alphabet characters. This rule will remove sample text such as &quot;4.&quot;, &quot;!&quot;, etc. | Distribution of labels in accepted data . accepted_df = label_df[label_df[&quot;rating_label&quot;] == label_df[&quot;nlptown_bert_label&quot;]] . num_neutral = len(accepted_df[accepted_df[&quot;rating_label&quot;] == &quot;Neutral&quot;]) num_positive = len(accepted_df[accepted_df[&quot;rating_label&quot;] == &quot;Positive&quot;]) num_negative = len(accepted_df[accepted_df[&quot;rating_label&quot;] == &quot;Negative&quot;]) . data = {&quot;Negative&quot;: num_negative, &quot;Neutral&quot;: num_neutral, &quot;Positive&quot;: num_positive} draw_bar_graph(data, title=&quot;Distribution of classes&quot;, x_label=&quot;Classes&quot;, y_label=&quot;Number of samples&quot;) . The dataset is unbalanced and the class has the least number of sample is Neutral, which is what we should expect. The reason is since we segment the doc to multiple sentences, there will be some sentences has neutral polarity but still get labeled as positive or negative due to the rating_label. . Upload to Lable Studio . def generate_import_json(text, labels): json_instance = {} json_instance[&#39;data&#39;] = {&quot;text&quot;: text} json_instance[&#39;annotations&#39;] = [] for label in labels: json_instance[&#39;annotations&#39;].append({ &quot;result&quot;: [ { &quot;type&quot;: &quot;choices&quot;, &quot;value&quot;: { &quot;choices&quot;: [label] }, &quot;to_name&quot;: &quot;text&quot;, &quot;from_name&quot;: &quot;sentiment&quot; } ] }) return json_instance . labeled_df = df.drop(conflict_df.index) . labeled_df.to_csv(&quot;labeled_df.csv&quot;, index=False) . relabeled_df = pd.read_csv(&quot;relabeled_data.csv&quot;) . relabeled_df[relabeled_df[&#39;annotation_id&#39;] &gt; 60000] . text id sentiment annotator annotation_id . 0 no es la mejor. | 521560 | Neutral | admin@slsops.gmail.com | 68106 | . 4 Ese es su único defecto, | 521559 | Neutral | admin@slsops.gmail.com | 68105 | . 8 3 horas en trabajo medio, con varios aplicativ... | 521558 | Neutral | admin@slsops.gmail.com | 68104 | . 12 This machine is NOT a touchscreen. | 521465 | Negative | admin@slsops.gmail.com | 68011 | . 16 Also when I try to use my audio interface in L... | 521453 | Neutral | admin@slsops.gmail.com | 67999 | . ... ... | ... | ... | ... | ... | . 672 Like: size, weight, screen picture, battery us... | 521395 | Positive | admin@slsops.gmail.com | 67941 | . 676 Almost too perfect. | 521394 | Positive | admin@slsops.gmail.com | 67940 | . 680 I don’t have time to get coffee anymore. | 521393 | Negative | admin@slsops.gmail.com | 67939 | . 684 Ha ha. | 521392 | Positive | admin@slsops.gmail.com | 67937 | . 688 I used to wait around for this spinning wheel ... | 521391 | Positive | admin@slsops.gmail.com | 67936 | . 173 rows × 5 columns . samples = [] rating_label = list(conflict_df[&#39;rating_label&#39;]) LSTM_label = list(conflict_df[&#39;LSTM_label&#39;]) distilbert_label = list(conflict_df[&#39;distilbert_label&#39;]) conflict_text = list(conflict_df[&#39;text&#39;]) for i in range(len(conflict_df)): samples.append(generate_import_json(conflict_text[i], [rating_label[i], LSTM_label[i], distilbert_label[i]])) . import requests def upload_2_labelstudio(samples, project_num): headers = {&#39;Content-Type&#39;: &#39;application/json&#39;, &#39;Authorization&#39;: &#39;Token 05f1e1540050e570826c2f6229b4a0a20bde2d1f&#39;} url = f&#39;https://label.slsops.athenka.com/api/projects/{project_num}/import&#39; r = requests.post(url, headers=headers, data=samples) print(r.text) . import json for i in range(0, len(conflict_df), 500): json_data = json.dumps(samples[i:i+500]) upload_2_labelstudio(json_data, 274) . sample_json = [ { &quot;data&quot;: { &quot;text&quot;: &quot;This is a test sentence&quot; }, &quot;annotations&quot;: [ { &quot;result&quot;: [ { &quot;type&quot;: &quot;choices&quot;, &quot;value&quot;: { &quot;choices&quot;: [&quot;Negative&quot;] }, &quot;to_name&quot;: &quot;text&quot;, &quot;from_name&quot;: &quot;sentiment&quot; } ] }, { &quot;result&quot;: [ { &quot;type&quot;: &quot;choices&quot;, &quot;value&quot;: { &quot;choices&quot;: [&quot;Neutral&quot;] }, &quot;to_name&quot;: &quot;text&quot;, &quot;from_name&quot;: &quot;sentiment&quot; } ] }, { &quot;result&quot;: [ { &quot;type&quot;: &quot;choices&quot;, &quot;value&quot;: { &quot;choices&quot;: [&quot;Positive&quot;] }, &quot;to_name&quot;: &quot;text&quot;, &quot;from_name&quot;: &quot;sentiment&quot; } ] } ] } ] .",
            "url": "https://minhdang241.github.io/minhdg-blog/implementation/2021/07/28/NLP_8_Text_Preprocessing_and_Labelling_-Part_2.html",
            "relUrl": "/implementation/2021/07/28/NLP_8_Text_Preprocessing_and_Labelling_-Part_2.html",
            "date": " • Jul 28, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "Text Processing & Labelling [Part1]",
            "content": "The full notebook is availabel here. . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(&#34;/content/drive&#34;, force_remount=True). . %%capture !pip install transformers !pip install emoji !pip install Unidecode !pip install contractions !pip install word2number !python -m spacy download en_core_web_md !pip install spacy-langdetect . Load Dataset . df = pd.read_csv(&quot;/content/drive/MyDrive/Colab Notebooks/Text Classification/Pipeline/datasets.csv&quot;) . df.dropna(inplace=True) # drop row(s) containing &quot;nan&quot; value . For those who want to reproduce the note book, you can get the data from here. . import re import string from itertools import groupby import contractions import emoji import unidecode from bs4 import BeautifulSoup from spacy_langdetect import LanguageDetector from word2number import w2n . import spacy nlp = spacy.load(&#39;en_core_web_md&#39;) . import pandas as pd pd.set_option(&#39;display.max_colwidth&#39;, None) # Set to display full-width dataframe . Preprocess data . Step 1: Remove HTML Tags . HTLM tags does not add any useful information for understanding and analyzing text, so we remove it. . def remove_html_tags(text): soup = BeautifulSoup(text, &quot;html.parser&quot;) stripped_text = soup.get_text() return stripped_text . df[&quot;no_html&quot;] = df[&quot;review&quot;].apply(remove_html_tags) . df[df[&quot;no_html&quot;] != df[&quot;review&quot;]][100:120] . comment_id review star_rating no_html . 8897 255542 | The colors are super vibrant &amp;amp; unique. I was unable to find colors like this in multiple stores I visited, let alone find both a left &amp;amp; right controller together so this was definitely a win-win. | 5 | The colors are super vibrant &amp; unique. I was unable to find colors like this in multiple stores I visited, let alone find both a left &amp; right controller together so this was definitely a win-win. | . 8955 255550 | I received my Neon Pink &amp;amp; Neon Green Joy Cons yesterday and I&#39;m amazed at how vibrant and colorful this particular set is! These 2 colors compliment each other perfectly, too! 5/5 Stars! Good packaging, prompt next-day delivery as a Prime Member. | 5 | I received my Neon Pink &amp; Neon Green Joy Cons yesterday and I&#39;m amazed at how vibrant and colorful this particular set is! These 2 colors compliment each other perfectly, too! 5/5 Stars! Good packaging, prompt next-day delivery as a Prime Member. | . 9216 255962 | Love my Switch &amp;amp; these are fun colors | 5 | Love my Switch &amp; these are fun colors | . 9293 256306 | &amp;lt;3 | 5 | &lt;3 | . 9466 255331 | Perfect pair of new joycons I&#39;m using for a shell &amp;amp; button mod swap. | 5 | Perfect pair of new joycons I&#39;m using for a shell &amp; button mod swap. | . 10566 257919 | Works &amp;amp; bright colors! | 5 | Works &amp; bright colors! | . 10717 258185 | Although we do enjoy the new features that Switch have over Wii:* Does not require sensor bar* Portable - able to play on-the-go with build-in console batteryThere are few limitations that we were not aware prior to purchase:* Joy Con battery not removable. (Since rechargeable batteries have limited life, customers will need to purchase new controllers every 1-2 years depending on amount of use)* Joy Con controller size are small for adults including the joystick &amp;amp; buttons* Gel-Con Guards need to be removed when switching to Wheel adopter* Hand Strap need to removed in order to place on charger | 3 | Although we do enjoy the new features that Switch have over Wii:* Does not require sensor bar* Portable - able to play on-the-go with build-in console batteryThere are few limitations that we were not aware prior to purchase:* Joy Con battery not removable. (Since rechargeable batteries have limited life, customers will need to purchase new controllers every 1-2 years depending on amount of use)* Joy Con controller size are small for adults including the joystick &amp; buttons* Gel-Con Guards need to be removed when switching to Wheel adopter* Hand Strap need to removed in order to place on charger | . 10737 258240 | After a few months of use, without dropping them, nothing smeared on them, and just playing Smash Bros Ultimate, one of the sticks on a Joy-con is starting to wear down. I can&#39;t make it respond to sudden movements or flicking. My left stick, in particular, is now drifting. I tried calibrating the controls, and it&#39;s fine, but it did nothing to fix the issue.I looked up on means to fix this, and it requires the risk of ruining your controller further by taking it apart to replace the stick with a new one (or at least adjust the current one). Even then, it does not take long for the drifting to come back.It&#39;s entirely possible I got unlucky and received a bad pair with my Switch, but it doesn&#39;t change the fact that something like this occurred so soon for something so expensive. I really want to enjoy my games on-the-go more often than at home, but it&#39;s not going to happen the way the design is flawed.Even the Pro-Controller is having the same issue... so now I&#39;m hesitant to buy any Nintendo-licensed controller... and it doesn&#39;t help that the warranty for these controllers are so short. Terrific. Thanks for nothing, Nintendo.&amp;gt;.&amp;gt; | 2 | After a few months of use, without dropping them, nothing smeared on them, and just playing Smash Bros Ultimate, one of the sticks on a Joy-con is starting to wear down. I can&#39;t make it respond to sudden movements or flicking. My left stick, in particular, is now drifting. I tried calibrating the controls, and it&#39;s fine, but it did nothing to fix the issue.I looked up on means to fix this, and it requires the risk of ruining your controller further by taking it apart to replace the stick with a new one (or at least adjust the current one). Even then, it does not take long for the drifting to come back.It&#39;s entirely possible I got unlucky and received a bad pair with my Switch, but it doesn&#39;t change the fact that something like this occurred so soon for something so expensive. I really want to enjoy my games on-the-go more often than at home, but it&#39;s not going to happen the way the design is flawed.Even the Pro-Controller is having the same issue... so now I&#39;m hesitant to buy any Nintendo-licensed controller... and it doesn&#39;t help that the warranty for these controllers are so short. Terrific. Thanks for nothing, Nintendo.&gt;.&gt; | . 10748 258269 | I for one actually really like Joy Cons, they’re a very unique controller &amp;amp; can work together as one or just use a single joy con as one controller, these purple &amp;amp; neon orange combo is extraordinary! The Purple would sometimes look more like a Hot pink (depending when light hits it) and the neon orange would look more like a summer yellow (same reason; lighting) but they actually are a great combo and if you have other types of color joy cons, you can mixed them up &amp;amp; create your own colorful creation! | 5 | I for one actually really like Joy Cons, they’re a very unique controller &amp; can work together as one or just use a single joy con as one controller, these purple &amp; neon orange combo is extraordinary! The Purple would sometimes look more like a Hot pink (depending when light hits it) and the neon orange would look more like a summer yellow (same reason; lighting) but they actually are a great combo and if you have other types of color joy cons, you can mixed them up &amp; create your own colorful creation! | . 10866 258366 | I bought this for my daughter for Christmas. She had several people over &amp;amp; they all enjoyed using the new controllers. | 5 | I bought this for my daughter for Christmas. She had several people over &amp; they all enjoyed using the new controllers. | . 10892 258431 | Colors are vibrant &amp;amp; they work great (as expected lol)! Very fun purchase! We accidentally yeeted one of them across the living room playing a Mario party mini game and it actually still works LOL The stick is a little wonky but overall impressed that it even survived! 10/10 will buy more colors! | 5 | Colors are vibrant &amp; they work great (as expected lol)! Very fun purchase! We accidentally yeeted one of them across the living room playing a Mario party mini game and it actually still works LOL The stick is a little wonky but overall impressed that it even survived! 10/10 will buy more colors! | . 11561 257944 | They hold a super long charge and the pink &amp;amp; green fill me with nostalgia for the fairly odd parents (my SHOW as a kid). | 5 | They hold a super long charge and the pink &amp; green fill me with nostalgia for the fairly odd parents (my SHOW as a kid). | . 11667 258509 | They are cute &amp;amp; i love the colors 💜 | 5 | They are cute &amp; i love the colors 💜 | . 11720 258580 | My child is soooo happy to have new working controllers! The shipping was quick &amp;amp; on time for his birthday last month. | 5 | My child is soooo happy to have new working controllers! The shipping was quick &amp; on time for his birthday last month. | . 11825 258629 | Perfect finial addition to me now owning every single pair of joycons (- grey colour as to bland for me) from the UK, Japan &amp;amp; Also the US 😀 very speedy international delivery &amp;amp; arrived perfect so thank you 5* | 0 | Perfect finial addition to me now owning every single pair of joycons (- grey colour as to bland for me) from the UK, Japan &amp; Also the US 😀 very speedy international delivery &amp; arrived perfect so thank you 5* | . 11842 258645 | Estoy en mi trabajo, y resulta que ya me entregaron el paquete y para colmo tienen el descaro de poner que la persona que recogió el paquete fui yo. TIENEN MI NUMERO DE TELÉFONO, MI DIRECCIÓN &amp;amp; SE ATREVEN A ENTREGARLE EL PRODUCTO A ALGUIEN QUE EN PRIMER LUGAR SE ENCUENTRA FUERA DE LA PROPIEDAD, YA QUE EN LA MISMA HAY REJAS A LO CUAL NADIE PUEDE ENTRAR, QUE ASCO CON EL SERVICIO DE PAQUETERIA. Sigo a la espera de llamada..... | 0 | Estoy en mi trabajo, y resulta que ya me entregaron el paquete y para colmo tienen el descaro de poner que la persona que recogió el paquete fui yo. TIENEN MI NUMERO DE TELÉFONO, MI DIRECCIÓN &amp; SE ATREVEN A ENTREGARLE EL PRODUCTO A ALGUIEN QUE EN PRIMER LUGAR SE ENCUENTRA FUERA DE LA PROPIEDAD, YA QUE EN LA MISMA HAY REJAS A LO CUAL NADIE PUEDE ENTRAR, QUE ASCO CON EL SERVICIO DE PAQUETERIA. Sigo a la espera de llamada..... | . 11879 253884 | I bought these used for a custom mod, so I only needed the internals. Before taking them apart they seemed to work normally. Post mod they still work normally. It is worth noting however that the shells had scuffs &amp;amp; a few distinct scratches. I recommend just buying new ones if you are using them as is. If you are looking to save a few bucks on a custom controller mod &amp;amp; only need the internal parts then these work. It is worth noting that the sticks did not seem to have any drifting issues either. | 4 | I bought these used for a custom mod, so I only needed the internals. Before taking them apart they seemed to work normally. Post mod they still work normally. It is worth noting however that the shells had scuffs &amp; a few distinct scratches. I recommend just buying new ones if you are using them as is. If you are looking to save a few bucks on a custom controller mod &amp; only need the internal parts then these work. It is worth noting that the sticks did not seem to have any drifting issues either. | . 11961 254562 | When I bought this product used, all of the buttons worked on both joycons minus the L &amp;amp; R button. I opened them up and saw that the button on the motherboard was not attached but next to where it should have been. Also, the left joycon joystick looks like a toddler chewed on it. I guess that’s what I get for trying to buy used joycons? | 3 | When I bought this product used, all of the buttons worked on both joycons minus the L &amp; R button. I opened them up and saw that the button on the motherboard was not attached but next to where it should have been. Also, the left joycon joystick looks like a toddler chewed on it. I guess that’s what I get for trying to buy used joycons? | . 11968 254892 | This is our 4th set of Nintendo Switch Joy-Cons. They’re great fun &amp;amp; just as expected, BUT the left one wears out so quickly. And we don’t play video games all the time like some people. For such a high price, Nintendo really should do better. | 3 | This is our 4th set of Nintendo Switch Joy-Cons. They’re great fun &amp; just as expected, BUT the left one wears out so quickly. And we don’t play video games all the time like some people. For such a high price, Nintendo really should do better. | . 12031 256532 | The left one gets stuck &amp;amp; drifts! Just bought a few months ago this shouldn’t happen!! So disappointed | 1 | The left one gets stuck &amp; drifts! Just bought a few months ago this shouldn’t happen!! So disappointed | . One notice from the example above is that the BeautifulSoup function convert &amp;amp; to $. In general, the function tries to convert decode the HTML Character Entities. . Step 2: Remove redundant elements . def remove_redundant_elements(text): # remove urls text = re.sub(r&quot;http S+&quot;, &quot; &quot;, text) # remove phone text = re.sub(r&quot;[ +]?[(]?[0-9]{3}[)]?[- s .]?[0-9]{3}[- s .]?[0-9]{4,6}&quot;, &quot; &quot;, text) # remove email text = re.sub(r&quot;[ w.+-]+@[ w-]+ .[ w.-]+&quot;, &quot; &quot;, text) # remove newline table = str.maketrans(&quot; n t r&quot;, &quot; &quot;) text = text.translate(table) # remove redundant whitespaces text = &quot; &quot;.join(text.split()) # # remove punctuations # table_ = str.maketrans(string.punctuation, &quot; &quot; * len(string.punctuation)) # comment = &quot; &quot;.join(comment.translate(table_).split()) return text . df[&quot;no_redundant&quot;] = df[&quot;no_html&quot;].apply(remove_redundant_elements) . df[df[&quot;no_redundant&quot;] != df[&quot;no_html&quot;]][[&quot;no_html&quot;, &quot;no_redundant&quot;]] . no_html no_redundant . 1950 I am overall satisfied with the laptop. It&#39;s fast, works great, and didn&#39;t have any trouble setting up. I&#39;ve got to admit, it was hard switching from Windows to IOS, but that was on my part. I was loving it until I really started seeing some changes...It was only, what? Two days in? I unplugged my laptop because I left my room to do assignments in my sister&#39;s room, and less than an hour later my laptop went from 100 to 89. I wasn&#39;t even using any &quot;THIS NEEDS POWER&quot; apps. I had all the energy saver settings on, and my brightness was low as well. Also, (please read the whole thing because I&#39;m not sure if it&#39;s me or the laptop) I had problems with the temperature. It was overheating. I would always hear the fan on at times that were so unnecessary.I&#39;ll admit, high-graphic games were played, but after I stopped playing those games, the fan was still moving like someone trying to find a bathroom in Taco Bell. And, it was LOUD, like enough to wake up a &#39;tarantula&#39; loud (of course not THAT loud, but it sounded like I was using a 2010 desktop Windows 7 Vista CPU). I have a laptop stand, but it has holes. Could that still factor in my circulation issues? I mean, there aren&#39;t any ventilation holes on the bottom, right? RIGHT?That&#39;s the laptop stand. It says it has heat vents, and in the picture, it shows a Macbook:https://www.amazon.com/Adjustable-Aluminum-Multi-Angle-Heat-Vent-Compatible/dp/B088DB45HG/ref=pd_ybh_a_219?_encoding=UTF8&amp;psc=1&amp;refRID=R8VBZ111SHQCQCPPHJSX | I am overall satisfied with the laptop. It&#39;s fast, works great, and didn&#39;t have any trouble setting up. I&#39;ve got to admit, it was hard switching from Windows to IOS, but that was on my part. I was loving it until I really started seeing some changes...It was only, what? Two days in? I unplugged my laptop because I left my room to do assignments in my sister&#39;s room, and less than an hour later my laptop went from 100 to 89. I wasn&#39;t even using any &quot;THIS NEEDS POWER&quot; apps. I had all the energy saver settings on, and my brightness was low as well. Also, (please read the whole thing because I&#39;m not sure if it&#39;s me or the laptop) I had problems with the temperature. It was overheating. I would always hear the fan on at times that were so unnecessary.I&#39;ll admit, high-graphic games were played, but after I stopped playing those games, the fan was still moving like someone trying to find a bathroom in Taco Bell. And, it was LOUD, like enough to wake up a &#39;tarantula&#39; loud (of course not THAT loud, but it sounded like I was using a 2010 desktop Windows 7 Vista CPU). I have a laptop stand, but it has holes. Could that still factor in my circulation issues? I mean, there aren&#39;t any ventilation holes on the bottom, right? RIGHT?That&#39;s the laptop stand. It says it has heat vents, and in the picture, it shows a Macbook: | . 4248 Essa review do Switch Lite está fragmentada em duas partes, software e hardware.Começando pelo aspecto de hardware, é seguro dizer que a Nvidia fez um trabalho muito melhor do que a Nintendo: O SoC Tegra é capaz de entregar jogos antigos de PC (2013 em diante) para o handheld sem screen tearing, sem frame drops, e com uma boa duração de bateria (no máximo 3 horas, dependendo do jogo).Porém, a Nintendo me desapontou: embora os face buttons (X, Y, A B) sejam macios de apertar, a pressa da empresa em lançar logo o Switch Lite afim de aproveitar o hype que o tradicional Switch gerou culminou em sticks com qualidade duvidosa sendo implementados na versão final do produto. Uma vez que o seu stick esteja &quot;funcionando sozinho&quot;, isso vai sempre te perseguir até que você resolva o problema: ou envie para um representante da Nintendo no exterior para consertar, o que pode levar até semanas, ou você resolve o problema sozinho - e é aí que você se depara com uma outra limitação imposta pela Nintendo, as tri-wing screws (parafusos de três pontas) que a empresa implementou propositalmente para evitar que seus clientes sejam capazes de fazer a manutenção do Switch Lite. Lamentável.Em termos de software: até a geração passada da Nintendo (WiiU) o senso comum ditava que a audiência da empresa sempre foram os pequenos até os adolescentes. Com o Switch, a Nintendo quer mudar essa idéia e abraçar todos os públicos. Mas os desenvolvedores ainda não engoliram essa, principalmente porque lançaram seus jogos nas plataformas anteriores da Nintendo e se arrependeram amargamente, devido às míseras vendas de seus jogos. É por isso que desenvolvedores como Rockstar, Activision, EA, dentre outros não lançam jogos considerados &#39;Mature&#39; na plataforma. Depois de quase três anos de mercado, o Switch ainda vive o momento em que essas desenvolvedoras ficam esperando ver quem dá o primeiro passo. Se for feito com sucesso e a lucratividade compensar, as outras seguem. Nesse período de indecisão, a comunidade Switch ainda debate &quot;onde está GTA V para o Switch?&quot;, &quot;Cadê o port de Red Dead Redemption?&quot;, &quot;por quê ainda não temos Tomb Raider ou Deus EX no Switch?&quot;, entre outras reivindicações. Os jogos &quot;first-party&quot; nada mais são do que ports do WiiU cujos preços são absurdamente caros. Para se ter uma idéia, Donkey Kong Tropical Freeze, um jogo do WiiU com mais de cinco anos de existência, é cobrado por 60 Dólares. Tudo bem, o jogo é bonito, porém velho demais e caro demais. E essa tem sido a filosofia da empresa, se for first-party, cobre o máximo. Diferente da competidora Sony, onde até mesmo jogos first-party como God of War é descontado mais da metade em promoções na PS Store, a Nintendo quer sempre cobrar o máximo, descontando seus jogos em 33% de vez em nunca na Nintendo eShop. Esse desconto é seletivo (não valem para todos os jogos da empresa). Além disso, falando na eShop, você sempre compra um jogo &#39;no escuro&#39;: sem uma demo, sem review para você ter uma idéia se o jogo é bom ou não antes de comprar. Então supomos que você compre o jogo mesmo assim. Se arrependeu? Azar o seu, a Nintendo não permite refunds (retorno do software e o seu dinheiro de volta). Um absurdo. E como as leis vigentes brasileiras são mais feitas pra te ferrar do que pra te ajudar, é melhor você procurar um vídeo de um gameplay no Youtube antes de efetuar a sua compra. Você foi avisado.Por fim, eu tenho mais de 340 horas com o meu Switch Lite. Me arrependo de ter comprado o handheld com um preço tão salgado, confesso que deveria ter esperado mais um ano, quem sabe até lá o Switch Lite teria um preço menos abusivo e jogos mais atrativos. Não sou fã de Mario e toda aquela corja &quot;fofinha demais e caro demais&quot; da Nintendo. Admitidamente, se o projeto Smach Z (Kickstarter) tivesse entregado um produto digno da espera, não teria sequer passado perto do Nintendo Switch. E tem mais: se você curte apenas jogos em 2D ou então no estilo dos da Gameloft, teu celular vai ter dar uma experiência melhor do que o Nintendo Switch Lite, supondo que você tenha um controle Bluetooth e um celular com uma configuração respeitável e com mais de 2000mAh de bateria. O único quesito que o Switch Lite ganha é que é apenas uma única configuração de hardware, portanto os desenvolvedores oferecem o suporte aos seus jogos de maneira que rodem de forma suave e compatível, coisa que não se vê muito em jogos Android em 2020.Adicionalmente, se o seu Switch Lite for teu hardware principal para jogos, ele vai ficar bastante judiado.Você vai precisar de um case, uma skin e um grip. Eu recomendo essa solução três-em-um da Skull &amp; Co:https://www.amazon.com/gp/product/B082B56D2H/ref=ppx_yo_dt_b_asin_title_o00_s00?ie=UTF8&amp;psc=1Um screen protector para evitar arranhões na tela:https://www.amazon.com/gp/product/B07QNRB34L/ref=ppx_yo_dt_b_asin_title_o03_s01?ie=UTF8&amp;psc=1E por fim, um cartão de memória. Dependendo se você for um colecionador, a memória interna talvez seja o suficiente. Caso contrário, um cartão de 200GB da SanDisk deve bastar para o seu primeiro ano com o Switch Lite:https://www.amazon.com/gp/product/B073JY5T7T/ref=ppx_yo_dt_b_asin_title_o03_s00?ie=UTF8&amp;psc=1 | Essa review do Switch Lite está fragmentada em duas partes, software e hardware.Começando pelo aspecto de hardware, é seguro dizer que a Nvidia fez um trabalho muito melhor do que a Nintendo: O SoC Tegra é capaz de entregar jogos antigos de PC (2013 em diante) para o handheld sem screen tearing, sem frame drops, e com uma boa duração de bateria (no máximo 3 horas, dependendo do jogo).Porém, a Nintendo me desapontou: embora os face buttons (X, Y, A B) sejam macios de apertar, a pressa da empresa em lançar logo o Switch Lite afim de aproveitar o hype que o tradicional Switch gerou culminou em sticks com qualidade duvidosa sendo implementados na versão final do produto. Uma vez que o seu stick esteja &quot;funcionando sozinho&quot;, isso vai sempre te perseguir até que você resolva o problema: ou envie para um representante da Nintendo no exterior para consertar, o que pode levar até semanas, ou você resolve o problema sozinho - e é aí que você se depara com uma outra limitação imposta pela Nintendo, as tri-wing screws (parafusos de três pontas) que a empresa implementou propositalmente para evitar que seus clientes sejam capazes de fazer a manutenção do Switch Lite. Lamentável.Em termos de software: até a geração passada da Nintendo (WiiU) o senso comum ditava que a audiência da empresa sempre foram os pequenos até os adolescentes. Com o Switch, a Nintendo quer mudar essa idéia e abraçar todos os públicos. Mas os desenvolvedores ainda não engoliram essa, principalmente porque lançaram seus jogos nas plataformas anteriores da Nintendo e se arrependeram amargamente, devido às míseras vendas de seus jogos. É por isso que desenvolvedores como Rockstar, Activision, EA, dentre outros não lançam jogos considerados &#39;Mature&#39; na plataforma. Depois de quase três anos de mercado, o Switch ainda vive o momento em que essas desenvolvedoras ficam esperando ver quem dá o primeiro passo. Se for feito com sucesso e a lucratividade compensar, as outras seguem. Nesse período de indecisão, a comunidade Switch ainda debate &quot;onde está GTA V para o Switch?&quot;, &quot;Cadê o port de Red Dead Redemption?&quot;, &quot;por quê ainda não temos Tomb Raider ou Deus EX no Switch?&quot;, entre outras reivindicações. Os jogos &quot;first-party&quot; nada mais são do que ports do WiiU cujos preços são absurdamente caros. Para se ter uma idéia, Donkey Kong Tropical Freeze, um jogo do WiiU com mais de cinco anos de existência, é cobrado por 60 Dólares. Tudo bem, o jogo é bonito, porém velho demais e caro demais. E essa tem sido a filosofia da empresa, se for first-party, cobre o máximo. Diferente da competidora Sony, onde até mesmo jogos first-party como God of War é descontado mais da metade em promoções na PS Store, a Nintendo quer sempre cobrar o máximo, descontando seus jogos em 33% de vez em nunca na Nintendo eShop. Esse desconto é seletivo (não valem para todos os jogos da empresa). Além disso, falando na eShop, você sempre compra um jogo &#39;no escuro&#39;: sem uma demo, sem review para você ter uma idéia se o jogo é bom ou não antes de comprar. Então supomos que você compre o jogo mesmo assim. Se arrependeu? Azar o seu, a Nintendo não permite refunds (retorno do software e o seu dinheiro de volta). Um absurdo. E como as leis vigentes brasileiras são mais feitas pra te ferrar do que pra te ajudar, é melhor você procurar um vídeo de um gameplay no Youtube antes de efetuar a sua compra. Você foi avisado.Por fim, eu tenho mais de 340 horas com o meu Switch Lite. Me arrependo de ter comprado o handheld com um preço tão salgado, confesso que deveria ter esperado mais um ano, quem sabe até lá o Switch Lite teria um preço menos abusivo e jogos mais atrativos. Não sou fã de Mario e toda aquela corja &quot;fofinha demais e caro demais&quot; da Nintendo. Admitidamente, se o projeto Smach Z (Kickstarter) tivesse entregado um produto digno da espera, não teria sequer passado perto do Nintendo Switch. E tem mais: se você curte apenas jogos em 2D ou então no estilo dos da Gameloft, teu celular vai ter dar uma experiência melhor do que o Nintendo Switch Lite, supondo que você tenha um controle Bluetooth e um celular com uma configuração respeitável e com mais de 2000mAh de bateria. O único quesito que o Switch Lite ganha é que é apenas uma única configuração de hardware, portanto os desenvolvedores oferecem o suporte aos seus jogos de maneira que rodem de forma suave e compatível, coisa que não se vê muito em jogos Android em 2020.Adicionalmente, se o seu Switch Lite for teu hardware principal para jogos, ele vai ficar bastante judiado.Você vai precisar de um case, uma skin e um grip. Eu recomendo essa solução três-em-um da Skull &amp; Co: screen protector para evitar arranhões na tela: por fim, um cartão de memória. Dependendo se você for um colecionador, a memória interna talvez seja o suficiente. Caso contrário, um cartão de 200GB da SanDisk deve bastar para o seu primeiro ano com o Switch Lite: | . 5503 Button on left as in picture broke too easily please send new one to my niece. Jennifer Canady We spent $200 for this in June.... and we will send old one back (include return shipping label) please call Deborah 512-809-5934 or Sandra niece (512) 944-2592thank you | Button on left as in picture broke too easily please send new one to my niece. Jennifer Canady We spent $200 for this in June.... and we will send old one back (include return shipping label) please call Deborah or Sandra niece thank you | . 12295 Please warranty my joy-con Left-side doesn’t charge! New email is huitang2009@hotmail.com. I bought it 2/12 2018!! Only use couple times! Sent me warranty one so I can sent you back the broken one!!!!! | Please warranty my joy-con Left-side doesn’t charge! New email is I bought it 2/12 2018!! Only use couple times! Sent me warranty one so I can sent you back the broken one!!!!! | . Step 3: Remove emoji . def remove_emoji(text): return emoji.get_emoji_regexp().sub(r&quot; &quot;, text) . df[&quot;no_emoji&quot;] = df[&quot;no_redundant&quot;].apply(remove_emoji) . df[df[&quot;no_redundant&quot;] != df[&quot;no_emoji&quot;]][[&quot;no_redundant&quot;, &quot;no_emoji&quot;]] . no_redundant no_emoji . 19 I have been using my renewed computer 👩🏾‍💻 for about 2 weeks now and I am so glad I bought it from “All-out-Apple” the best computer seller on Amazon! I received the 2018 MacBook Air i5 quad core 256gb and the actual specs matched the description! I use it for college for my Zoom classes and the virtual background works!! I upgraded from my 2013 MacBook Air and this one is a lot faster and a much better battery life. It also came with a brand new usb-c original Apple charger for this Mac. This computer is like-new with no scratches at all and I was able to transfer all my old data to this new computer. I would recommend this computer for students and teachers too. | I have been using my renewed computer for about 2 weeks now and I am so glad I bought it from “All-out-Apple” the best computer seller on Amazon! I received the 2018 MacBook Air i5 quad core 256gb and the actual specs matched the description! I use it for college for my Zoom classes and the virtual background works!! I upgraded from my 2013 MacBook Air and this one is a lot faster and a much better battery life. It also came with a brand new usb-c original Apple charger for this Mac. This computer is like-new with no scratches at all and I was able to transfer all my old data to this new computer. I would recommend this computer for students and teachers too. | . 239 Great purchase! Worth every penny. And the color is gorgeous 😍 | Great purchase! Worth every penny. And the color is gorgeous | . 363 I spent a lot of time debating on purchasing brand new or renewed off amazon. I ended up going the cheaper route and went with the amazon renewed one. The product came in a plain brown box, but was wrapped like it was brand new. There are no marks or dents on mine, and it acts like a brand new computer!! I am obsessed with it!!! Best purchase I’ve made all year. Seriously, great bang for your buck! 😁 | I spent a lot of time debating on purchasing brand new or renewed off amazon. I ended up going the cheaper route and went with the amazon renewed one. The product came in a plain brown box, but was wrapped like it was brand new. There are no marks or dents on mine, and it acts like a brand new computer!! I am obsessed with it!!! Best purchase I’ve made all year. Seriously, great bang for your buck! | . 475 I&#39;m happy with product. Is apple 🍎 there&#39;s not much to say. there product are great. I&#39;m a prime member. I received it 2 days later. My daughter needed for school on line | I&#39;m happy with product. Is apple there&#39;s not much to say. there product are great. I&#39;m a prime member. I received it 2 days later. My daughter needed for school on line | . 527 I’m in love with my new Mac book very easy to use and set up. I Definitely recommend it great purchase that I did 👌😁 | I’m in love with my new Mac book very easy to use and set up. I Definitely recommend it great purchase that I did | . ... ... | ... | . 11874 Arrived broken, you can see in the one pic how it came, when my husband took it out of the plastic he said this isn’t right. The black part was completely unattached to the red main part. Upon inspection, because my husband can fix anything...it looks like someone just ripped it off the main part of the controller. It’s missing one screw and the other was ripped out with the red con plastic still on it. It’s beyond repair 😒. How did it pass inspection?! | Arrived broken, you can see in the one pic how it came, when my husband took it out of the plastic he said this isn’t right. The black part was completely unattached to the red main part. Upon inspection, because my husband can fix anything...it looks like someone just ripped it off the main part of the controller. It’s missing one screw and the other was ripped out with the red con plastic still on it. It’s beyond repair . How did it pass inspection?! | . 11894 Had original gray Joy-Cons when I got my Switch and had the dreaded analog drift. It was time I purchased official Nintendo (pricey) Joy-Cons...and always thought this Neon Purple/Orange was eye-catching and lemme tell you...once you see them in person, they&#39;re beautiful.All the buttons feel a notch up more stable and comfortable to the input. Drift is no longer an issue and I was super satisfied with these Joy-Cons. My Switch never looked better. 😉 | Had original gray Joy-Cons when I got my Switch and had the dreaded analog drift. It was time I purchased official Nintendo (pricey) Joy-Cons...and always thought this Neon Purple/Orange was eye-catching and lemme tell you...once you see them in person, they&#39;re beautiful.All the buttons feel a notch up more stable and comfortable to the input. Drift is no longer an issue and I was super satisfied with these Joy-Cons. My Switch never looked better. | . 11934 Only giving it one star because they worked great for about 2 days then the right controller started doing exactly the same thing our left controller did. We bought these to replace our original ones but they’re the same 😒 | Only giving it one star because they worked great for about 2 days then the right controller started doing exactly the same thing our left controller did. We bought these to replace our original ones but they’re the same | . 11942 I surprised my nephew for 10th birthday andHe loves it!🙂 | I surprised my nephew for 10th birthday andHe loves it! | . 12134 I love these Joy Cons I purchased for the purpose of replacing my red and blue neon pair because the left joy con&#39;s analog stick was broken. My biggest problem/complaint is that the left Joy Con battery dies way too quickly. It&#39;s almost been a month since I had these joy cons and I&#39;ve never had to charge the left one, only the right one. I don&#39;t understand it 🤷🤷 | I love these Joy Cons I purchased for the purpose of replacing my red and blue neon pair because the left joy con&#39;s analog stick was broken. My biggest problem/complaint is that the left Joy Con battery dies way too quickly. It&#39;s almost been a month since I had these joy cons and I&#39;ve never had to charge the left one, only the right one. I don&#39;t understand it | . 217 rows × 2 columns . All the emojies detected are removed . Step 4: Expand Contractions . def expand_contractions(text): &quot;&quot;&quot;expand shortened words, e.g. don&#39;t to do not&quot;&quot;&quot; text = contractions.fix(text) return text . df[&quot;expand_contractions&quot;] = df[&quot;no_emoji&quot;].apply(expand_contractions) . df[df[&quot;expand_contractions&quot;] != df[&quot;no_emoji&quot;]][[&quot;no_emoji&quot;, &quot;expand_contractions&quot;]] . no_emoji expand_contractions . 1 Best computer I’ve ever own!! This computer forces me to be productive. I used to wait around for this spinning wheel to stop, and now I can do everything so quickly that I think I almost miss the waiting part. Ha ha. I don’t have time to get coffee anymore. All my apps run smoothly, including adobe illustrator and Photoshop, and they work perfectly. Almost too perfect. I really love this computer. I hope it last me for many years to come. | Best computer I have ever own!! This computer forces me to be productive. I used to wait around for this spinning wheel to stop, and now I can do everything so quickly that I think I almost miss the waiting part. Ha ha. I do not have time to get coffee anymore. All my apps run smoothly, including adobe illustrator and Photoshop, and they work perfectly. Almost too perfect. I really love this computer. I hope it last me for many years to come. | . 4 I left my brand new Macbook pro in my car for an hour and now the screen looks like a Picasso painting. Neither Amazon nor Macintosh will pay for repairs, even though I bought it only two months ago, so I&#39;m out $700 to repair my brand new computer. I would heavily advise against buying one of these, because if 80 degree heat is enough to damage the screen, then they&#39;re essentially useless if your air conditioner goes out and you will be left with a repair bill that is half the value of the computer. | I left my brand new Macbook pro in my car for an hour and now the screen looks like a Picasso painting. Neither Amazon nor Macintosh will pay for repairs, even though I bought it only two months ago, so I am out $700 to repair my brand new computer. I would heavily advise against buying one of these, because if 80 degree heat is enough to damage the screen, then they are essentially useless if your air conditioner goes out and you will be left with a repair bill that is half the value of the computer. | . 8 Product came in excellent condition. Battery life isn’t as long as I would like it to be. Product overall works excellent. | Product came in excellent condition. Battery life is not as long as I would like it to be. Product overall works excellent. | . 9 I don’t what to think I bought 2017 16gb 256 ssd but I received a refurbished 2019 8g 256 perfectly packaged, I can’t put apple care I already call for that but im not sure to keep it because I want a computer of 16of ram but this one is 2019, im gonna give the chance to see how it works, And it cost me the same price of a refurbished 2019 Of apple but those ones you can put apple care | I do not what to think I bought 2017 16gb 256 ssd but I received a refurbished 2019 8g 256 perfectly packaged, I cannot put apple care I already call for that but I am not sure to keep it because I want a computer of 16of ram but this one is 2019, I am going to give the chance to see how it works, And it cost me the same price of a refurbished 2019 Of apple but those ones you can put apple care | . 15 KEYBOARD FAILED! I ordered this in November and started using it in January as my main “home” laptop (minimal use). The keyboard stopped working properly in June. Some letters don’t regularly work. Sometimes - but not always- the space bar leaves two spaces instead of one. I wish I spent the money to get a NEW laptop and not refurbished. This was my first refurbished purchase, which I now see is a mistake. I live in a remote area, so fixing a keyboard may outweigh the cost savings. The battery works fine. Regrets here. | KEYBOARD FAILED! I ordered this in November and started using it in January as my main “home” laptop (minimal use). The keyboard stopped working properly in June. Some letters do not regularly work. Sometimes - but not always- the space bar leaves two spaces instead of one. I wish I spent the money to get a NEW laptop and not refurbished. This was my first refurbished purchase, which I now see is a mistake. I live in a remote area, so fixing a keyboard may outweigh the cost savings. The battery works fine. Regrets here. | . ... ... | ... | . 12413 We must all understand the expectations of purchasing used products. I bought these joy-cons used directly by Amazon as &quot;very good condition&quot;, so I figured I would take the chance. With how great amazon is delivering quality for a great price, their reputation made me feel at ease for buying used directly from them.Instant regret when I opened the box. The right joy-con has severe drifting issue with the joystick. And there are many bite marks on both joy-cons. No doubt adding to the drifting. I did what I could to clean the base of the joystick without opening either device. But even then, major involuntary movements when using it. I have to be sure I recenter the stick after every movement to reduce drift.Might not be clear enough, but in the pictures I attached you might be able to make out the various bite marks and the damaged joystick base. Nintendo is very aware that their older joy-con controllers are prone to this drifting problem, and thus offer free repairs or replacements well past their warranty. However, that whole repair process with Nintendo takes around 3 weeks. I don&#39;t have that time, so instead I returned these to Amazon. I am hopeful that Amazon won&#39;t put these back up for sale as someone else will be disappointed :(Save yourselves the headache and invest an extra $10 for new joy-cons. | We must all understand the expectations of purchasing used products. I bought these joy-cons used directly by Amazon as &quot;very good condition&quot;, so I figured I would take the chance. With how great amazon is delivering quality for a great price, their reputation made me feel at ease for buying used directly from them.Instant regret when I opened the box. The right joy-con has severe drifting issue with the joystick. And there are many bite marks on both joy-cons. No doubt adding to the drifting. I did what I could to clean the base of the joystick without opening either device. But even then, major involuntary movements when using it. I have to be sure I recenter the stick after every movement to reduce drift.Might not be clear enough, but in the pictures I attached you might be able to make out the various bite marks and the damaged joystick base. Nintendo is very aware that their older joy-con controllers are prone to this drifting problem, and thus offer free repairs or replacements well past their warranty. However, that whole repair process with Nintendo takes around 3 weeks. I do not have that time, so instead I returned these to Amazon. I am hopeful that Amazon will not put these back up for sale as someone else will be disappointed :(Save yourselves the headache and invest an extra $10 for new joy-cons. | . 12415 This is not so much a product review as a compliment, so here goes...Just wanted to give the Amazon delivery service a “Thank you”. I’ve had my Switch for almost 2 yrs and have logged many happy, sometimes frustrating hours on it. So last week when the Joy-Cons started gradually sticking I knew they needed replacing. The R stick wasn’t actually “physically” sticking to the right, but was sending the message to the game to move right when I wanted to stand my ground. Don’t know if any of you have ever tried fighting Ice Lizalfos on a mountain top while Link keeps trying to creep off the cliff, but I would not recommend it. I’d already searched to replace them, but due to the COVID pandemic Switch Joy-Cons are near impossible to get in regular grey here in Sacramento. EVERY store was wiped out. Even GameStop, Walmart, Best Buy and Fry’s couldn’t provide via store OR online. Amazon said they could deliver, but not until August 1st... it was the best offer I could get. So when that beautiful little brown box showed up yesterday afternoon, July 28th, while I was actually playing Zelda BOTW no less, the feelings of relief that swept over me can only be understated. And just in time too. Yesterday, only an hour or so before delivery, the L stick was starting to stick to the right also. Whew!.... Thanks again, Amazon for that little extra “sumthin’” you always seem to provide.P.S. Oh, and the controllers were delivered, packaged, and function perfectly. The actual Nintendo Joy-Con box was untampered and had safety seals in tact - something I always look for, especially with electronics (and food, of course). | This is not so much a product review as a compliment, so here goes...Just wanted to give the Amazon delivery service a “Thank you”. I have had my Switch for almost 2 yrs and have logged many happy, sometimes frustrating hours on it. So last week when the Joy-Cons started gradually sticking I knew they needed replacing. The R stick was not actually “physically” sticking to the right, but was sending the message to the game to move right when I wanted to stand my ground. do not know if any of you have ever tried fighting Ice Lizalfos on a mountain top while Link keeps trying to creep off the cliff, but I would not recommend it. I would already searched to replace them, but due to the COVID pandemic Switch Joy-Cons are near impossible to get in regular grey here in Sacramento. EVERY store was wiped out. Even GameStop, Walmart, Best Buy and Fry’s could not provide via store OR online. Amazon said they could deliver, but not until August 1st... it was the best offer I could get. So when that beautiful little brown box showed up yesterday afternoon, July 28th, while I was actually playing Zelda BOTW no less, the feelings of relief that swept over me can only be understated. And just in time too. Yesterday, only an hour or so before delivery, the L stick was starting to stick to the right also. Whew!.... Thanks again, Amazon for that little extra “sumthin’” you always seem to provide.P.S. Oh, and the controllers were delivered, packaged, and function perfectly. The actual Nintendo Joy-Con box was untampered and had safety seals in tact - something I always look for, especially with electronics (and food, of course). | . 12416 I desperately wanted to love this product. I&#39;m a huge Nintendo fan &amp; Switch advocate. I love that they have HD rumble, an NFC reader, &amp; pretty responsive gyro controls. I even love that they can be used as individual controllers for many games. What I don&#39;t love is the horrible drift all 6 pairs I&#39;ve purchased has eventually gotten (4 different pairs purchased, a blue pair, 2 yellow pair, &amp; the green/pink pair, plus 2 more pairs from purchasing systems). Before anyone wants to jump down my throat saying I should&#39;ve gone to Nintendo, I actually have done that more than once. Nintendo did not charge me anything to send them for repairs because each time they claimed nothing was wrong with them &amp; the very same Joy-Cons would be returned to me. Lo &amp; behold, these Joy-Cons that were returned to me still drifted. Other than that, I&#39;ve heard people say the size of these controllers aren&#39;t bothersome or small. I&#39;ve also heard people say they&#39;re much too small, &amp; I certainly fall somewhere in the latter category. Holding &amp; playing my Switch in handheld is always a struggle, even for a short amount of time. I don&#39;t know if having sorta big hands was a factor but after a few months, most of my Joy-Cons also began having issues remaining securely on the side rails. This is especially true for my original Cons, they would frequently have to be clicked back into place for handheld mode. Overall I don&#39;t mind how the Joy-Cons work at all. But either I&#39;m an incredibly unlucky sob or there is something wrong with how the control sticks are designed or manufactured. | I desperately wanted to love this product. I am a huge Nintendo fan &amp; Switch advocate. I love that they have HD rumble, an NFC reader, &amp; pretty responsive gyro controls. I even love that they can be used as individual controllers for many games. What I do not love is the horrible drift all 6 pairs I have purchased has eventually gotten (4 different pairs purchased, a blue pair, 2 yellow pair, &amp; the green/pink pair, plus 2 more pairs from purchasing systems). Before anyone wants to jump down my throat saying I should have gone to Nintendo, I actually have done that more than once. Nintendo did not charge me anything to send them for repairs because each time they claimed nothing was wrong with them &amp; the very same Joy-Cons would be returned to me. Lo &amp; behold, these Joy-Cons that were returned to me still drifted. Other than that, I have heard people say the size of these controllers are not bothersome or small. I have also heard people say they are much too small, &amp; I certainly fall somewhere in the latter category. Holding &amp; playing my Switch in handheld is always a struggle, even for a short amount of time. I do not know if having sorta big hands was a factor but after a few months, most of my Joy-Cons also began having issues remaining securely on the side rails. This is especially true for my original Cons, they would frequently have to be clicked back into place for handheld mode. Overall I do not mind how the Joy-Cons work at all. But either I am an incredibly unlucky sob or there is something wrong with how the control sticks are designed or manufactured. | . 12417 Bought these controllers because after a year the ones that came with the switch started to malfunction. One of the analog controllers would drift making gameplay extremely hard. It would make scrolling through menus damn near impossible. I did buy the replacement parts and fixed the remote first (because that is the much cheaper option) but within two months it started happening again so I decided to bite the bullet and replace them. Wouldn’t you know the replacements came and didn’t even last two weeks with very light use! The analog broke and the controller started drifting again. I looked it up and it turns out that this is a common problem with these remotes. I’m disappointed with nintendo. You pay a lot for these systems and the accessories I expect them to last at least a few years. I will say that Amazon was fantastic and replaced them right away. The replacement should be here today. I’m curious to see how long this one lasts. | Bought these controllers because after a year the ones that came with the switch started to malfunction. One of the analog controllers would drift making gameplay extremely hard. It would make scrolling through menus damn near impossible. I did buy the replacement parts and fixed the remote first (because that is the much cheaper option) but within two months it started happening again so I decided to bite the bullet and replace them. would not you know the replacements came and did not even last two weeks with very light use! The analog broke and the controller started drifting again. I looked it up and it turns out that this is a common problem with these remotes. I am disappointed with nintendo. You pay a lot for these systems and the accessories I expect them to last at least a few years. I will say that Amazon was fantastic and replaced them right away. The replacement should be here today. I am curious to see how long this one lasts. | . 12418 Edit: 2yrs later. Today is april 24th 2021 and let me say i am still disappointed. These worked but were the first to start drifting after about i dunno 1 month not bad but still upsetting for full price &quot;new&quot; joycons... both drift and still do till this day simply bc i have not sent them out to be fixed.1. Not new joy cons2. colors were swaped (didn’t even match what the actual box stated; (L) red (R) Blue)3. They are USEDso to start off the box of the controllers itself seemed to be slightly bent as if something heavier was placed on top. The first thing that i noticed was the colors were switched than advertised on the box (i dont mind that at all).Then i decided to check the controllers individually; both have black scratch marks as if being constantly put on and taken off of the console. With that said it already tells me they were used; now i did not pay ‘full’ price for something to be used, i initially didn’t buy them used. I could see small chips on the paint where they slide on and off of the console.Now they work, yes they seemed to work when i put them on the console; however, i haven’t actually played using them yet.I gave this 3 stars mainly for the fact that technically i didn’t get what i paid for. All in all i dont mind, as long as they work but it is upsetting to not get a good presentation. | Edit: 2yrs later. Today is april 24th 2021 and let me say i am still disappointed. These worked but were the first to start drifting after about i dunno 1 month not bad but still upsetting for full price &quot;new&quot; joycons... both drift and still do till this day simply bc i have not sent them out to be fixed.1. Not new joy cons2. colors were swaped (did not even match what the actual box stated; (L) red (R) Blue)3. They are USEDso to start off the box of the controllers itself seemed to be slightly bent as if something heavier was placed on top. The first thing that i noticed was the colors were switched than advertised on the box (i do not mind that at all).Then i decided to check the controllers individually; both have black scratch marks as if being constantly put on and taken off of the console. With that said it already tells me they were used; now i did not pay ‘full’ price for something to be used, i initially did not buy them used. I could see small chips on the paint where they slide on and off of the console.Now they work, yes they seemed to work when i put them on the console; however, i have not actually played using them yet.I gave this 3 stars mainly for the fact that technically i did not get what i paid for. All in all i do not mind, as long as they work but it is upsetting to not get a good presentation. | . 3400 rows × 2 columns . Step 5: Removing accented characters . import unidecode def remove_accented_chars(text): text = unidecode.unidecode(text) return text . df[&quot;no_accented&quot;] = df[&quot;expand_contractions&quot;].apply(remove_accented_chars) . df[df[&quot;expand_contractions&quot;] != df[&quot;no_accented&quot;]][[&quot;expand_contractions&quot;, &quot;no_accented&quot;]] . expand_contractions no_accented . 15 KEYBOARD FAILED! I ordered this in November and started using it in January as my main “home” laptop (minimal use). The keyboard stopped working properly in June. Some letters do not regularly work. Sometimes - but not always- the space bar leaves two spaces instead of one. I wish I spent the money to get a NEW laptop and not refurbished. This was my first refurbished purchase, which I now see is a mistake. I live in a remote area, so fixing a keyboard may outweigh the cost savings. The battery works fine. Regrets here. | KEYBOARD FAILED! I ordered this in November and started using it in January as my main &quot;home&quot; laptop (minimal use). The keyboard stopped working properly in June. Some letters do not regularly work. Sometimes - but not always- the space bar leaves two spaces instead of one. I wish I spent the money to get a NEW laptop and not refurbished. This was my first refurbished purchase, which I now see is a mistake. I live in a remote area, so fixing a keyboard may outweigh the cost savings. The battery works fine. Regrets here. | . 19 I have been using my renewed computer for about 2 weeks now and I am so glad I bought it from “All-out-Apple” the best computer seller on Amazon! I received the 2018 MacBook Air i5 quad core 256gb and the actual specs matched the description! I use it for college for my Zoom classes and the virtual background works!! I upgraded from my 2013 MacBook Air and this one is a lot faster and a much better battery life. It also came with a brand new usb-c original Apple charger for this Mac. This computer is like-new with no scratches at all and I was able to transfer all my old data to this new computer. I would recommend this computer for students and teachers too. | I have been using my renewed computer for about 2 weeks now and I am so glad I bought it from &quot;All-out-Apple&quot; the best computer seller on Amazon! I received the 2018 MacBook Air i5 quad core 256gb and the actual specs matched the description! I use it for college for my Zoom classes and the virtual background works!! I upgraded from my 2013 MacBook Air and this one is a lot faster and a much better battery life. It also came with a brand new usb-c original Apple charger for this Mac. This computer is like-new with no scratches at all and I was able to transfer all my old data to this new computer. I would recommend this computer for students and teachers too. | . 24 Excelente producto!! Sin palabras!, Lo mejor para el trabajo, gaming, día a día, el mejor producto de apple hasta la fecha!!! | Excelente producto!! Sin palabras!, Lo mejor para el trabajo, gaming, dia a dia, el mejor producto de apple hasta la fecha!!! | . 36 Wow, absolutely perfect! I bought this for my daughter’s birthday and for her to use at college. She loves it!! It arrived super fast and in perfect condition!! We are extremely pleased with this MacBook. Thanks for a great purchase! | Wow, absolutely perfect! I bought this for my daughter&#39;s birthday and for her to use at college. She loves it!! It arrived super fast and in perfect condition!! We are extremely pleased with this MacBook. Thanks for a great purchase! | . 48 I am kindof dissatisfied. So I just opened it and cannot tell you everything, however I can tell you what I do not like that I already found. The apple emblem is cracked and the power cord that it came with has MANY scratches, bumps, and scrapes all over it so I question if the cable even charges properly. I know this is referbished, but can we please follow the policy &quot;external finishes like new” legit? Aside from those so far I am satisfied. Scrolling on the mouse pad is Kindof meh but maybe it is because I am not use to it yet? The keys are in fine condition and the finger print scanner works. I was worried with some of the reviews saying that they got a grey instead of a space grey but mine is space grey so I am very happy. My fave color. I can leave another review with more information after a week or so of use. | I am kindof dissatisfied. So I just opened it and cannot tell you everything, however I can tell you what I do not like that I already found. The apple emblem is cracked and the power cord that it came with has MANY scratches, bumps, and scrapes all over it so I question if the cable even charges properly. I know this is referbished, but can we please follow the policy &quot;external finishes like new&quot; legit? Aside from those so far I am satisfied. Scrolling on the mouse pad is Kindof meh but maybe it is because I am not use to it yet? The keys are in fine condition and the finger print scanner works. I was worried with some of the reviews saying that they got a grey instead of a space grey but mine is space grey so I am very happy. My fave color. I can leave another review with more information after a week or so of use. | . ... ... | ... | . 12362 Compré este par de Joy-Con para reemplazar los grises que venían originalmente con mi consola, pues esos tenían input lag, muy notorio especialmente en el control derecho.Estos Joy-Con color neon venían &quot;sellados&quot;, pero pareciera que retiraron el sello original, abrieron la caja, usaron los controles y luego los volvieron a colocar. Digo lo de los sellos porque en la caja hay partes donde falta pintura y se nota que un sello la retiró.Además menciono que usaron los controles, debido a que recién sacados de la caja, tienen marcas de haber sido introducidos en una consola (los rieles dejaron marca). Lo cual realmente no da entera confianza de que el producto sea nuevo.El producto funciona, pero cuesta mucho creer que sea 100% nuevo. Además afuera de la caja menciona que debe incluirse una guía de inicio rápido y una póliza de garantía, cosa que no venía incluída. | Compre este par de Joy-Con para reemplazar los grises que venian originalmente con mi consola, pues esos tenian input lag, muy notorio especialmente en el control derecho.Estos Joy-Con color neon venian &quot;sellados&quot;, pero pareciera que retiraron el sello original, abrieron la caja, usaron los controles y luego los volvieron a colocar. Digo lo de los sellos porque en la caja hay partes donde falta pintura y se nota que un sello la retiro.Ademas menciono que usaron los controles, debido a que recien sacados de la caja, tienen marcas de haber sido introducidos en una consola (los rieles dejaron marca). Lo cual realmente no da entera confianza de que el producto sea nuevo.El producto funciona, pero cuesta mucho creer que sea 100% nuevo. Ademas afuera de la caja menciona que debe incluirse una guia de inicio rapido y una poliza de garantia, cosa que no venia incluida. | . 12363 A ciencia cierta no sé que pasó, los dos primeros cinco días de uso con mi nintendo switch en modo de sobremesa, al jugar mario odyssey me dieron muchos problemas estoy joy con nuevos. Inicia el juego, inicia la partida y parece que todo normal, pero después de los primeros cinco minutos de juego, dejaban de funcionar, se apagaban/desconectaban había que oprimir los botones para que la consola los reconociera nuevamente. No funcionó, los acoplé a la consola y los reconoció de inmediato, volví a sobremesa y oprimí los botones y volvieron a funcionar. Así los 4 días restantes, pensé en hacer la devolución pero finalmente terminó por dejar de pasar ese error y amarga experiencia. Los utilizo diariamente y no ha vuelto a suceder. Ahora que sú estética es excelente son realmente bonitos en color naranja y morado neón, no creo que vuelva a suceder dicho error menos con nintendo en la mira de todos pero quién sabe. Los joy con de mi consola nunca me hicieron eso de dejar de funcionar sin embargo el control izquierdo tiene problema con la palanquilla izquierda que hace que el personaje se mueva solo, lo que me hizo optar por estos atractivos joy con nuevos y chulos de bonitos, pero parece que todos los productos de nintendo switch acaban teniendo algún detallito. Después de esos días frustrantes ahora estoy muy contento con su uso. | A ciencia cierta no se que paso, los dos primeros cinco dias de uso con mi nintendo switch en modo de sobremesa, al jugar mario odyssey me dieron muchos problemas estoy joy con nuevos. Inicia el juego, inicia la partida y parece que todo normal, pero despues de los primeros cinco minutos de juego, dejaban de funcionar, se apagaban/desconectaban habia que oprimir los botones para que la consola los reconociera nuevamente. No funciono, los acople a la consola y los reconocio de inmediato, volvi a sobremesa y oprimi los botones y volvieron a funcionar. Asi los 4 dias restantes, pense en hacer la devolucion pero finalmente termino por dejar de pasar ese error y amarga experiencia. Los utilizo diariamente y no ha vuelto a suceder. Ahora que su estetica es excelente son realmente bonitos en color naranja y morado neon, no creo que vuelva a suceder dicho error menos con nintendo en la mira de todos pero quien sabe. Los joy con de mi consola nunca me hicieron eso de dejar de funcionar sin embargo el control izquierdo tiene problema con la palanquilla izquierda que hace que el personaje se mueva solo, lo que me hizo optar por estos atractivos joy con nuevos y chulos de bonitos, pero parece que todos los productos de nintendo switch acaban teniendo algun detallito. Despues de esos dias frustrantes ahora estoy muy contento con su uso. | . 12377 Súper bien | Super bien | . 12415 This is not so much a product review as a compliment, so here goes...Just wanted to give the Amazon delivery service a “Thank you”. I have had my Switch for almost 2 yrs and have logged many happy, sometimes frustrating hours on it. So last week when the Joy-Cons started gradually sticking I knew they needed replacing. The R stick was not actually “physically” sticking to the right, but was sending the message to the game to move right when I wanted to stand my ground. do not know if any of you have ever tried fighting Ice Lizalfos on a mountain top while Link keeps trying to creep off the cliff, but I would not recommend it. I would already searched to replace them, but due to the COVID pandemic Switch Joy-Cons are near impossible to get in regular grey here in Sacramento. EVERY store was wiped out. Even GameStop, Walmart, Best Buy and Fry’s could not provide via store OR online. Amazon said they could deliver, but not until August 1st... it was the best offer I could get. So when that beautiful little brown box showed up yesterday afternoon, July 28th, while I was actually playing Zelda BOTW no less, the feelings of relief that swept over me can only be understated. And just in time too. Yesterday, only an hour or so before delivery, the L stick was starting to stick to the right also. Whew!.... Thanks again, Amazon for that little extra “sumthin’” you always seem to provide.P.S. Oh, and the controllers were delivered, packaged, and function perfectly. The actual Nintendo Joy-Con box was untampered and had safety seals in tact - something I always look for, especially with electronics (and food, of course). | This is not so much a product review as a compliment, so here goes...Just wanted to give the Amazon delivery service a &quot;Thank you&quot;. I have had my Switch for almost 2 yrs and have logged many happy, sometimes frustrating hours on it. So last week when the Joy-Cons started gradually sticking I knew they needed replacing. The R stick was not actually &quot;physically&quot; sticking to the right, but was sending the message to the game to move right when I wanted to stand my ground. do not know if any of you have ever tried fighting Ice Lizalfos on a mountain top while Link keeps trying to creep off the cliff, but I would not recommend it. I would already searched to replace them, but due to the COVID pandemic Switch Joy-Cons are near impossible to get in regular grey here in Sacramento. EVERY store was wiped out. Even GameStop, Walmart, Best Buy and Fry&#39;s could not provide via store OR online. Amazon said they could deliver, but not until August 1st... it was the best offer I could get. So when that beautiful little brown box showed up yesterday afternoon, July 28th, while I was actually playing Zelda BOTW no less, the feelings of relief that swept over me can only be understated. And just in time too. Yesterday, only an hour or so before delivery, the L stick was starting to stick to the right also. Whew!.... Thanks again, Amazon for that little extra &quot;sumthin&#39;&quot; you always seem to provide.P.S. Oh, and the controllers were delivered, packaged, and function perfectly. The actual Nintendo Joy-Con box was untampered and had safety seals in tact - something I always look for, especially with electronics (and food, of course). | . 12418 Edit: 2yrs later. Today is april 24th 2021 and let me say i am still disappointed. These worked but were the first to start drifting after about i dunno 1 month not bad but still upsetting for full price &quot;new&quot; joycons... both drift and still do till this day simply bc i have not sent them out to be fixed.1. Not new joy cons2. colors were swaped (did not even match what the actual box stated; (L) red (R) Blue)3. They are USEDso to start off the box of the controllers itself seemed to be slightly bent as if something heavier was placed on top. The first thing that i noticed was the colors were switched than advertised on the box (i do not mind that at all).Then i decided to check the controllers individually; both have black scratch marks as if being constantly put on and taken off of the console. With that said it already tells me they were used; now i did not pay ‘full’ price for something to be used, i initially did not buy them used. I could see small chips on the paint where they slide on and off of the console.Now they work, yes they seemed to work when i put them on the console; however, i have not actually played using them yet.I gave this 3 stars mainly for the fact that technically i did not get what i paid for. All in all i do not mind, as long as they work but it is upsetting to not get a good presentation. | Edit: 2yrs later. Today is april 24th 2021 and let me say i am still disappointed. These worked but were the first to start drifting after about i dunno 1 month not bad but still upsetting for full price &quot;new&quot; joycons... both drift and still do till this day simply bc i have not sent them out to be fixed.1. Not new joy cons2. colors were swaped (did not even match what the actual box stated; (L) red (R) Blue)3. They are USEDso to start off the box of the controllers itself seemed to be slightly bent as if something heavier was placed on top. The first thing that i noticed was the colors were switched than advertised on the box (i do not mind that at all).Then i decided to check the controllers individually; both have black scratch marks as if being constantly put on and taken off of the console. With that said it already tells me they were used; now i did not pay &#39;full&#39; price for something to be used, i initially did not buy them used. I could see small chips on the paint where they slide on and off of the console.Now they work, yes they seemed to work when i put them on the console; however, i have not actually played using them yet.I gave this 3 stars mainly for the fact that technically i did not get what i paid for. All in all i do not mind, as long as they work but it is upsetting to not get a good presentation. | . 1466 rows × 2 columns . Step 6: Collapse duplicated punctuation . punc = string.punctuation def remove_consecutive_punctuation(text): newtext = [] for k, g in groupby(text): if k in punc: newtext.append(k + &quot; &quot;) else: newtext.extend(g) return &#39;&#39;.join(newtext) . remove_consecutive_punctuation(&quot;Hello World..Now I can see you&quot;) . df[&quot;no_consecutive_punc&quot;] = df[&quot;expand_contractions&quot;].apply(remove_consecutive_punctuation) . df[df[&quot;expand_contractions&quot;] != df[&quot;no_consecutive_punc&quot;]][[&quot;expand_contractions&quot;, &quot;no_consecutive_punc&quot;]] . expand_contractions no_consecutive_punc . 1 Best computer I have ever own!! This computer forces me to be productive. I used to wait around for this spinning wheel to stop, and now I can do everything so quickly that I think I almost miss the waiting part. Ha ha. I do not have time to get coffee anymore. All my apps run smoothly, including adobe illustrator and Photoshop, and they work perfectly. Almost too perfect. I really love this computer. I hope it last me for many years to come. | Best computer I have ever own! This computer forces me to be productive. I used to wait around for this spinning wheel to stop, and now I can do everything so quickly that I think I almost miss the waiting part. Ha ha. I do not have time to get coffee anymore. All my apps run smoothly, including adobe illustrator and Photoshop, and they work perfectly. Almost too perfect. I really love this computer. I hope it last me for many years to come. | . 11 Positivo, EXCELENTE EQUIPO!!! | Positivo, EXCELENTE EQUIPO! | . 19 I have been using my renewed computer for about 2 weeks now and I am so glad I bought it from “All-out-Apple” the best computer seller on Amazon! I received the 2018 MacBook Air i5 quad core 256gb and the actual specs matched the description! I use it for college for my Zoom classes and the virtual background works!! I upgraded from my 2013 MacBook Air and this one is a lot faster and a much better battery life. It also came with a brand new usb-c original Apple charger for this Mac. This computer is like-new with no scratches at all and I was able to transfer all my old data to this new computer. I would recommend this computer for students and teachers too. | I have been using my renewed computer for about 2 weeks now and I am so glad I bought it from “All-out-Apple” the best computer seller on Amazon! I received the 2018 MacBook Air i5 quad core 256gb and the actual specs matched the description! I use it for college for my Zoom classes and the virtual background works! I upgraded from my 2013 MacBook Air and this one is a lot faster and a much better battery life. It also came with a brand new usb-c original Apple charger for this Mac. This computer is like-new with no scratches at all and I was able to transfer all my old data to this new computer. I would recommend this computer for students and teachers too. | . 24 Excelente producto!! Sin palabras!, Lo mejor para el trabajo, gaming, día a día, el mejor producto de apple hasta la fecha!!! | Excelente producto! Sin palabras!, Lo mejor para el trabajo, gaming, día a día, el mejor producto de apple hasta la fecha! | . 26 I am extremely pleased with this early 2015, 13&quot; Macbook Pro! There is not one mark on the case, screen, keyboard - it is exactly like the brand-new one I purchased from Apple, 5 years ago!! The battery cycle count is only 21 - truly remarkable! It also came with a genuine MagSafe 2 Apple charger (I did check, and it is new and authentic). I am very happy with the purchase so far - thank you for selling such a quality item! | I am extremely pleased with this early 2015, 13&quot; Macbook Pro! There is not one mark on the case, screen, keyboard - it is exactly like the brand-new one I purchased from Apple, 5 years ago! The battery cycle count is only 21 - truly remarkable! It also came with a genuine MagSafe 2 Apple charger (I did check, and it is new and authentic). I am very happy with the purchase so far - thank you for selling such a quality item! | . ... ... | ... | . 12405 These were an early Christmas gift for my son who has everything he wants, he literally does not want or need anything, so I am always far stretched when trying to figure out what to give him for birthdays and Christmas.I was relieved as heck when he said he wanted a set of these controllers. I could not wait for Christmas because he had the new Super Mario Party game and we were having a few people come to the house to play it.The controllers arrived just in time for our Mario Party , but my son and I played to practice the new game the day ahead. I usually am triple-thumbed when it comes to controlling the controllers but these were surprisingly easy for me to use.Note:I discovered that using a certain color controller gives that user certain controls over the game that the other users do not have. For instance, when using a particular color controller, I had the ability to click the game back to the previous screen, thus making everyone groan loudly and wait for me to click us back to the game at hand. :)~~~~ | These were an early Christmas gift for my son who has everything he wants, he literally does not want or need anything, so I am always far stretched when trying to figure out what to give him for birthdays and Christmas.I was relieved as heck when he said he wanted a set of these controllers. I could not wait for Christmas because he had the new Super Mario Party game and we were having a few people come to the house to play it.The controllers arrived just in time for our Mario Party , but my son and I played to practice the new game the day ahead. I usually am triple-thumbed when it comes to controlling the controllers but these were surprisingly easy for me to use.Note:I discovered that using a certain color controller gives that user certain controls over the game that the other users do not have. For instance, when using a particular color controller, I had the ability to click the game back to the previous screen, thus making everyone groan loudly and wait for me to click us back to the game at hand. :)~ | . 12408 Did not purchase from Amazon as third party sellers were of course raising prices due to low stock and high demand. Managed to find these MSRP.I had purchased the Neon Blue/Red Switch and wanted these because I read they were opposite the set that came with the Neon Switch. This is true. Purchasing these will give you a complete set of Blue and Red. So if you want to throw them on your Switch and have matching colors, you can now!They are a little on the expensive side compared to a typical controller from other console makers, but I get it. They are individual controllers for Multiplayer games and are pretty sophisticated. The motion sending is great, the rumble feels nice, the colors really pop! And the batteries last a very long time. You will not have to charge these often!Speaking of charging you have two options: purchase a charging dock to charge them, or have them connected to your Switch. I never found keeping the extra pairs charged because you will probably just have them attached to the console anyway. I rotate them out so they are always charged. The fact that the battery life is ~20 hrs, you will have a hard time and rarely be low on battery. Plus having more joycons means more Multiplayer fun!! | Did not purchase from Amazon as third party sellers were of course raising prices due to low stock and high demand. Managed to find these MSRP.I had purchased the Neon Blue/Red Switch and wanted these because I read they were opposite the set that came with the Neon Switch. This is true. Purchasing these will give you a complete set of Blue and Red. So if you want to throw them on your Switch and have matching colors, you can now!They are a little on the expensive side compared to a typical controller from other console makers, but I get it. They are individual controllers for Multiplayer games and are pretty sophisticated. The motion sending is great, the rumble feels nice, the colors really pop! And the batteries last a very long time. You will not have to charge these often!Speaking of charging you have two options: purchase a charging dock to charge them, or have them connected to your Switch. I never found keeping the extra pairs charged because you will probably just have them attached to the console anyway. I rotate them out so they are always charged. The fact that the battery life is ~20 hrs, you will have a hard time and rarely be low on battery. Plus having more joycons means more Multiplayer fun! | . 12410 I have been a Nintendo fan since the late 80&#39;s. I love their products for the most part. The Switch seems like a high water mark for innovation and functionality, with one caveat. The joy-con SUCKS!We have the blue and red joy-cons which came with the Switch. I bought the Pink &amp; Green joy-cons so we could play Mario Party (which we LOVE). Initially, we had no problems with the controllers. I was not impressed with the range, but whatever. Also, the delay while playing wirelessly is pitiable. If you are playing any game which requires timed button presses (Mario Party, Smash Bro&#39;s, Hollow Knight...) you cannot depend on accuracy, which is downright silly. Latency is not an issue for any other system&#39;s controllers.Now, I have got a blue controller which will not hold a charge, a pink controller who is &quot;L&quot; button does not register and my green controller&#39;s &quot;X&quot; button sticks. Perhaps these issues are from maltreatment. I do have three kids. But I was their age when I got my NES and I abused the heck out of those controllers and they STILL work today!I want to love the Joy-cons. they are adorable. The ability to switch between two and one controller play is a great feat in system engineering. The Switch system itself is a GREAT system. To ask $70!!! for garbage controllers which have lower range and higher latency than any other controller is a poor business practice. You are better than this Nintendo. | I have been a Nintendo fan since the late 80&#39;s. I love their products for the most part. The Switch seems like a high water mark for innovation and functionality, with one caveat. The joy-con SUCKS!We have the blue and red joy-cons which came with the Switch. I bought the Pink &amp; Green joy-cons so we could play Mario Party (which we LOVE). Initially, we had no problems with the controllers. I was not impressed with the range, but whatever. Also, the delay while playing wirelessly is pitiable. If you are playing any game which requires timed button presses (Mario Party, Smash Bro&#39;s, Hollow Knight.) you cannot depend on accuracy, which is downright silly. Latency is not an issue for any other system&#39;s controllers.Now, I have got a blue controller which will not hold a charge, a pink controller who is &quot;L&quot; button does not register and my green controller&#39;s &quot;X&quot; button sticks. Perhaps these issues are from maltreatment. I do have three kids. But I was their age when I got my NES and I abused the heck out of those controllers and they STILL work today!I want to love the Joy-cons. they are adorable. The ability to switch between two and one controller play is a great feat in system engineering. The Switch system itself is a GREAT system. To ask $70! for garbage controllers which have lower range and higher latency than any other controller is a poor business practice. You are better than this Nintendo. | . 12415 This is not so much a product review as a compliment, so here goes...Just wanted to give the Amazon delivery service a “Thank you”. I have had my Switch for almost 2 yrs and have logged many happy, sometimes frustrating hours on it. So last week when the Joy-Cons started gradually sticking I knew they needed replacing. The R stick was not actually “physically” sticking to the right, but was sending the message to the game to move right when I wanted to stand my ground. do not know if any of you have ever tried fighting Ice Lizalfos on a mountain top while Link keeps trying to creep off the cliff, but I would not recommend it. I would already searched to replace them, but due to the COVID pandemic Switch Joy-Cons are near impossible to get in regular grey here in Sacramento. EVERY store was wiped out. Even GameStop, Walmart, Best Buy and Fry’s could not provide via store OR online. Amazon said they could deliver, but not until August 1st... it was the best offer I could get. So when that beautiful little brown box showed up yesterday afternoon, July 28th, while I was actually playing Zelda BOTW no less, the feelings of relief that swept over me can only be understated. And just in time too. Yesterday, only an hour or so before delivery, the L stick was starting to stick to the right also. Whew!.... Thanks again, Amazon for that little extra “sumthin’” you always seem to provide.P.S. Oh, and the controllers were delivered, packaged, and function perfectly. The actual Nintendo Joy-Con box was untampered and had safety seals in tact - something I always look for, especially with electronics (and food, of course). | This is not so much a product review as a compliment, so here goes.Just wanted to give the Amazon delivery service a “Thank you”. I have had my Switch for almost 2 yrs and have logged many happy, sometimes frustrating hours on it. So last week when the Joy-Cons started gradually sticking I knew they needed replacing. The R stick was not actually “physically” sticking to the right, but was sending the message to the game to move right when I wanted to stand my ground. do not know if any of you have ever tried fighting Ice Lizalfos on a mountain top while Link keeps trying to creep off the cliff, but I would not recommend it. I would already searched to replace them, but due to the COVID pandemic Switch Joy-Cons are near impossible to get in regular grey here in Sacramento. EVERY store was wiped out. Even GameStop, Walmart, Best Buy and Fry’s could not provide via store OR online. Amazon said they could deliver, but not until August 1st. it was the best offer I could get. So when that beautiful little brown box showed up yesterday afternoon, July 28th, while I was actually playing Zelda BOTW no less, the feelings of relief that swept over me can only be understated. And just in time too. Yesterday, only an hour or so before delivery, the L stick was starting to stick to the right also. Whew!. Thanks again, Amazon for that little extra “sumthin’” you always seem to provide.P.S. Oh, and the controllers were delivered, packaged, and function perfectly. The actual Nintendo Joy-Con box was untampered and had safety seals in tact - something I always look for, especially with electronics (and food, of course). | . 12418 Edit: 2yrs later. Today is april 24th 2021 and let me say i am still disappointed. These worked but were the first to start drifting after about i dunno 1 month not bad but still upsetting for full price &quot;new&quot; joycons... both drift and still do till this day simply bc i have not sent them out to be fixed.1. Not new joy cons2. colors were swaped (did not even match what the actual box stated; (L) red (R) Blue)3. They are USEDso to start off the box of the controllers itself seemed to be slightly bent as if something heavier was placed on top. The first thing that i noticed was the colors were switched than advertised on the box (i do not mind that at all).Then i decided to check the controllers individually; both have black scratch marks as if being constantly put on and taken off of the console. With that said it already tells me they were used; now i did not pay ‘full’ price for something to be used, i initially did not buy them used. I could see small chips on the paint where they slide on and off of the console.Now they work, yes they seemed to work when i put them on the console; however, i have not actually played using them yet.I gave this 3 stars mainly for the fact that technically i did not get what i paid for. All in all i do not mind, as long as they work but it is upsetting to not get a good presentation. | Edit: 2yrs later. Today is april 24th 2021 and let me say i am still disappointed. These worked but were the first to start drifting after about i dunno 1 month not bad but still upsetting for full price &quot;new&quot; joycons. both drift and still do till this day simply bc i have not sent them out to be fixed.1. Not new joy cons2. colors were swaped (did not even match what the actual box stated; (L) red (R) Blue)3. They are USEDso to start off the box of the controllers itself seemed to be slightly bent as if something heavier was placed on top. The first thing that i noticed was the colors were switched than advertised on the box (i do not mind that at all).Then i decided to check the controllers individually; both have black scratch marks as if being constantly put on and taken off of the console. With that said it already tells me they were used; now i did not pay ‘full’ price for something to be used, i initially did not buy them used. I could see small chips on the paint where they slide on and off of the console.Now they work, yes they seemed to work when i put them on the console; however, i have not actually played using them yet.I gave this 3 stars mainly for the fact that technically i did not get what i paid for. All in all i do not mind, as long as they work but it is upsetting to not get a good presentation. | . 1113 rows × 2 columns . Step 7: Filter Languages (English only) . nlp.add_pipe(LanguageDetector(), name=&#39;language_detector&#39;, last=True) . def detect_lang(text): doc = nlp(text) lang = doc._.language[&#39;language&#39;] return lang . df[&quot;lang&quot;] = df[&quot;no_consecutive_punc&quot;].apply(detect_lang) . non_english_df = df[df.lang != &quot;en&quot;][[&quot;no_consecutive_punc&quot;, &quot;lang&quot;]] print(&quot;number of non english comments&quot;, non_english_df.shape) . number of non english comments (2559, 2) . df.to_csv(&quot;preprocessed.csv&quot;) . filtered_df = df[df.lang == &quot;en&quot;] . print(&quot;Number of data before filter:&quot;, len(df)) print(&quot;Number of data after filter:&quot;, len(filtered_df)) . Number of data before filter: 12416 Number of data after filter: 9857 . Step 8: Lower case . df[&#39;lower_case&#39;] = df[&quot;no_consecutive_punc&quot;].str.lower() . df.to_csv(&quot;preprocessed.csv&quot;, index=False) . Discussion . There some other techniques that can be considered depends on your task at hand. For example, remove numbers or convert text to number or vice versa. .",
            "url": "https://minhdang241.github.io/minhdg-blog/implementation/2021/07/27/NLP_7_Text_Preprocessing_and_Labelling_-Part_1.html",
            "relUrl": "/implementation/2021/07/27/NLP_7_Text_Preprocessing_and_Labelling_-Part_1.html",
            "date": " • Jul 27, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "Word Embeddings (Word2Vec) [Part1]",
            "content": "The full notebook is available here. . Word Embeddings Overview . Word embeddings are dense vectors of real numbers, one for each word in the vocabulary, which is the collection of words extracted from the dataset. . There are many ways to represent a word on a computer. For example, we can use ASCII code. Yet, it only tells what the word is, not its meaning. Another option is to use a one-hot vector to represent a word, in which we put the number 1 in the location of the represented word. However, using a one-hot vector has 2 main drawbacks. First of all, the vector is huge and sparse. The size of the vector is the same as the size of the vocabulary. The vector is sparse since there is only one position that has a non-zero value. Next, it treats all words independently, with no relation to each other. Technically said it does not provide any notion of similarity between words. . Take an example from Pytorch documentation: . Suppose we are building a language model. Suppose we have seen the sentences. . The mathematician ran to the store. | The physicist ran to the store. | The mathematician solved the open problem. | . &gt; . In the training data, suppose we get the sentence never seen before:* The physicist solved the open problem.Our language model might be doing OK on this sentence. But it&#39;s better if we can use the following facts: . We have seen the mathematician and physicist in the same role in the sentence. As a result, they can have a semantic relation somehow. | We have seen mathematicians in the same role in this new unseen sentence as we are now seeing physicists.That infers the physicist is a good fit in the new unseen sentence. That&#39;s what we mean by semantic similarity. That relies on the assumption that:words appearing in similar contexts are related to each other semantically To encode the similarity between words we can think up some semantic attributes. We then put those attributes in the vector and give a score for each. We give high scores for shared attributes and low scores for the counterparts. We can measure the similarity between two word vectors using the dot product. As a result, similar words will have a similarity score near 1 and different words will have a similarity score near zero. . | Since thinking of the semantic attributes is hard and manually intensive, we can let them be the parameters in the network and be updated during training. One drawback of doing this way is the attribute scores are not interpretable. That is, we do not know what is attribute that a specific score represents. . In summary, word embeddings are a representation of the semantics of a word, efficiently encoding semantic information that might be relevant to the task at hand . To read more about word embeddings in Pytorch, click here . Word2Vec . Word2Vec is one the approaches to develop a word embedding. There are two algorithms used in Word2Vec: continuous bag-of-words (CBOW) and skip-gram. CBOW aims to predict a center word from the surrounding context in terms of word vectors. Skip-gram does the opposite, and predicts the probability of context words from a center word. In this post, we will try to implement both. . Continuous Bag-of-words (CBOW) (Pytorch) . The algorithm aims to predict a center word give the surrounding context in terms of word vectors. For example, given a sentence &quot;The cat jumped over the puddle&quot;, the algorithm treats {&quot;The&quot;, &quot;cat&quot;, &quot;over&quot;, &quot;the&quot;, &quot;puddle&quot;} as context words and {&quot;jumped&quot;} as the center word. The objective is to generate the center word from context words. . import torch import torch.nn as nn import torch.nn.functional as F import torch.optim as optim # reproduction purpose torch.manual_seed(1) . &lt;torch._C.Generator at 0x7ff4203ac150&gt; . CONTEXT_SIZE = 2 # 2 words to the left, 2 to the right EMBEDDING_DIM = 10 HIDDEN_DIM = 128 raw_text = &quot;&quot;&quot;We are about to study the idea of a computational process. Computational processes are abstract beings that inhabit computers. As they evolve, processes manipulate other abstract things called data. The evolution of a process is directed by a pattern of rules called a program. People create programs to direct processes. In effect, we conjure the spirits of the computer with our spells.&quot;&quot;&quot;.split() # By deriving a set from `raw_text`, we deduplicate the array vocab = set(raw_text) vocab_size = len(vocab) word_to_ix = {word: i for i, word in enumerate(vocab)} data = [] for i in range(2, len(raw_text) - 2): context = [raw_text[i - 2], raw_text[i - 1], raw_text[i + 1], raw_text[i + 2]] target = raw_text[i] data.append((context, target)) class CBOW(nn.Module): def __init__(self, vocab_size, embedding_dim, hidden_dim): super(CBOW, self).__init__() self.embeddings = nn.Embedding(vocab_size, embedding_dim) self.linear1 = nn.Linear(embedding_dim, hidden_dim) self.linear2 = nn.Linear(hidden_dim, vocab_size) def forward(self, inputs): out = self.embeddings(inputs) out = torch.sum(out, dim=0).view(1, -1) out = F.relu(self.linear1(out)) out = F.log_softmax(self.linear2(out), dim=-1) return out # create your model and train. here are some functions to help you make # the data ready for use by your module def make_context_vector(context, word_to_ix): idxs = [word_to_ix[w] for w in context] return torch.tensor(idxs, dtype=torch.long) # Training losses = [] loss_function = nn.NLLLoss() model = CBOW(vocab_size, EMBEDDING_DIM, HIDDEN_DIM) optimizer = optim.SGD(model.parameters(), lr=0.001) for epoch in range(10): total_loss = 0 for context, target in data: context_idxs = make_context_vector(context, word_to_ix) model.zero_grad() log_probs = model(context_idxs) loss = loss_function(log_probs, torch.tensor([word_to_ix[target]], dtype=torch.long)) loss.backward() optimizer.step() total_loss += loss.item() losses.append(total_loss) print(losses) print(model.embeddings.weight[word_to_ix[&#39;spirits&#39;]]) . [238.0529305934906, 233.41328835487366, 228.94981503486633, 224.64973831176758, 220.50258708000183, 216.49783158302307, 212.62398993968964, 208.87176704406738, 205.23141360282898, 201.69729340076447] tensor([-0.7098, -0.6179, -0.3807, 2.3069, -0.7957, 1.4458, 0.6856, 2.1891, -0.2936, 0.5549], grad_fn=&lt;SelectBackward&gt;) . Skip-gram (Pytorch) . CONTEXT_SIZE = 2 # 2 words to the left, 2 to the right EMBEDDING_DIM = 10 HIDDEN_DIM = 128 raw_text = &quot;&quot;&quot;We are about to study the idea of a computational process. Computational processes are abstract beings that inhabit computers. As they evolve, processes manipulate other abstract things called data. The evolution of a process is directed by a pattern of rules called a program. People create programs to direct processes. In effect, we conjure the spirits of the computer with our spells.&quot;&quot;&quot;.split() # By deriving a set from `raw_text`, we deduplicate the array vocab = set(raw_text) vocab_size = len(vocab) word_to_ix = {word: i for i, word in enumerate(vocab)} data = [] for i in range(2, len(raw_text) - 2): context = [raw_text[i - 2], raw_text[i - 1], raw_text[i + 1], raw_text[i + 2]] target = raw_text[i] for value in context: sample = (target, value) data.append(sample) class SkipGram(nn.Module): def __init__(self, vocab_size, embedding_dim, hidden_dim): super(SkipGram, self).__init__() self.embeddings = nn.Embedding(vocab_size, embedding_dim) self.linear1 = nn.Linear(embedding_dim, hidden_dim) self.linear2 = nn.Linear(hidden_dim, vocab_size) def forward(self, inputs): out = self.embeddings(inputs) out = F.relu(self.linear1(out)) out = F.log_softmax(self.linear2(out), dim=-1) return out # create your model and train. here are some functions to help you make # the data ready for use by your module # Training losses = [] loss_function = nn.NLLLoss() model = SkipGram(vocab_size, EMBEDDING_DIM, HIDDEN_DIM) optimizer = optim.SGD(model.parameters(), lr=0.001) for epoch in range(10): total_loss = 0 for input, output in data: input_index = torch.tensor([word_to_ix[input]], dtype=torch.long) model.zero_grad() log_probs = model(input_index) loss = loss_function(log_probs, torch.tensor([word_to_ix[output]], dtype=torch.long)) loss.backward() optimizer.step() total_loss += loss.item() losses.append(total_loss) print(losses) print(model.embeddings.weight[word_to_ix[&#39;spirits&#39;]]) . [912.227198600769, 903.7498636245728, 895.8144631385803, 888.3975474834442, 881.4723126888275, 875.0154674053192, 869.0011675357819, 863.3996088504791, 858.1725707054138, 853.288257598877] tensor([ 0.3021, 0.2816, -1.1773, 1.0418, 1.8390, -0.5845, -0.2637, 1.3842, 0.3855, 0.1923], grad_fn=&lt;SelectBackward&gt;) . Word2Vec (Gensim) . Gensim implements CBOW and using negative sampling for training by default. To toggle between CBOW and skip-gram algorithm, add this argument below when create the Word2Vec instance. sg ({0, 1}, optional) – Training algorithm: 1 for skip-gram; otherwise CBOW. . %%capture !pip install --upgrade gensim . from gensim.test.utils import datapath from gensim import utils class MyCorpus: &quot;&quot;&quot;An iterator that yields sentences&quot;&quot;&quot; def __iter__(self): corpus_path = datapath(&#39;lee_background.cor&#39;) for line in open(corpus_path): # assume there is one document per line, tokens separated by whitespace yield utils.simple_preprocess(line) . import gensim sentences = MyCorpus() model = gensim.models.Word2Vec(sentences=sentences, sg=0) # change to 1 if prefer skip-gram . model.wv[&#39;king&#39;] . array([-1.47548895e-02, 4.44000289e-02, 1.02321925e-02, 1.20065575e-02, 9.83571820e-03, -8.47978592e-02, 3.42624560e-02, 8.44758376e-02, -3.13533121e-03, -1.38494289e-02, -4.28904686e-03, -5.30756600e-02, 7.55382003e-03, 2.79652104e-02, 4.44820989e-03, 1.32240532e-02, -2.42202985e-03, -2.49751448e-03, -1.71462744e-02, -6.11230545e-02, 3.83632220e-02, 9.09661502e-03, 1.09449634e-02, -2.17360468e-03, -1.88374687e-02, 2.02645455e-02, -1.86126940e-02, -1.27745485e-02, -2.71721575e-02, 1.31690372e-02, 3.29722501e-02, -4.22514454e-02, 3.72793637e-02, -3.36719528e-02, -7.06554204e-03, 4.73929197e-02, 1.39981424e-02, 7.61039788e-03, -1.61971990e-02, -3.04519087e-02, -1.60803776e-02, 4.38297074e-03, -8.02283920e-03, 1.50885303e-02, 2.63876691e-02, -1.95540637e-02, -2.64777783e-02, -3.67977191e-04, 7.01137306e-03, 3.12562287e-02, 1.64159592e-02, -2.16274485e-02, -1.62629951e-02, 8.53445439e-04, -1.33869080e-02, 1.73475724e-02, -1.21692673e-03, 2.21166899e-03, -2.24457402e-02, 4.26836731e-03, -1.45576373e-02, 6.20996347e-04, 6.98805647e-03, -4.57839714e-03, -2.95367688e-02, 6.10822700e-02, 1.47746662e-02, 3.35532837e-02, -3.87191810e-02, 4.92215976e-02, -1.04450071e-02, 2.97265081e-03, 5.04135974e-02, -8.13318323e-03, 3.63118313e-02, 2.79957112e-02, -1.12850778e-03, -2.14369707e-02, -4.13609855e-02, -1.58206820e-02, -3.22486572e-02, 7.98239373e-03, -3.16767953e-02, 4.03956585e-02, -3.79999110e-05, -1.51074128e-02, 2.10159868e-02, 3.33536156e-02, 4.75050472e-02, 1.45110274e-02, 3.53002362e-02, 5.23244813e-02, 4.45592292e-02, 9.90339927e-03, 8.80143940e-02, 2.01153327e-02, 4.54641357e-02, -4.78953496e-03, 7.65400566e-03, -5.82322525e-03], dtype=float32) . Word2Vec is unsupervised task, so there is no good way to evaluate the result. Evaluation depends on the application. . Example of Gensim Word2Vec functions . import gensim.downloader as api wv = api.load(&#39;word2vec-google-news-300&#39;) . [=================================================-] 99.8% 1660.2/1662.8MB downloaded . for index , word in enumerate(wv.index_to_key): if index == 10: break print(f&quot;word #{index}/{len(wv.index_to_key)} is {word}&quot;) . word #0/3000000 is &lt;/s&gt; word #1/3000000 is in word #2/3000000 is for word #3/3000000 is that word #4/3000000 is is word #5/3000000 is on word #6/3000000 is ## word #7/3000000 is The word #8/3000000 is with word #9/3000000 is said . vec_queen = wv[&#39;queen&#39;] . One limitation of Word2Vec is that the model is unable to infer vectors for unseen words. . Note: FastText model can solve this limitation. . try: vec_random = wv[&#39;vietname&#39;] except KeyError: print(&quot;The word &#39;vietname&#39; does not appear in this model&quot;) . The word &#39;vietname&#39; does not appear in this model . pairs = [ (&#39;scooter&#39;, &#39;chair&#39;), (&#39;scooter&#39;, &#39;motorbike&#39;), (&#39;scooter&#39;, &#39;football&#39;) ] for w1, w2 in pairs: print(f&#39;{w1} t{w2} t{wv.similarity(w1, w2)}&#39;) . scooter chair 0.20833881199359894 scooter motorbike 0.7071131467819214 scooter football 0.07120829075574875 . print(wv.most_similar(positive=[&#39;vietnam&#39;], topn=5)) . [(&#39;ww2&#39;, 0.6164373159408569), (&#39;iraq&#39;, 0.6033741235733032), (&#39;reagan&#39;, 0.5772603154182434), (&#39;VietNam&#39;, 0.5732988119125366), (&#39;afghanistan&#39;, 0.5602078437805176)] . print(wv.doesnt_match([&#39;you&#39;, &quot;don&#39;t&quot;, &quot;know&quot;, &quot;me&quot;, &quot;son&quot;])) . son . Visualize the Word Embeddings using tSNE . Visualization can be used to notice semantic and syntactic trends in the data. . Semantic: words like cat, dog, cow have a tendency to lie close by. | Syntactic: words like run, running or cut, cutting lie close together. | . %matplotlib inline from sklearn.decomposition import IncrementalPCA # inital reduction from sklearn.manifold import TSNE # final reduction import numpy as np # array handling def reduce_dimensions(model): num_dimensions = 2 # final num dimensions (2D, 3D, etc) # extract the words &amp; their vectors, as numpy arrays vectors = np.asarray(model.wv.vectors) labels = np.asarray(model.wv.index_to_key) # fixed-width numpy strings # reduce using t-SNE tsne = TSNE(n_components=num_dimensions, random_state=0) vectors = tsne.fit_transform(vectors) x_vals = [v[0] for v in vectors] y_vals = [v[1] for v in vectors] return x_vals, y_vals, labels x_vals, y_vals, labels = reduce_dimensions(model) def plot_with_plotly(x_vals, y_vals, labels, plot_in_notebook=True): from plotly.offline import init_notebook_mode, iplot, plot import plotly.graph_objs as go trace = go.Scatter(x=x_vals, y=y_vals, mode=&#39;text&#39;, text=labels) data = [trace] if plot_in_notebook: init_notebook_mode(connected=True) iplot(data, filename=&#39;word-embedding-plot&#39;) else: plot(data, filename=&#39;word-embedding-plot.html&#39;) def plot_with_matplotlib(x_vals, y_vals, labels): import matplotlib.pyplot as plt import random random.seed(0) plt.figure(figsize=(12, 12)) plt.scatter(x_vals, y_vals) # # Label randomly subsampled 25 data points # indices = list(range(len(labels))) selected_indices = random.sample(indices, 25) for i in selected_indices: plt.annotate(labels[i], (x_vals[i], y_vals[i])) try: get_ipython() except Exception: plot_function = plot_with_matplotlib else: plot_function = plot_with_plotly plot_function(x_vals, y_vals, labels) . Using Pretrained Word2Vec in Pytorch . Construct the vocabulary of our own data. | Load word vectors corresponding to words in our vocabulary. | Use the our word2index to translate our text to indices. |",
            "url": "https://minhdang241.github.io/minhdg-blog/implementation/2021/07/26/NLP_6_Word_Embeddings_Word2Vec_-Part_1.html",
            "relUrl": "/implementation/2021/07/26/NLP_6_Word_Embeddings_Word2Vec_-Part_1.html",
            "date": " • Jul 26, 2021"
        }
        
    
  
    
        ,"post10": {
            "title": "Interactive Attention Networks for Aspect-Level Sentiment Classification",
            "content": "The full notebook is available here. . Introduction . Previous stuides have realized the importance of targets in aspect-based sentiment analysis. However, they all ignore the separate modeling for targets. In other word, they don&#39;t have a separate model to learn the target text. In this paper, the author proposed an architecture which has 2 sub-networks used to model the both the contexts and the targets. They argued that targets and contexts can be modelled separately, but learned from their interaction. . When “short” is collocated with “battery life”, the sentiment tends to be negative. But when “short” is used with “spoon” in the context “Short fat noodle spoon, relatively deep some curva”, the sentiment can be neu- tral. Then, the next problem is how to simultaneously model targets and contexts precisely. First, target and context can determine representations of each other. For example, when we see the target “picture quality”, context word “clear-cut” is naturally associated with the target. And it is vice versa - “picture quality” is first connected with “clear-cut” . Also, contexts and targets both includes many words. Different words may have different contributions to the final representation. Therefore, in this paper, the author created 2 attention mechanisms to capture the important information for both contexts and targets. . from IPython.display import Image Image(filename=&#39;architecture.png&#39;) . The model is called interactive attention network (IAN). It is based on LSTM and attention mechanism. . The text input will be firstly converted to embeddings. Then they are feeded into LSTMs. After that, the authors averaged the hidden states of the context LSTM to get the inital representation of context (pool vector in the figure). They do the same for the target LSTM. Then they used the target pool vector in the context attention computation and vice versa. They argued that with this design, the target and context can influence the generation of their representations interactively. Lastly, they concatenate the target and context vector and feed it into the softmax layer to do the classification. . Explain using Query, Key, Value: Regarding the target LSTM, in the figure 1 the pool vector is computed by averaging hidden states of the LSTM. That vector will play as the query vector. Each hidden state vectors represents both the key and value vectors. Then just calculate the attention score as the step below: . Step 1: Calculate the similarity score between the query vector and all the key vectors. | Step 2: Normalize the score using softmax. | Step 3: Calculate the final representation vector by weighted average the value vectors using the normalized scores. | . Install and Import required packages . %%capture !pip install pytorch-lightning !pip install torchmetrics . import os import pickle from collections import Counter, OrderedDict from pathlib import Path from typing import Any, Dict, List, Optional, Tuple, Union from urllib.request import urlretrieve import numpy as np from tqdm import tqdm import pytorch_lightning as pl import torch import torch.nn as nn import torch.nn.functional as F import torchmetrics import torchtext from pytorch_lightning import loggers as pl_loggers from pytorch_lightning.callbacks import ModelCheckpoint from torch.nn.utils.rnn import (pack_padded_sequence, pad_packed_sequence, pad_sequence) from torch.utils.data import DataLoader, Dataset, random_split from torchtext.data import get_tokenizer from torchtext.vocab import Vectors, Vocab # For repoducibility pl.utilities.seed.seed_everything(seed=2401, workers=True) . Global seed set to 2401 . 2401 . Define dataset, dataloader class and utility functions . class TqdmUpTo(tqdm): &quot;&quot;&quot;From https://github.com/tqdm/tqdm/blob/master/examples/tqdm_wget.py&quot;&quot;&quot; def update_to(self, blocks=1, bsize=1, tsize=None): &quot;&quot;&quot; Parameters - blocks: int, optional Number of blocks transferred so far [default: 1]. bsize: int, optional Size of each block (in tqdm units) [default: 1]. tsize: int, optional Total size (in tqdm units). If [default: None] remains unchanged. &quot;&quot;&quot; if tsize is not None: self.total = tsize self.update(blocks * bsize - self.n) class Tokenizer(): def __init__(self, tokenizer: Any, is_lower=True): self.counter = Counter([&#39;&lt;pad&gt;&#39;, &#39;&lt;unk&gt;&#39;]) self.tokenizer = tokenizer self.vocab = self.update_vocab() self.is_lower = is_lower def update_vocab(self): sorted_by_freq_tuples = sorted(self.counter.items(), key=lambda x: x[1], reverse=True) ordered_dict = OrderedDict(sorted_by_freq_tuples) self.vocab = torchtext.vocab.vocab(ordered_dict, min_freq=1) def fit_on_texts(self, texts: List[str]): &quot;&quot;&quot; Updates internal vocabulary based on a list of texts. &quot;&quot;&quot; # lower and tokenize texts to sequences for text in texts: self.counter.update(self.tokenizer(text)) self.update_vocab() def texts_to_sequences(self, texts: List[str], reverse: bool=False, tensor: bool=True) -&gt; List[List[int]]: word2idx = self.vocab.get_stoi() sequences = [] for text in texts: if self.is_lower: text = text.lower() seq = [word2idx.get(word, word2idx[&#39;&lt;unk&gt;&#39;]) for word in self.tokenizer(text)] if reverse: seq = seq[::-1] if tensor: seq = torch.tensor(seq) sequences.append(seq) return sequences def text_to_sequence(self, text: str, reverse: bool=False, tensor: bool=True) -&gt; List[int]: if self.is_lower: text = text.lower() word2idx = self.vocab.get_stoi() seq = [word2idx.get(word, word2idx[&#39;&lt;unk&gt;&#39;]) for word in self.tokenizer(text)] if reverse: seq = seq[::-1] if tensor: seq = torch.tensor(seq) return seq def download_url(url, filename, directory=&#39;.&#39;): &quot;&quot;&quot;Download a file from url to filename, with a progress bar.&quot;&quot;&quot; if not os.path.exists(directory): os.makedirs(directory) path = os.path.join(directory, filename) with TqdmUpTo(unit=&quot;B&quot;, unit_scale=True, unit_divisor=1024, miniters=1) as t: urlretrieve(url, path, reporthook=t.update_to, data=None) # nosec return path def load_data_from(path: Union[str, Path]): sentences = [] targets = [] sentiments = [] with open(path, &#39;r&#39;) as f: lines = f.readlines() for index in range(0, len(lines), 3): text = lines[index].lower().strip() target = lines[index+1].lower().strip() text = text.replace(&#39;$t$&#39;, target) sentences.append(text) targets.append(target) sentiments.append(int(lines[index+2].strip())) return sentences, targets, sentiments def _preprocess_data(data, tokenizer): sentences, targets, sentiments = data # Create sentence sequences and aspects sequences sequences = tokenizer.texts_to_sequences(sentences) target_seqs = tokenizer.texts_to_sequences(targets) sentiments = torch.tensor(sentiments) + 1 # pad sequences seq_lens = torch.tensor([len(seq) for seq in sequences]) target_lens = torch.tensor([len(target_seq) for target_seq in target_seqs]) sequences = pad_sequence(sequences, batch_first=True) target_seqs = pad_sequence(target_seqs, batch_first=True) assert len(sequences) == len(sentiments) assert len(sequences) == len(target_seqs) all_data = [] for i in range(len(sentiments)): sample = { &#39;context_seq&#39;: sequences[i], &#39;context_len&#39;: seq_lens[i], &#39;target_seq&#39;: target_seqs[i], &#39;target_len&#39;: target_lens[i], &#39;sentiment&#39;: sentiments[i] } all_data.append(sample) return all_data def build_vocab(tokenizer, data): sentences = data[0] tokenizer.fit_on_texts(sentences) def load_pretrained_word_embeddings(options: Dict[str, Any]): return torchtext.vocab.GloVe(options[&#39;name&#39;], options[&#39;dim&#39;]) def create_embedding_matrix(word_embeddings: Vectors, vocab: Vocab, path: Union[str, Path]): if os.path.exists(path): print(f&#39;loading embedding matrix from {path}&#39;) embedding_matrix = pickle.load(open(path, &#39;rb&#39;)) else: embedding_matrix = torch.zeros((len(vocab), word_embeddings.dim), dtype=torch.float) # words that are not availabel in the pretrained word embeddings will be zeros for word, index in vocab.get_stoi().items(): embedding_matrix[index] = word_embeddings.get_vecs_by_tokens(word) # save embedding matrix pickle.dump(embedding_matrix, open(path, &#39;wb&#39;)) return embedding_matrix . class SemEvalDataset(Dataset): def __init__(self, data): self.data = data def __len__(self): return len(self.data) def __getitem__(self, idx): return self.data[idx] . RES_TRAIN_DS_URL = &#39;https://raw.githubusercontent.com/songyouwei/ABSA-PyTorch/master/datasets/semeval14/Restaurants_Train.xml.seg&#39; RES_TEST_DS_URL = &#39;https://raw.githubusercontent.com/songyouwei/ABSA-PyTorch/master/datasets/semeval14/Restaurants_Test_Gold.xml.seg&#39; # Laptop LAP_TRAIN_DS_URL = &#39;https://raw.githubusercontent.com/songyouwei/ABSA-PyTorch/master/datasets/semeval14/Laptops_Train.xml.seg&#39; LAP_TEST_DS_URL = &#39;https://raw.githubusercontent.com/songyouwei/ABSA-PyTorch/master/datasets/semeval14/Laptops_Test_Gold.xml.seg&#39; class SemEval2014(pl.LightningDataModule): def __init__(self, tokenizer, opts): super().__init__() self.tokenizer = tokenizer self.batch_size = opts[&#39;batch_size&#39;] self.num_workers = opts[&#39;num_workers&#39;] self.on_gpu = opts[&#39;on_gpu&#39;] self.mapping = {&quot;negative&quot;: 0, &quot;neutral&quot;: 1, &quot;positive&quot;: 2} self.inverse_mapping = {v: k for k, v in enumerate(self.mapping)} def prepare_data(self) -&gt; None: self.train_path = &#39;download/SemEval2014/train.xml&#39; self.test_path = &#39;download/SemEval2014/test.xml&#39; if not os.path.exists(train_path): print(&quot;Downloading train dataset&quot;) self.train_path = download_url(RES_TRAIN_DS_URL, &#39;train.xml&#39;, &#39;download/SemEval2014&#39;) if not os.path.exists(test_path): print(&quot;Downloading test dataset&quot;) self.test_path = download_url(RES_TEST_DS_URL, &#39;test.xml&#39;, &#39;download/SemEval2014&#39;) def setup(self, stage: str = None) -&gt; None: if stage == &#39;fit&#39; or stage is None: # Load data from files train_data = load_data_from(self.train_path) valid_data = load_data_from(self.test_path) self.train_data = _preprocess_data(train_data, self.tokenizer) self.val_data = _preprocess_data(valid_data, self.tokenizer) elif stage == &#39;test&#39; or stage is None: test_data = load_data_from(self.test_path) self.test_data = _preprocess_data(test_data, self.tokenizer) def train_dataloader(self): # Create Dataset object train_ds = SemEvalDataset(self.train_data) # Create Dataloader return DataLoader( train_ds, shuffle=True, batch_size=self.batch_size, num_workers=self.num_workers, pin_memory=self.on_gpu, ) def val_dataloader(self): val_ds = SemEvalDataset(self.val_data) return DataLoader( val_ds, shuffle=False, batch_size=self.batch_size, num_workers=self.num_workers, pin_memory=self.on_gpu, ) def test_dataloader(self): test_ds = SemEvalDataset(self.test_data) return DataLoader( test_ds, shuffle=False, batch_size=self.batch_size, num_workers=self.num_workers, pin_memory=self.on_gpu, ) def __repr__(self): basic = f&quot;SemEval2014 Dataset nNum classes: {len(self.mapping)} nMapping: {self.mapping} n&quot; if self.train_data is None and self.val_data is None and self.test_data is None: return basic batch = next(iter(self.train_dataloader())) cols = [&#39;context_seq&#39;, &#39;context_len&#39;, &#39;target_seq&#39;, &#39;target_len&#39;, &#39;sentiment&#39;] context_seqs, context_lens, target_seqs, target_lens, sentiments = [batch[col] for col in cols] data = ( f&quot;Train/val/test sizes: {len(self.train_data)}, {len(self.val_data)}, {len(self.test_data)} n&quot; f&quot;Batch context_seqs stats: {(context_seqs.shape, context_seqs.dtype)} n&quot; f&quot;Batch context_lens stats: {(context_lens.shape, context_lens.dtype)} n&quot; f&quot;Batch target_seqs stats: {(target_seqs.shape, target_seqs.dtype)} n&quot; f&quot;Batch target_lens stats: {(target_lens.shape, target_lens.dtype)} n&quot; f&quot;Batch sentiments stats: {(sentiments.shape, sentiments.dtype)} n&quot; ) return basic + data . Implementation . class Attention(nn.Module): def __init__(self, hidden_size): super(Attention, self).__init__() self.linear = nn.Linear(hidden_size, hidden_size) def forward(self, query, key, value, max_seq_len, seq_lens, device): # Calculate similarity between query and key vectors score = torch.tanh(torch.matmul( self.linear(key), query.transpose(-2,-1))).squeeze(-1) # BxL # Mask out padding score att_mask = torch.arange(max_seq_len, device=device)[None,:] &lt; seq_lens[:, None] score = score.masked_fill(att_mask == False, float(&#39;-inf&#39;)) softmax_score = F.softmax(score, dim=-1).unsqueeze(2) #BxLx1 out = torch.matmul(value.transpose(-2,-1), softmax_score).squeeze() #BxH return out . class IAN(pl.LightningModule): def __init__(self, embedding_matrix, hidden_size, num_layers=1, num_classes=3, batch_first=True, lr=1e-3, dropout=0, l2reg=0.0): super().__init__() embedding_dim = embedding_matrix.shape[1] self.batch_first = batch_first self.lr = lr self.l2reg = l2reg # Define architecture components self.embedding = nn.Embedding.from_pretrained(embedding_matrix) self.target_lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=batch_first, dropout=dropout) self.context_lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=batch_first, dropout=dropout) self.context_attn = Attention(hidden_size) self.target_attn = Attention(hidden_size) self.linear = nn.Linear(hidden_size*2, num_classes) # Define metrics self.train_acc = torchmetrics.Accuracy() self.val_acc = torchmetrics.Accuracy() self.test_acc = torchmetrics.Accuracy() # Initialize layer parameters # for layer in [self.context_lstm, self.target_lstm, # self.context_attention, self.target_attention, self.linear]: # nn.init.uniform_(layer.weight, a=-0.1, b=0.1) def configure_optimizers(self): optim = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.l2reg) return optim def forward(self, input): cols = [&quot;context_seq&quot;, &quot;context_len&quot;, &quot;target_seq&quot;, &quot;target_len&quot;] padded_context_seqs, context_lens, padded_target_seqs, target_lens = [input[col] for col in cols] padded_context_embeddings = self.embedding(padded_context_seqs) padded_target_embeddings = self.embedding(padded_target_seqs) context_seqs_pack = pack_padded_sequence(padded_context_embeddings, context_lens.cpu(), batch_first=self.batch_first, enforce_sorted=False) target_seqs_pack = pack_padded_sequence(padded_target_embeddings, target_lens.cpu(), batch_first=self.batch_first, enforce_sorted=False) H_context, _ = self.context_lstm(context_seqs_pack) H_target, _ = self.target_lstm(target_seqs_pack) # Unpack to get the full hidden states padded_H_context, _ = pad_packed_sequence(H_context, batch_first=self.batch_first) # BxLxH padded_H_target, _ = pad_packed_sequence(H_target, batch_first=self.batch_first) # BxLxH # Compute the initial representation for target and context c_avg = torch.mean(padded_H_context, dim=1, keepdim=True) #Bx1xH t_avg = torch.mean(padded_H_target, dim=1, keepdim=True) #Bx1xH c_max_seq_len = torch.max(context_lens) final_c = self.context_attn(t_avg, padded_H_context, padded_H_context, c_max_seq_len, context_lens, self.device) t_max_seq_len = torch.max(target_lens) inal_t = self.target_attn(c_avg, padded_H_target, padded_H_target, t_max_seq_len, target_lens, self.device) final_vector = torch.cat([final_t, final_c], dim=-1) # Bx2H out = self.linear(final_vector) logits = torch.tanh(out) return logits def training_step(self, batch, batch_idx): sentiments = batch[&#39;sentiment&#39;] logits = self.forward(batch) loss = F.cross_entropy(logits, sentiments) scores = F.softmax(logits, dim=-1) self.train_acc(scores, sentiments) self.log(&#39;train_loss&#39;, loss, on_step=True, on_epoch=True, prog_bar=True) self.log(&#39;train_acc&#39;, self.train_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True) return loss def validation_step(self, batch, batch_idx): sentiments = batch[&#39;sentiment&#39;] logits = self.forward(batch) loss = F.cross_entropy(logits, sentiments) scores = F.softmax(logits, dim=-1) self.val_acc(scores, sentiments) self.log(&#39;val_loss&#39;, loss, on_step=True, on_epoch=True, prog_bar=True) self.log(&#39;val_acc&#39;, self.val_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True) def test_step(self, batch, batch_idx): sentiments = batch[&#39;sentiment&#39;] logits = self.forward(batch) scores = F.softmax(logits, dim=-1) self.test_acc(scores, sentiments) self.log(&#39;test_acc&#39;, self.test_acc, on_step=False, on_epoch=True, logger=True) . Training . processed_train_data = _preprocess_data(train_data, tokenizer) . train_path = download_url(RES_TRAIN_DS_URL, &#39;train.xml&#39;, &#39;download/SemEval2014&#39;) test_path = download_url(RES_TEST_DS_URL, &#39;test.xml&#39;, &#39;download/SemEval2014&#39;) train_data = load_data_from(train_path) test_data = load_data_from(test_path) all_sentences = train_data[0] + test_data[0] tokenizer = Tokenizer(get_tokenizer(&quot;basic_english&quot;)) build_vocab(tokenizer, [all_sentences]) . 384kB [00:00, 1.71MB/s] 120kB [00:00, 626kB/s] . word_embeddings = load_pretrained_word_embeddings({&quot;name&quot;: &quot;42B&quot;, &quot;dim&quot;: 300}) . .vector_cache/glove.42B.300d.zip: 1.88GB [05:53, 5.31MB/s] 100%|█████████▉| 1916797/1917494 [04:10&lt;00:00, 8178.84it/s] . train_path = download_url(RES_TRAIN_DS_URL, &#39;train.xml&#39;, &#39;download/SemEval2014&#39;) test_path = download_url(RES_TEST_DS_URL, &#39;test.xml&#39;, &#39;download/SemEval2014&#39;) train_data = load_data_from(train_path) test_data = load_data_from(test_path) all_sentences = train_data[0] + test_data[0] tokenizer = Tokenizer(get_tokenizer(&quot;basic_english&quot;)) build_vocab(tokenizer, [all_sentences]) options = { &quot;on_gpu&quot;: True, &quot;batch_size&quot;: 16, &quot;num_workers&quot;: 2 } datamodule = SemEval2014(tokenizer, options) embedding_matrix = create_embedding_matrix(word_embeddings, tokenizer.vocab, &quot;embedding_matrix.dat&quot;) . 384kB [00:00, 7.09MB/s] 120kB [00:00, 2.81MB/s] . loading embedding matrix from embedding_matrix.dat . torch.autograd.set_detect_anomaly(True) checkpoint_callback = ModelCheckpoint( monitor=&#39;val_acc&#39;, # save the model with the best validation accuracy dirpath=&#39;checkpoints&#39;, mode=&#39;max&#39;, ) tb_logger = pl_loggers.TensorBoardLogger(&#39;logs/&#39;) # create logger for tensorboard # Set hyper-parameters lr = 1e-3 hidden_size = 300 aspect_embedding_dim = 300 num_epochs = 30 l2reg = 1e-5 dropout = 0.0 trainer = pl.Trainer(gpus=1, max_epochs=num_epochs, logger=tb_logger, callbacks=[checkpoint_callback], deterministic=True) # trainer = pl.Trainer(fast_dev_run=True, gpus=1) #Debug # trainer = pl.Trainer(overfit_batches=0.025, max_epochs=num_epochs, gpus=1) #Debug model = IAN(embedding_matrix=embedding_matrix, hidden_size=hidden_size, lr=lr, l2reg=l2reg, dropout=dropout) trainer.fit(model, datamodule) . GPU available: True, used: True TPU available: False, using: 0 TPU cores LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params - 0 | embedding | Embedding | 1.4 M 1 | target_lstm | LSTM | 722 K 2 | context_lstm | LSTM | 722 K 3 | context_attn | Attention | 90.3 K 4 | target_attn | Attention | 90.3 K 5 | linear | Linear | 1.8 K 6 | train_acc | Accuracy | 0 7 | val_acc | Accuracy | 0 8 | test_acc | Accuracy | 0 - 1.6 M Trainable params 1.4 M Non-trainable params 3.0 M Total params 11.921 Total estimated model params size (MB) Global seed set to 2401 . . trainer.test(ckpt_path=checkpoint_callback.best_model_path, test_dataloaders=datamodule.test_dataloader()) . LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] . -- DATALOADER:0 TEST RESULTS {&#39;test_acc&#39;: 0.7866071462631226} -- . [{&#39;test_acc&#39;: 0.7866071462631226}] . Discussion . Our result: . Dataset Restaurants . IAN | 0.786 | . Paper result: . Dataset Restaurants Laptops . No-target | 0.772 | 0.708 | . No-interaction | 0.769 | 0.706 | . Target2Content | 0.775 | 0.712 | . IAN | 0.786 | 0.721 | . From the two table above, we can see that our training get the same accuracy value with the paper. . Analysis: . The author analyzed the IAN model effectiveness by comparing it with 3 other types of models. All the models are based on LSTM and attention mechanism. The No-target model does not model the representation of the target. The second model, No-interaction, used 2 LSTM networks to model the representations of target and context via their own local atttentions, but without interaction. Next, the Target2Content model also employs 2 LSTM networks to learn target and context representation, but only uses the pool target vector for the context attention computation. The difference between this model and the IAN is the IAN also use the pool context vector in target attetion computation. . The results verify that target should be separately modeled and target representations can make contribution to judging the sentiment polarity of a target. . The improvements on Restaurant category is much less than those on Laptop category. The author explained that by pointing out that the Restaurant dataset has 9% 1-word target more than the Laptop one. In other words, the Laptop dataset has more multi-words targets. In IAN, the targets are modeled by LSTM networks and interactive attentions. LSTM networks and interactive attention are more effective on modelling long targets than short ones. . You can read more about the case study in which the author analyzes the attention score when doing inference here. . Lesson . Pass device in forward function instead of __init__ | When masking, create a mask matrix and times with the matrix we want to mask. By doing that, we can avoid modifying the tensor in-place error. We can also use the function mask_fill with &#39;underscore&#39;. | When the training model is slow, check the number of model parameters! | When using functions that requires the dim, we should set it explicitly to avoid bugs in our code. For example, in this implementation, using squeeze() function after calculating the similariry score between query and key vectors has error when the sequence length of key is 1. | Suggestion for Readers: . You can try a larger word embeddings to see whether we can improve the metrics. | Training on the Laptop data | Have fun :) |",
            "url": "https://minhdang241.github.io/minhdg-blog/implementation/2021/07/04/NLP_5_Interactive_Attention_Networks_for_Aspect_Level_Sentiment_Classififcation.html",
            "relUrl": "/implementation/2021/07/04/NLP_5_Interactive_Attention_Networks_for_Aspect_Level_Sentiment_Classififcation.html",
            "date": " • Jul 4, 2021"
        }
        
    
  
    
        ,"post11": {
            "title": "Attention based LSTM for Aspect level Sentiment Classification",
            "content": "The full notebook is available here. . Introduction . Aspect-level sentiment classification is a fine- grained task in sentiment analysis. Since it provides more complete and in-depth results, aspect-level sentiment analysis has received much attention these years. In this paper, we reveal that the sentiment polarity of a sentence is not only determined by the content but is also highly related to the concerned aspect. For instance, “The appetizers are ok, but the service is slow.”, for aspect taste, the polarity is positive while for service, the polarity is negative. Therefore, it is worthwhile to explore the connection between an aspect and the content of a sentence. To this end, we propose an Attention-based Long Short-Term Memory Network for aspect-level sentiment classification. The attention mechanism can concentrate on different parts of a sentence when different aspects are taken as input. We experiment on the SemEval 2014 dataset and results show that our model achieves state-of- the-art performance on aspect-level sentiment classification. . Install required packages . %%capture !pip install pytorch-lightning !pip install torchmetrics . Import required packages . import os import pickle from collections import Counter, OrderedDict from pathlib import Path from typing import Any, Dict, List, Optional, Tuple, Union from urllib.request import urlretrieve import numpy as np from tqdm import tqdm import pytorch_lightning as pl import torch import torch.nn as nn import torch.nn.functional as F import torchmetrics import torchtext from pytorch_lightning import loggers as pl_loggers from pytorch_lightning.callbacks import ModelCheckpoint from torch.nn.utils.rnn import (pack_padded_sequence, pad_packed_sequence, pad_sequence) from torch.utils.data import DataLoader, Dataset, random_split from torchtext.data import get_tokenizer from torchtext.vocab import Vectors, Vocab import xml.etree.ElementTree as ET # For repoducibility pl.utilities.seed.seed_everything(seed=2401, workers=True) . /usr/local/lib/python3.7/dist-packages/pytorch_lightning/metrics/__init__.py:44: LightningDeprecationWarning: `pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package (https://github.com/PyTorchLightning/metrics) since v1.3 and will be removed in v1.5 &#34;`pytorch_lightning.metrics.*` module has been renamed to `torchmetrics.*` and split off to its own package&#34; Global seed set to 2401 . 2401 . Define dataset, data module class, utils function . class TqdmUpTo(tqdm): &quot;&quot;&quot;From https://github.com/tqdm/tqdm/blob/master/examples/tqdm_wget.py&quot;&quot;&quot; def update_to(self, blocks=1, bsize=1, tsize=None): &quot;&quot;&quot; Parameters - blocks: int, optional Number of blocks transferred so far [default: 1]. bsize: int, optional Size of each block (in tqdm units) [default: 1]. tsize: int, optional Total size (in tqdm units). If [default: None] remains unchanged. &quot;&quot;&quot; if tsize is not None: self.total = tsize self.update(blocks * bsize - self.n) class Tokenizer(): def __init__(self, tokenizer: Any): self.counter = Counter([&#39;&lt;pad&gt;&#39;, &#39;&lt;unk&gt;&#39;]) self.tokenizer = tokenizer self.vocab = self.update_vocab() def update_vocab(self): sorted_by_freq_tuples = sorted(self.counter.items(), key=lambda x: x[1], reverse=True) ordered_dict = OrderedDict(sorted_by_freq_tuples) self.vocab = torchtext.vocab.vocab(ordered_dict, min_freq=1) def fit_on_texts(self, texts: List[str]): &quot;&quot;&quot; Updates internal vocabulary based on a list of texts. &quot;&quot;&quot; # lower and tokenize texts to sequences for text in texts: self.counter.update(self.tokenizer(text)) self.update_vocab() def texts_to_sequences(self, texts: List[str], reverse: bool=False, tensor: bool=True) -&gt; List[int]: word2idx = self.vocab.get_stoi() sequences = [] for text in texts: seq = [word2idx.get(word, word2idx[&#39;&lt;unk&gt;&#39;]) for word in self.tokenizer(text)] if reverse: seq = seq[::-1] if tensor: seq = torch.tensor(seq) sequences.append(seq) return sequences def download_url(url, filename, directory=&#39;.&#39;): &quot;&quot;&quot;Download a file from url to filename, with a progress bar.&quot;&quot;&quot; if not os.path.exists(directory): os.makedirs(directory) path = os.path.join(directory, filename) with TqdmUpTo(unit=&quot;B&quot;, unit_scale=True, unit_divisor=1024, miniters=1) as t: urlretrieve(url, path, reporthook=t.update_to, data=None) # nosec return path def _preprocess_data(data, tokenizer, mapping_polarity, mapping_aspect): sentences, text_aspects, text_sentiments = data # Create sentence sequences and aspects sequences sequences = tokenizer.texts_to_sequences(sentences) sentiments = [] for val in text_sentiments: sentiments.append(mapping_polarity[val]) sentiments = torch.tensor(sentiments) aspects = [] for val in text_aspects: aspects.append(mapping_aspect[val]) aspects = torch.tensor(aspects) # pad sequences seq_lens = torch.tensor([len(seq) for seq in sequences]) sequences = pad_sequence(sequences, batch_first=True) assert len(sequences) == len(sentiments) assert len(sequences) == len(aspects) all_data = [] for i in range(len(sentiments)): sample = { &#39;sequence&#39;: sequences[i], &#39;seq_len&#39;: seq_lens[i], &#39;aspect&#39;: aspects[i], &#39;sentiment&#39;: sentiments[i] } all_data.append(sample) return all_data def load_data_from(path: Union[str, Path]): tree = ET.parse(path) root = tree.getroot() sentences = [] aspects = [] sentiments = [] for sent in root: text = &#39;&#39; for i, child in enumerate(sent): if i == 0: text = child.text elif i == 2: for aspect in child: # Get polarities polarity = aspect.attrib[&#39;polarity&#39;].lower().strip() if polarity == &quot;conflict&quot;: continue sentiments.append(polarity) # Get aspects asp = aspect.attrib[&#39;category&#39;].lower().strip() if asp == &#39;anecdotes/miscellaneous&#39;: aspects.append(&#39;miscellaneous&#39;) else: aspects.append(asp) # Get sentences sentences.append(text) return sentences, aspects, sentiments def build_vocab(tokenizer, data): sentences = data[0] tokenizer.fit_on_texts(sentences) def load_pretrained_word_embeddings(options: Dict[str, Any]): return torchtext.vocab.GloVe(options[&#39;name&#39;], options[&#39;dim&#39;]) def create_embedding_matrix(word_embeddings: Vectors, vocab: Vocab, path: Union[str, Path]): if os.path.exists(path): print(f&#39;loading embedding matrix from {path}&#39;) embedding_matrix = pickle.load(open(path, &#39;rb&#39;)) else: embedding_matrix = torch.zeros((len(vocab), word_embeddings.dim), dtype=torch.float) # words that are not availabel in the pretrained word embeddings will be zeros for word, index in vocab.get_stoi().items(): embedding_matrix[index] = word_embeddings.get_vecs_by_tokens(word) # save embedding matrix pickle.dump(embedding_matrix, open(path, &#39;wb&#39;)) return embedding_matrix . class SemEvalDataset(Dataset): def __init__(self, data): self.data = data def __len__(self): return len(self.data) def __getitem__(self, idx): return self.data[idx] . TRAIN_DS_URL = &#39;https://raw.githubusercontent.com/zhangjf-nlp/ATAE-LSTM/master/data/restaurants-train.xml&#39; VALID_DS_URL = &#39;https://raw.githubusercontent.com/zhangjf-nlp/ATAE-LSTM/master/data/restaurants-trial.xml&#39; TEST_DS_URL = &quot;https://raw.githubusercontent.com/AlexYangLi/ABSA_Keras/master/raw_data/semeval14_restaurant/Restaurants_Test_Gold.xml&quot; class SemEval2014(pl.LightningDataModule): def __init__(self, tokenizer, opts): super().__init__() self.tokenizer = tokenizer self.batch_size = opts[&#39;batch_size&#39;] self.num_workers = opts[&#39;num_workers&#39;] self.on_gpu = opts[&#39;on_gpu&#39;] self.mapping = {&quot;negative&quot;: 0, &quot;neutral&quot;: 1, &quot;positive&quot;: 2} self.mapping_aspects = {&#39;ambience&#39;: 0, &#39;food&#39;: 1, &#39;miscellaneous&#39;: 2, &#39;price&#39;: 3, &#39;service&#39;: 4} self.inverse_mapping = {v: k for k, v in enumerate(self.mapping)} def prepare_data(self, *args, **kwargs) -&gt; None: self.train_path = &#39;download/SemEval2014/train.xml&#39; self.valid_path = &#39;download/SemEval2014/valid.xml&#39; self.test_path = &#39;download/SemEval2014/test.xml&#39; if not os.path.exists(train_path): print(&quot;Downloading train dataset&quot;) self.train_path = download_url(TRAIN_DS_URL, &#39;train.xml&#39;, &#39;download/SemEval2014&#39;) if not os.path.exists(valid_path): print(&quot;Downloading valid dataset&quot;) self.valid_path = download_url(VALID_DS_URL, &#39;valid.xml&#39;, &#39;download/SemEval2014&#39;) if not os.path.exists(test_path): print(&quot;Downloading test dataset&quot;) self.test_path = download_url(TEST_DS_URL, &#39;test.xml&#39;, &#39;download/SemEval2014&#39;) def setup(self, stage: str = None) -&gt; None: if stage == &#39;fit&#39; or stage is None: # Load data from files train_data = load_data_from(self.train_path) valid_data = load_data_from(self.valid_path) self.train_data = _preprocess_data(train_data, self.tokenizer, self.mapping, self.mapping_aspects) self.val_data = _preprocess_data(valid_data, self.tokenizer, self.mapping, self.mapping_aspects) elif stage == &#39;test&#39; or stage is None: test_data = load_data_from(self.test_path) self.test_data = _preprocess_data(test_data, self.tokenizer, self.mapping, self.mapping_aspects) def train_dataloader(self): # Create Dataset object train_ds = SemEvalDataset(self.train_data) # Create Dataloader return DataLoader( train_ds, shuffle=True, batch_size=self.batch_size, num_workers=self.num_workers, pin_memory=self.on_gpu, ) def val_dataloader(self): val_ds = SemEvalDataset(self.val_data) return DataLoader( val_ds, shuffle=False, batch_size=self.batch_size, num_workers=self.num_workers, pin_memory=self.on_gpu, ) def test_dataloader(self): test_ds = SemEvalDataset(self.test_data) return DataLoader( test_ds, shuffle=False, batch_size=self.batch_size, num_workers=self.num_workers, pin_memory=self.on_gpu, ) def __repr__(self): basic = f&quot;SemEval2014 Dataset nNum classes: {len(self.mapping)} nMapping: {self.mapping} n&quot; if self.train_data is None and self.val_data is None and self.test_data is None: return basic batch = next(iter(self.train_dataloader())) sequences, seq_lens, aspects, sentiments = batch[&#39;sequence&#39;], batch[&#39;seq_len&#39;], batch[&#39;aspect&#39;], batch[&#39;sentiment&#39;] data = ( f&quot;Train/val/test sizes: {len(self.train_data)}, {len(self.val_data)}, {len(self.test_data)} n&quot; f&quot;Batch sequences stats: {(sequences.shape, sequences.dtype)} n&quot; f&quot;Batch seq_lens stats: {(seq_lens.shape, seq_lens.dtype)} n&quot; f&quot;Batch aspects stats: {(aspects.shape, aspects.dtype)} n&quot; f&quot;Batch sentiments stats: {(sentiments.shape, sentiments.dtype)} n&quot; ) return basic + data . Implementation . AT-LSTM . LSTM with Aspect Embedding (AE-LSTM) . Aspect information is important when doing classificaiton on the sentence. We may get different polarities with different aspects. The author proposed to learn an embedding vector for each aspect. . Attention-based LSTM (AT-LSTM) . The standard LSTM cannot detect which is the important part for aspect-level sentiment classification. The author proposed to design an attention mechanism capturing the key part of sentence in response to a given aspect. . from IPython.display import Image Image(filename=&#39;/Users/minhdang/Desktop/AT-LSTM.png&#39;) . class AT_LSTM(pl.LightningModule): def __init__(self, embeddings, hidden_size, aspect_hidden_size, num_layers=1, num_classes=3, batch_first=True, lr=1e-3, dropout=0, l2reg=0.01): super().__init__() embedding_dim = embeddings.shape[1] self.embedding = nn.Embedding.from_pretrained(embeddings) # load pre-trained word embeddings self.aspect_embedding = nn.Embedding(5, embedding_dim) self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=batch_first, dropout=dropout) self.linear_h = nn.Linear(hidden_size, hidden_size, bias=False) self.linear_v = nn.Linear(aspect_hidden_size, aspect_hidden_size, bias=False) self.linear_p = nn.Linear(hidden_size, hidden_size, bias=False) self.linear_x = nn.Linear(hidden_size, hidden_size, bias=False) self.linear = nn.Linear(hidden_size + aspect_hidden_size, 1) self.linear_s = nn.Linear(hidden_size, num_classes) self.batch_first = batch_first self.lr = lr self.l2reg = l2reg # Define metrics self.train_acc = torchmetrics.Accuracy() self.val_acc = torchmetrics.Accuracy() self.val_f1 = torchmetrics.F1(num_classes=3, average=&#39;macro&#39;) self.test_acc = torchmetrics.Accuracy() self.test_f1 = torchmetrics.F1(num_classes=3, average=&#39;macro&#39;) def configure_optimizers(self): optim = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.l2reg) return optim def forward(self, input): sequences, seq_lens, aspect_seqs = input[&#39;sequence&#39;], input[&#39;seq_len&#39;], input[&#39;aspect&#39;] # Covert sequence to embeddings embeds = self.embedding(sequences) # Get the max sequence length max_seq_len = torch.max(seq_lens) # Convert aspect to embeddings aspect_embeds = self.aspect_embedding(aspect_seqs) packed_embeds = pack_padded_sequence(embeds, seq_lens.cpu(), batch_first=self.batch_first, enforce_sorted=False) H, (h, c) = self.lstm(packed_embeds) padded_H, lens = pad_packed_sequence(H, batch_first=True) Wh_H = self.linear_h(padded_H) Wv_va = self.linear_v(aspect_embeds) Wv_va = Wv_va.unsqueeze(1).repeat(1, max_seq_len, 1) M = torch.tanh(torch.cat([Wh_H, Wv_va], dim=-1)) # Calculate attention score score = self.linear(M).squeeze() att_mask = torch.arange(max_seq_len, device=self.device)[None,:] &lt; seq_lens[:, None] # Create mask to zero out attention scores for padding tokens score[~att_mask] = float(&#39;-inf&#39;) alpha = F.softmax(score, dim=-1).unsqueeze(2) r = torch.matmul(padded_H.transpose(-2,-1), alpha).squeeze() final_h = torch.tanh(self.linear_p(r) + self.linear_x(h[-1])) out = self.linear_s(final_h) return out def training_step(self, batch, batch_idx): sentiments = batch[&#39;sentiment&#39;] logits = self.forward(batch) loss = F.cross_entropy(logits, sentiments) scores = F.softmax(logits, dim=-1) self.train_acc(scores, sentiments) self.log(&#39;train_loss&#39;, loss, on_step=True, on_epoch=True, prog_bar=True) self.log(&#39;train_acc&#39;, self.train_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True) return loss def validation_step(self, batch, batch_idx): # pylint: disable=unused-argument sentiments = batch[&#39;sentiment&#39;] logits = self.forward(batch) loss = F.cross_entropy(logits, sentiments) scores = F.softmax(logits, dim=-1) self.val_acc(scores, sentiments) self.val_f1(scores, sentiments) self.log(&#39;val_loss&#39;, loss, on_step=True, on_epoch=True, prog_bar=True) self.log(&#39;val_acc&#39;, self.val_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True) self.log(&#39;val_f1&#39;, self.val_f1, on_step=False, on_epoch=True, prog_bar=True, logger=True) def test_step(self, batch, batch_idx): # pylint: disable=unused-argument sentiments = batch[&#39;sentiment&#39;] logits = self.forward(batch) scores = F.softmax(logits, dim=-1) self.test_acc(scores, sentiments) self.test_f1(scores, sentiments) self.log(&#39;test_acc&#39;, self.test_acc, on_step=False, on_epoch=True, logger=True) self.log(&#39;test_f1&#39;, self.test_f1, on_step=False, on_epoch=True, logger=True) . ATAE-LSTM . To take advanatage of aspect information, we append the input aspect embedding into each word input vector. By doing that, the inter-dependence between words and the input aspect can be modeled. . from IPython.display import Image Image(filename=&#39;/Users/minhdang/Desktop/ATAE-LSTM.png&#39;) . class ATAE_LSTM(pl.LightningModule): def __init__(self, embeddings, hidden_size, aspect_hidden_size, num_layers=1, num_classes=3, batch_first=True, lr=1e-3, dropout=0, l2reg=0.01): super().__init__() embedding_dim = embeddings.shape[1] self.embedding = nn.Embedding.from_pretrained(embeddings) # load pre-trained word embeddings self.aspect_embedding = nn.Embedding(5, embedding_dim) self.lstm = nn.LSTM(2*embedding_dim, hidden_size, num_layers, batch_first=batch_first, dropout=dropout) self.linear_h = nn.Linear(hidden_size, hidden_size, bias=False) self.linear_v = nn.Linear(aspect_hidden_size, aspect_hidden_size, bias=False) self.linear_p = nn.Linear(hidden_size, hidden_size, bias=False) self.linear_x = nn.Linear(hidden_size, hidden_size, bias=False) self.linear = nn.Linear(hidden_size + aspect_hidden_size, 1) self.linear_s = nn.Linear(hidden_size, num_classes) self.batch_first = batch_first self.lr = lr self.l2reg = l2reg # Define metrics self.train_acc = torchmetrics.Accuracy() self.val_acc = torchmetrics.Accuracy() self.val_f1 = torchmetrics.F1(num_classes=3, average=&#39;macro&#39;) self.test_acc = torchmetrics.Accuracy() self.test_f1 = torchmetrics.F1(num_classes=3, average=&#39;macro&#39;) def configure_optimizers(self): optim = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.l2reg) return optim def forward(self, input): sequences, seq_lens, aspect_seqs = input[&#39;sequence&#39;], input[&#39;seq_len&#39;], input[&#39;aspect&#39;] # Covert sequence to embeddings embeds = self.embedding(sequences) # Get the max sequence length max_seq_len = torch.max(seq_lens) # Convert aspect to embeddings aspect_embeds = self.aspect_embedding(aspect_seqs) # Repeat the aspect vector across the dimension 1 aspect_embeds_repeat = aspect_embeds.unsqueeze(1).repeat(1,embeds.shape[1],1) # Append the aspect vector to the input word vector embeds = torch.cat([embeds, aspect_embeds_repeat], dim=-1) packed_embeds = pack_padded_sequence(embeds, seq_lens.cpu(), batch_first=self.batch_first, enforce_sorted=False) H, (h, c) = self.lstm(packed_embeds) padded_H, lens = pad_packed_sequence(H, batch_first=True) Wh_H = self.linear_h(padded_H) Wv_va = self.linear_v(aspect_embeds) Wv_va = Wv_va.unsqueeze(1).repeat(1, max_seq_len, 1) M = torch.tanh(torch.cat([Wh_H, Wv_va], dim=-1)) # Calculate attention score score = self.linear(M).squeeze() # Create mask to zero out attention scores for padding tokens att_mask = torch.arange(max_seq_len, device=self.device)[None,:] &lt; seq_lens[:, None] score[~att_mask] = float(&#39;-inf&#39;) alpha = F.softmax(score, dim=-1).unsqueeze(2) r = torch.matmul(padded_H.transpose(-2,-1), alpha).squeeze() final_h = torch.tanh(self.linear_p(r) + self.linear_x(h[-1])) out = self.linear_s(final_h) return out def training_step(self, batch, batch_idx): sentiments = batch[&#39;sentiment&#39;] logits = self.forward(batch) loss = F.cross_entropy(logits, sentiments) scores = F.softmax(logits, dim=-1) self.train_acc(scores, sentiments) self.log(&#39;train_loss&#39;, loss, on_step=True, on_epoch=True, prog_bar=True) self.log(&#39;train_acc&#39;, self.train_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True) return loss def validation_step(self, batch, batch_idx): # pylint: disable=unused-argument sentiments = batch[&#39;sentiment&#39;] logits = self.forward(batch) loss = F.cross_entropy(logits, sentiments) scores = F.softmax(logits, dim=-1) self.val_acc(scores, sentiments) self.val_f1(scores, sentiments) self.log(&#39;val_loss&#39;, loss, on_step=True, on_epoch=True, prog_bar=True) self.log(&#39;val_acc&#39;, self.val_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True) self.log(&#39;val_f1&#39;, self.val_f1, on_step=False, on_epoch=True, prog_bar=True, logger=True) def test_step(self, batch, batch_idx): # pylint: disable=unused-argument sentiments = batch[&#39;sentiment&#39;] logits = self.forward(batch) scores = F.softmax(logits, dim=-1) self.test_acc(scores, sentiments) self.test_f1(scores, sentiments) self.log(&#39;test_acc&#39;, self.test_acc, on_step=False, on_epoch=True, logger=True) self.log(&#39;test_f1&#39;, self.test_f1, on_step=False, on_epoch=True, logger=True) . Training . word_embeddings = load_pretrained_word_embeddings({&quot;name&quot;: &quot;840B&quot;, &quot;dim&quot;: 300}) . train_path = download_url(TRAIN_DS_URL, &#39;train.xml&#39;, &#39;download/SemEval2014&#39;) valid_path = download_url(VALID_DS_URL, &#39;valid.xml&#39;, &#39;download/SemEval2014&#39;) test_path = download_url(TEST_DS_URL, &#39;test.xml&#39;, &#39;download/SemEval2014&#39;) train_data = load_data_from(train_path) valid_data = load_data_from(valid_path) test_data = load_data_from(test_path) all_sentences = train_data[0] + valid_data[0] + test_data[0] tokenizer = Tokenizer(get_tokenizer(&quot;basic_english&quot;)) build_vocab(tokenizer, [all_sentences]) options = { &quot;on_gpu&quot;: True, &quot;batch_size&quot;: 64, &quot;num_workers&quot;: 2 } datamodule = SemEval2014(tokenizer, options) embedding_matrix = create_embedding_matrix(word_embeddings, tokenizer.vocab, &quot;embedding_matrix.dat&quot;) . 1.18MB [00:00, 9.47MB/s] 40.0kB [00:00, 1.78MB/s] 352kB [00:00, 12.3MB/s] . loading embedding matrix from embedding_matrix.dat . AT-LSTM . checkpoint_callback = ModelCheckpoint( monitor=&#39;val_acc&#39;, # save the model with the best validation accuracy dirpath=&#39;checkpoints&#39;, mode=&#39;max&#39;, ) tb_logger = pl_loggers.TensorBoardLogger(&#39;logs/&#39;) # create logger for tensorboard # Set hyper-parameters lr = 1e-3 hidden_size = 300 aspect_embedding_dim = 300 num_epochs = 30 l2reg = 0.0 trainer = pl.Trainer(gpus=1, max_epochs=num_epochs, logger=tb_logger, callbacks=[checkpoint_callback], deterministic=True) # trainer = pl.Trainer(fast_dev_run=True) #Debug # trainer = pl.Trainer(overfit_batches=0.025, max_epochs=num_epochs) #Debug model = AT_LSTM(embedding_matrix, hidden_size, aspect_embedding_dim, lr=lr, l2reg=l2reg) trainer.fit(model, datamodule) . GPU available: True, used: True TPU available: False, using: 0 TPU cores LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params 0 | embedding | Embedding | 1.3 M 1 | aspect_embedding | Embedding | 1.5 K 2 | lstm | LSTM | 722 K 3 | linear_h | Linear | 90.0 K 4 | linear_v | Linear | 90.0 K 5 | linear_p | Linear | 90.0 K 6 | linear_x | Linear | 90.0 K 7 | linear | Linear | 601 8 | linear_s | Linear | 903 9 | train_acc | Accuracy | 0 10 | val_acc | Accuracy | 0 11 | val_f1 | F1 | 0 12 | test_acc | Accuracy | 0 13 | test_f1 | F1 | 0 1.1 M Trainable params 1.3 M Non-trainable params 2.4 M Total params 9.708 Total estimated model params size (MB) Global seed set to 2401 . . trainer.test(ckpt_path=checkpoint_callback.best_model_path) . LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] . -- DATALOADER:0 TEST RESULTS {&#39;test_acc&#39;: 0.8150510191917419, &#39;test_f1&#39;: 0.6747192740440369} -- . [{&#39;test_acc&#39;: 0.8150510191917419, &#39;test_f1&#39;: 0.6747192740440369}] . ATAE-LSTM . checkpoint_callback = ModelCheckpoint( monitor=&#39;val_acc&#39;, # save the model with the best validation accuracy dirpath=&#39;checkpoints&#39;, mode=&#39;max&#39;, ) tb_logger = pl_loggers.TensorBoardLogger(&#39;logs/&#39;) # create logger for tensorboard # Set hyper-parameters lr = 1e-3 hidden_size = 300 aspect_embedding_dim = 300 num_epochs = 30 l2reg = 0.0 trainer = pl.Trainer(gpus=1, max_epochs=num_epochs, logger=tb_logger, callbacks=[checkpoint_callback], deterministic=True) # trainer = pl.Trainer(fast_dev_run=True) #Debug # trainer = pl.Trainer(overfit_batches=0.025, max_epochs=num_epochs) #Debug model = ATAE_LSTM(embedding_matrix, hidden_size, aspect_embedding_dim, lr=lr, l2reg=l2reg) trainer.fit(model, datamodule) . GPU available: True, used: True TPU available: False, using: 0 TPU cores LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params 0 | embedding | Embedding | 1.3 M 1 | aspect_embedding | Embedding | 1.5 K 2 | lstm | LSTM | 1.1 M 3 | linear_h | Linear | 90.0 K 4 | linear_v | Linear | 90.0 K 5 | linear_p | Linear | 90.0 K 6 | linear_x | Linear | 90.0 K 7 | linear | Linear | 601 8 | linear_s | Linear | 903 9 | train_acc | Accuracy | 0 10 | val_acc | Accuracy | 0 11 | val_f1 | F1 | 0 12 | test_acc | Accuracy | 0 13 | test_f1 | F1 | 0 1.4 M Trainable params 1.3 M Non-trainable params 2.8 M Total params 11.148 Total estimated model params size (MB) Global seed set to 2401 . . trainer.test(ckpt_path=checkpoint_callback.best_model_path) . LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] . -- DATALOADER:0 TEST RESULTS {&#39;test_acc&#39;: 0.8227040767669678, &#39;test_f1&#39;: 0.6682634353637695} -- . [{&#39;test_acc&#39;: 0.8227040767669678, &#39;test_f1&#39;: 0.6682634353637695}] . Discussion . Since I could not find out the exact dataset used in the paper, it is impossible to compare with the paper&#39;s result. Instead, I will compare my implementation with other implementations from Github. . Our result . Model Accuracy F1 macro . AT-LSTM | 0.81 | 0.674 | . ATAE-LSTM | 0.82 | 0.668 | . There is a unbalance between positive, negative and positive classes in both train, valid and test set. That&#39;s the reason why we have the F1 macro lower than the accuracy. .",
            "url": "https://minhdang241.github.io/minhdg-blog/implementation/2021/06/26/NLP_4_Attention_based_LSTM_for_Aspect_level_Sentiment_Classification.html",
            "relUrl": "/implementation/2021/06/26/NLP_4_Attention_based_LSTM_for_Aspect_level_Sentiment_Classification.html",
            "date": " • Jun 26, 2021"
        }
        
    
  
    
        ,"post12": {
            "title": "PhoBERT Vietnamese Sentiment Analysis on UIT-VSFC dataset with transformers and Pytorch Lightning",
            "content": "The full notebook is available here. . Introduction . PhoBERT: Pre-trained language models for Vietnamese . PhoBERT models are the SOTA language models for Vietnamese. There are two versions of PhoBERT, which are PhoBERT base and PhoBERT large. Their pretraining approach is based on RoBERTa which optimizes the BERT pre-training procedure for more robust performance. PhoBERT has achieved SOTA in many downstream task such as POS, Dependency parsing, NER and NLI. You can read more about the PhoBERT here. . UIT-VSFC: Vietnamese Students&#8217; Feedback Corpus . Vietnamese Students’ Feedback Corpus (UIT-VSFC) is the resource consists of over 16,000 sentences which are human-annotated with two different tasks: sentiment-based and topic-based classifications. . In this project, we will apply PhoBERT to do the sentiment classification task on UIT-VSFC dataset. We will use pytorch-lightning and transformers for this project. . Install required packages . %%capture !pip install pytorch-lightning !pip install torchmetrics !pip install transformers !pip install datasets . Import required packages . import os import zipfile from pathlib import Path from typing import Any, Dict, List, Optional, Tuple, Union from urllib.request import urlretrieve import pandas as pd from tqdm import tqdm import pytorch_lightning as pl import torch import torch.nn.functional as F import torchmetrics from datasets import load_dataset from pytorch_lightning import loggers as pl_loggers from pytorch_lightning.callbacks import ModelCheckpoint from torch.utils.data import DataLoader from transformers import (AutoModelForSequenceClassification, AutoTokenizer, DataCollatorWithPadding) # For repoducibility pl.utilities.seed.seed_everything(seed=2401, workers=True) . Global seed set to 2401 . 2401 . Define dataset, dataloader class and utility functions . class TqdmUpTo(tqdm): &quot;&quot;&quot;From https://github.com/tqdm/tqdm/blob/master/examples/tqdm_wget.py&quot;&quot;&quot; def update_to(self, blocks=1, bsize=1, tsize=None): &quot;&quot;&quot; Parameters - blocks: int, optional Number of blocks transferred so far [default: 1]. bsize: int, optional Size of each block (in tqdm units) [default: 1]. tsize: int, optional Total size (in tqdm units). If [default: None] remains unchanged. &quot;&quot;&quot; if tsize is not None: self.total = tsize # pylint: disable=attribute-defined-outside-init self.update(blocks * bsize - self.n) # will also set self.n = b * bsize def download_url(url, filename, directory=&#39;.&#39;): &quot;&quot;&quot;Download a file from url to filename, with a progress bar.&quot;&quot;&quot; if not os.path.exists(directory): os.makedirs(directory) path = os.path.join(directory, filename) with TqdmUpTo(unit=&quot;B&quot;, unit_scale=True, unit_divisor=1024, miniters=1) as t: urlretrieve(url, path, reporthook=t.update_to, data=None) # nosec return path def _load_data_from(data_dir: Union[str, Path]): fnames = [&#39;sentiments.txt&#39;, &#39;sents.txt&#39;, &#39;topics.txt&#39;] sentiments = [] sents = [] topics = [] for name in fnames: with open(f&quot;{data_dir}/{name}&quot;, &#39;r&#39;) as f: if name == &quot;sentiments.txt&quot;: sentiments = [int(line.strip()) for line in f.readlines()] elif name == &quot;sents.txt&quot;: sents = [line.strip() for line in f.readlines()] else: topics = [int(line.strip()) for line in f.readlines()] return sents, sentiments, topics def _save_to_csv(file_path: Union[str, Path], data): sents, sentiments, topics = data df = pd.DataFrame({ &quot;sents&quot;: sents, &quot;labels&quot;: sentiments, &quot;topics&quot;: topics }) df.to_csv(file_path, index=False) return file_path . Define the UIT_VSFC datamodule class. You can read more here. . DS_URL = &quot;https://drive.google.com/uc?export=download&amp;id=1zg7cbRF2nFuJ2Q-AB63xlKuwEX3dTBsx&quot; class UIT_VSFC(pl.LightningDataModule): &quot;&quot;&quot; The Twitter dataset is ndwritten character digits derived from the NIST Special Database 19 &quot;&quot;&quot; def __init__(self, tokenizer, opts: Dict[str, Any]): super().__init__() self.tokenizer = tokenizer self.batch_size = opts[&#39;batch_size&#39;] self.num_workers = opts[&#39;num_workers&#39;] self.on_gpu = opts[&#39;on_gpu&#39;] self.data_collator = DataCollatorWithPadding(tokenizer=tokenizer) self.dataset = None self.mapping = {&quot;negative&quot;: 0, &quot;neutral&quot;: 1, &quot;positive&quot;: 2} self.inverse_mapping = {v: k for k, v in enumerate(self.mapping)} def prepare_data(self, *args, **kwargs) -&gt; None: data_dir = &#39;download/UIT_VSFC&#39; data_path = &#39;download/UIT_VSFC.zip&#39; if not os.path.exists(data_path): # Download the data data_path = download_url(DS_URL, &quot;UIT_VSFC.zip&quot;, &quot;download&quot;) if not os.path.exists(data_dir): # Unzip file with zipfile.ZipFile(data_path, &#39;r&#39;) as zip_ref: zip_ref.extractall(data_dir) # Load and save data to csv for path in [&quot;train&quot;, &quot;dev&quot;, &quot;test&quot;]: data = _load_data_from(f&quot;download/UIT_VSFC/{path}&quot;) if path == &quot;train&quot;: self.train_path = _save_to_csv(f&#39;{path}.csv&#39;, data) elif path == &quot;dev&quot;: self.dev_path = _save_to_csv(f&#39;{path}.csv&#39;, data) else: self.test_path = _save_to_csv(f&#39;{path}.csv&#39;, data) def setup(self, stage: str = None) -&gt; None: def encode(sample): return self.tokenizer(sample[&#39;sents&#39;], truncation=True) raw_datasets = load_dataset(&#39;csv&#39;, data_files={&#39;train&#39;: self.train_path, &#39;dev&#39;: self.dev_path, &#39;test&#39;: self.test_path}) self.dataset = raw_datasets.map(encode, batched=True) self.dataset = self.dataset.remove_columns( [&#39;sents&#39;, &#39;topics&#39;] ) self.dataset.set_format(&quot;torch&quot;) # Set the format of the datasets so they return PyTorch tensors instead of lists. def train_dataloader(self): return DataLoader( self.dataset[&#39;train&#39;], shuffle=True, batch_size=self.batch_size, num_workers=self.num_workers, pin_memory=self.on_gpu, collate_fn=self.data_collator ) def val_dataloader(self): return DataLoader( self.dataset[&#39;dev&#39;], shuffle=False, batch_size=self.batch_size, num_workers=self.num_workers, pin_memory=self.on_gpu, collate_fn=self.data_collator ) def test_dataloader(self): return DataLoader( self.dataset[&#39;test&#39;], shuffle=False, batch_size=self.batch_size, num_workers=self.num_workers, pin_memory=self.on_gpu, collate_fn=self.data_collator ) def __repr__(self): basic = f&quot;Twitter Dataset nNum classes: {len(self.mapping)} nMapping: {self.mapping} n&quot; if self.dataset is None: return basic batch = next(iter(self.train_dataloader())) data = ( f&quot;Train/val/test sizes: {len(self.dataset[&#39;train&#39;])}, {len(self.dataset[&#39;dev&#39;])}, {len(self.dataset[&#39;test&#39;])} n&quot; f&quot;Input_ids shape: {batch[&#39;input_ids&#39;].shape}&quot; ) return basic + data . Implementation . We will use the transformers model and wrapping it with the pytorch-lightning model class. This will help our code more clean and debug. You can read more about the pytorch-lightning model class here . class PhoBERT(pl.LightningModule): def __init__(self, lr, weight_decay): super().__init__() self.model = AutoModelForSequenceClassification.from_pretrained(&quot;vinai/phobert-base&quot;, num_labels=3) self.lr = lr self.weight_decay = weight_decay # Define metrics self.train_acc = torchmetrics.Accuracy() self.val_acc = torchmetrics.Accuracy() self.val_f1 = torchmetrics.F1(num_classes=3) self.test_acc = torchmetrics.Accuracy() self.test_f1 = torchmetrics.F1(num_classes=3) def configure_optimizers(self): return torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=self.weight_decay) def training_step(self, batch, batch_idx): outputs = self.model(**batch) loss, logits = outputs.loss, outputs.logits sentiments = batch[&#39;labels&#39;] scores = F.softmax(logits, dim=-1) self.train_acc(scores, sentiments) self.log(&#39;train_acc&#39;, self.train_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True) self.log(&#39;train_loss&#39;, loss, on_step=True, on_epoch=True, prog_bar=True, logger=True) return loss def validation_step(self, batch, batch_idx): outputs = self.model(**batch) loss, logits = outputs.loss, outputs.logits sentiments = batch[&#39;labels&#39;] scores = F.softmax(logits, dim=-1) self.val_acc(scores, sentiments) self.val_f1(scores, sentiments) self.log(&#39;val_loss&#39;, loss, on_step=True, on_epoch=True, prog_bar=True, logger=True) self.log(&#39;val_acc&#39;, self.val_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True) self.log(&#39;val_f1&#39;, self.val_f1, on_step=False, on_epoch=True, prog_bar=True, logger=True) def test_step(self, batch, batch_idx): outputs = self.model(**batch) logits = outputs.logits sentiments = batch[&#39;labels&#39;] scores = F.softmax(logits, dim=-1) self.test_acc(scores, sentiments) self.test_f1(scores, sentiments) self.log(&#39;test_acc&#39;, self.test_acc, on_step=False, on_epoch=True, logger=True) self.log(&#39;test_f1&#39;, self.test_f1, on_step=False, on_epoch=True, logger=True) . Training . tokenizer = AutoTokenizer.from_pretrained(&quot;vinai/phobert-base&quot;) options = { &quot;on_gpu&quot;: True, &quot;batch_size&quot;: 32, &quot;num_workers&quot;: 4 } datamodule = UIT_VSFC(tokenizer, options) tb_logger = pl_loggers.TensorBoardLogger(&#39;logs/&#39;) # create logger for tensorboard # hyper-parameters lr = 2e-5 max_epochs = 10 weight_decay = 0.01 model = PhoBERT(lr, weight_decay) checkpoint_callback = ModelCheckpoint( monitor=&#39;val_f1&#39;, # save the model with the best validation accuracy dirpath=&#39;checkpoints&#39;, mode=&#39;max&#39;, ) trainer = pl.Trainer(gpus=1, max_epochs=max_epochs, logger=tb_logger, callbacks=[checkpoint_callback], deterministic=True) # trainer = pl.Trainer(fast_dev_run=True) #Debug # trainer = pl.Trainer(overfit_batches=0.1, max_epochs=max_epochs) #Debug trainer.fit(model, datamodule) . Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained. Some weights of the model checkpoint at vinai/phobert-base were not used when initializing RobertaForSequenceClassification: [&#39;lm_head.decoder.bias&#39;, &#39;lm_head.bias&#39;, &#39;lm_head.dense.weight&#39;, &#39;roberta.pooler.dense.weight&#39;, &#39;lm_head.decoder.weight&#39;, &#39;lm_head.layer_norm.bias&#39;, &#39;roberta.pooler.dense.bias&#39;, &#39;lm_head.layer_norm.weight&#39;, &#39;lm_head.dense.bias&#39;] - This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model). - This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model). Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: [&#39;classifier.out_proj.weight&#39;, &#39;classifier.out_proj.bias&#39;, &#39;classifier.dense.weight&#39;, &#39;classifier.dense.bias&#39;] You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference. GPU available: True, used: True TPU available: False, using: 0 TPU cores Using custom data configuration default-d20422fbdfea28fe . Downloading and preparing dataset csv/default (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /root/.cache/huggingface/datasets/csv/default-d20422fbdfea28fe/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0... Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-d20422fbdfea28fe/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0. Subsequent calls will reuse this data. . LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] . . | Name | Type | Params 0 | model | RobertaForSequenceClassification | 135 M 1 | train_acc | Accuracy | 0 2 | val_acc | Accuracy | 0 3 | val_f1 | F1 | 0 4 | test_acc | Accuracy | 0 5 | test_f1 | F1 | 0 135 M Trainable params 0 Non-trainable params 135 M Total params 540.002 Total estimated model params size (MB) Global seed set to 2401 . . trainer.test(ckpt_path=checkpoint_callback.best_model_path, test_dataloaders=datamodule.test_dataloader()) . Using custom data configuration default-d20422fbdfea28fe Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-d20422fbdfea28fe/0.0.0/2dc6629a9ff6b5697d82c25b73731dd440507a69cbce8b425db50b751e8fcfd0) . . LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] . -- DATALOADER:0 TEST RESULTS {&#39;test_acc&#39;: 0.9314592480659485, &#39;test_f1&#39;: 0.9314592480659485} -- . [{&#39;test_acc&#39;: 0.9314592480659485, &#39;test_f1&#39;: 0.9314592480659485}] . Discussion . Results on test dataset: . Method Accuracy Macro-F1 . phoBERT | 0.931 | 0.931 | . MaxEnt (paper) | 87.9 | 87.9 | . We haven&#39;t tune the model but still get better result than the one in the UIT-VSFC paper. . To tune the model, there are somethings need to set up: . Wandb/Tensorboard: these tools will help us to visualize the loss per epoch of the model and other relevant information regarding metrics. Using those information we can come up with some ideas to tune the model. . | Wandb sweep: this tool allows us to define the range of hyperparameters we want to tune. . | . Lessons . When using transformers&#39; models, we should create out Dataset using the datasets library since it is helps to make the preprocessing step easier and cleaner. | Be careful with the metrics, for example, F1 micro and macro. | F1 and Accuracy are equal for cases in which every instance must be classified into one (and only one) class | .",
            "url": "https://minhdang241.github.io/minhdg-blog/implementation/2021/06/21/NLP_3_PhoBERT_Sentiment_Analysis.html",
            "relUrl": "/implementation/2021/06/21/NLP_3_PhoBERT_Sentiment_Analysis.html",
            "date": " • Jun 21, 2021"
        }
        
    
  
    
        ,"post13": {
            "title": "Effective LSTMs for Target Dependent Sentiment Classification [Part 2]",
            "content": "The full notebook is available here. . Install required packages . %%capture !pip install pytorch-lightning !pip install torchmetrics . Import required packages . import pickle from collections import Counter, OrderedDict from pathlib import Path from typing import Any, Dict, List, Optional, Tuple, Union from urllib.request import urlretrieve import numpy as np from tqdm import tqdm import pytorch_lightning as pl import torch import torch.nn as nn import torch.nn.functional as F import torchmetrics import torchtext from pytorch_lightning import loggers as pl_loggers from pytorch_lightning.callbacks import ModelCheckpoint from torch.nn.utils.rnn import (pack_padded_sequence, pad_packed_sequence, pad_sequence) from torch.utils.data import DataLoader, Dataset, random_split from torchtext.data import get_tokenizer from torchtext.vocab import Vectors, Vocab # For repoducibility pl.utilities.seed.seed_everything(seed=2401, workers=True) . Global seed set to 2401 . 2401 . Define dataset, data module class, utils function . =====Dataset File Format===== . Each instance consists three lines: . sentence (the target is replaced with $T$) | target | polarity label (0: neutral, 1:positive, -1:negative) | . Example: . i agree about arafat . i mean , shit , they even gave one to $T$ ha . it should be called &#39;&#39; the worst president &#39;&#39; prize . . jimmy carter . -1 . class TqdmUpTo(tqdm): &quot;&quot;&quot;From https://github.com/tqdm/tqdm/blob/master/examples/tqdm_wget.py&quot;&quot;&quot; def update_to(self, blocks=1, bsize=1, tsize=None): &quot;&quot;&quot; Parameters - blocks: int, optional Number of blocks transferred so far [default: 1]. bsize: int, optional Size of each block (in tqdm units) [default: 1]. tsize: int, optional Total size (in tqdm units). If [default: None] remains unchanged. &quot;&quot;&quot; if tsize is not None: self.total = tsize # pylint: disable=attribute-defined-outside-init self.update(blocks * bsize - self.n) # will also set self.n = b * bsize class Tokenizer(): def __init__(self, tokenizer: Any): self.counter = Counter([&#39;&lt;pad&gt;&#39;, &#39;&lt;unk&gt;&#39;]) self.tokenizer = tokenizer self.vocab = self.update_vocab() def update_vocab(self): sorted_by_freq_tuples = sorted(self.counter.items(), key=lambda x: x[1], reverse=True) ordered_dict = OrderedDict(sorted_by_freq_tuples) self.vocab = torchtext.vocab.vocab(ordered_dict, min_freq=1) self.vocab.set_default_index(self.vocab[&#39;&lt;unk&gt;&#39;]) def fit_on_texts(self, texts: List[str]): &quot;&quot;&quot; Updates internal vocabulary based on a list of texts. &quot;&quot;&quot; # lower and tokenize texts to sequences for text in texts: self.counter.update(self.tokenizer(text)) # self.counter.update([t.lower().strip() for t in text.split()]) self.update_vocab() def texts_to_sequences(self, texts: List[str], reverse: bool=False, tensor: bool=True) -&gt; List[int]: sequences = [] for text in texts: seq = [self.vocab[word] for word in self.tokenizer(text)] if reverse: seq = seq[::-1] if tensor: seq = torch.tensor(seq) sequences.append(seq) return sequences def _load_data_from(path: Union[str, Path]) -&gt; Tuple[List[List[str]], List[List[str]], List[set]]: &quot;&quot;&quot; Create a dataset from a file path Return: a TwitterDataset object &quot;&quot;&quot; sentences = [] targets = [] sentiments = [] with open(path) as f: lines = f.readlines() # Read the file line by line and # check the relative index to parse the data according to the format. for i, line in enumerate(lines): index = i % 3 # compute the relative index if index == 0: sentences.append(line[:-1]) elif index == 1: targets.append(line[:-1]) elif index == 2: sentiments.append(line.strip()) return sentences, targets, sentiments def download_url(url, filename, directory=&#39;.&#39;): &quot;&quot;&quot;Download a file from url to filename, with a progress bar.&quot;&quot;&quot; if not os.path.exists(directory): os.makedirs(directory) path = os.path.join(directory, filename) with TqdmUpTo(unit=&quot;B&quot;, unit_scale=True, unit_divisor=1024, miniters=1) as t: urlretrieve(url, path, reporthook=t.update_to, data=None) # nosec return path def _preprocess_data(data, tokenizer): sents, targets, sentiments = data l_texts = [] r_texts = [] texts = [] for i, sent in enumerate(sents): l_text, _, r_text = sent.partition(&quot;$T$&quot;) l_text = l_text + &#39; &#39; + targets[i] r_text = targets[i] + &#39; &#39; + r_text text = l_text + &#39; &#39; + targets[i] + &#39; &#39; + r_text l_texts.append(l_text) r_texts.append(r_text) texts.append(text) # Generate left, right and target sequences l_sequences = tokenizer.texts_to_sequences(l_texts) r_sequences = tokenizer.texts_to_sequences(r_texts, reverse=True) target_sequences = tokenizer.texts_to_sequences(targets) sequences = tokenizer.texts_to_sequences(texts) # Calcuate length of each sequence in the left, right sequences l_lens = torch.tensor([len(seq) for seq in l_sequences]) r_lens = torch.tensor([len(seq) for seq in r_sequences]) lens = torch.tensor([len(seq) for seq in sequences]) # Padding sequences l_sequences = pad_sequence(l_sequences, batch_first=True) r_sequences = pad_sequence(r_sequences, batch_first=True) target_sequences = pad_sequence(target_sequences, batch_first=True) sequences = pad_sequence(sequences, batch_first=True) #Convert sentiment text to number sentiments = list(map(lambda x: int(x), sentiments)) sentiments = torch.tensor(sentiments) + 1 # increment labels by 1 # Double Checking assert len(r_lens) == len(r_sequences) assert len(l_lens) == len(l_sequences) assert len(l_lens) == len(sentiments) data = [] for i in range(len(sentiments)): sample = { &#39;padded_l_sequence&#39;: l_sequences[i], &#39;padded_r_sequence&#39;: r_sequences[i], &#39;padded_sequence&#39;: sequences[i], &#39;l_len&#39;: l_lens[i], &#39;r_len&#39;: r_lens[i], &#39;len&#39;: lens[i], &#39;padded_target_sequence&#39;: target_sequences[i], &#39;sentiment&#39;: sentiments[i] } data.append(sample) return data def build_vocab(tokenizer, data): sentences, targets = data texts = [] for i, sent in enumerate(sentences): texts.append(sent.replace(&#39;$T$&#39;, targets[i])) tokenizer.fit_on_texts(texts) def load_pretrained_word_embeddings(options: Dict[str, Any]): return torchtext.vocab.GloVe(options[&#39;name&#39;], options[&#39;dim&#39;]) def create_embedding_matrix(word_embeddings: Vectors, vocab: Vocab, path: Union[str, Path]): if os.path.exists(path): print(f&#39;loading embedding matrix from {path}&#39;) embedding_matrix = pickle.load(open(path, &#39;rb&#39;)) else: embedding_matrix = torch.zeros((len(vocab), word_embeddings.dim), dtype=torch.float) # words that are not availabel in the pretrained word embeddings will be zeros for word, index in vocab.get_stoi().items(): embedding_matrix[index] = word_embeddings.get_vecs_by_tokens(word) # save embedding matrix pickle.dump(embedding_matrix, open(path, &#39;wb&#39;)) return embedding_matrix . class TwitterDataset(Dataset): def __init__(self, data): self.data = data def __len__(self): return len(self.data) def __getitem__(self, idx): return self.data[idx] TRAIN_DS_URL = &quot;https://raw.githubusercontent.com/songyouwei/ABSA-PyTorch/master/datasets/acl-14-short-data/train.raw&quot; TEST_DS_URL = &quot;https://raw.githubusercontent.com/songyouwei/ABSA-PyTorch/master/datasets/acl-14-short-data/test.raw&quot; class Twitter(pl.LightningDataModule): &quot;&quot;&quot; The Twitter dataset is ndwritten character digits derived from the NIST Special Database 19 &quot;&quot;&quot; def __init__(self, tokenizer: Tokenizer, opts: Dict[str, Any]): super().__init__() self.tokenizer = tokenizer self.batch_size = opts[&#39;batch_size&#39;] self.num_workers = opts[&#39;num_workers&#39;] self.on_gpu = opts[&#39;on_gpu&#39;] self.mapping = {&quot;negative&quot;: 0, &quot;neutral&quot;: 1, &quot;positive&quot;: 2} self.inverse_mapping = {v: k for k, v in enumerate(self.mapping)} def prepare_data(self, *args, **kwargs) -&gt; None: # Download the data train_path = &quot;download/raw_data/train.raw&quot; test_path = &quot;download/raw_data/test.raw&quot; if not os.path.exists(train_path): self.train_path = download_url(TRAIN_DS_URL, &quot;train.raw&quot;, &quot;download/raw_data&quot;) else: self.train_path = train_path if not os.path.exists(test_path): self.test_path = download_url(TEST_DS_URL, &quot;test.raw&quot;, &quot;download/raw_data&quot;) else: self.test_path = test_path def setup(self, stage: str = None) -&gt; None: if stage == &#39;fit&#39; or stage is None: # Load data from file train_data = _load_data_from(self.train_path) test_data = _load_data_from(self.test_path) # Preprocess data self.train_data = _preprocess_data(train_data, self.tokenizer) self.test_data = _preprocess_data(test_data, self.tokenizer) # In the paper, the author use the test set as validation set self.val_data = self.test_data elif stage == &#39;test&#39;: test_data = _load_data_from(self.test_path) self.test_data = _preprocess_data(test_data, self.tokenizer) def train_dataloader(self): # Create Dataset object train_ds = TwitterDataset(self.train_data) # Create Dataloader return DataLoader( train_ds, shuffle=True, batch_size=self.batch_size, num_workers=self.num_workers, pin_memory=self.on_gpu, ) def val_dataloader(self): val_ds = TwitterDataset(self.val_data) return DataLoader( val_ds, shuffle=False, batch_size=self.batch_size, num_workers=self.num_workers, pin_memory=self.on_gpu, ) def test_dataloader(self): test_ds = TwitterDataset(self.test_data) return DataLoader( test_ds, shuffle=False, batch_size=self.batch_size, num_workers=self.num_workers, pin_memory=self.on_gpu, ) def __repr__(self): basic = f&quot;Twitter Dataset nNum classes: {len(self.mapping)} nMapping: {self.mapping} n&quot; if self.train_data is None and self.val_data is None and self.test_data is None: return basic x, y = next(iter(self.train_dataloader())) data = ( f&quot;Train/val/test sizes: {len(self.train_data)}, {len(self.val_data)}, {len(self.test_data)} n&quot; f&quot;Batch x stats: {(x.shape, x.dtype)} n&quot; f&quot;Batch y stats: {(y.shape, y.dtype)} n&quot; ) return basic + data . In the paper, the author trained the model on training set, and evaluated the performance on test set . Implement Model Architecture . We use Adam as our optimizer and using accuracy and f1 as our evaluating metrics, just like in the original paper. Also, we use cross entropy function to calculate our loss, which is the de-facto function for multi-class classification task. . TD-LSTM . The architecture has a embedding layer, 2 LSTM layers and 1 dense layer. . Embedding layer: | . Convert the sequences to word vectors using pre-trained Glove word embeddings . 2 LSTM layers: | . One layer is used for the [left context + target] sequences, and one is used for the [target + right context] sequences. . Dense layer: | . We concate the 2 hidden states from the LSTM layers and feed it into the Dense layer. . To take into account of the target information, we make a slight modification on the $LSTM$ model. The basic idea is to model the preceding and following contexts surrounding the target string, so that contexts in both directions could be used as feature representations for sentiment classification. We believe that capturing such target-dependent context information could improve the accuracy of target-dependent sentiment classification. . Specifically, we use two $LSTM$ neural networks, a left one $LSTM_L$ and a right one $LSTM_R$, to model the preceding and following contexts respectively. An illustration of the model is shown in Figure 1. The input of $LSTM_L$ is the preceding contexts plus target string, and the input of $LSTM_R$ is the following contexts plus target string. We run $LSTM_L$ from left to right, and run $LSTM_R$ from right to left. We favor this strategy as we believe that regarding target string as the last unit could better utilize the semantics of target string when using the composed representation for sentiment classification. Afterwards, we concatenate the last hidden vectors of $LSTM_L$ and $LSTM_R$ , and feed them to a sof tmax layer to classify the sentiment polarity label. One could also try averaging or summing the last hidden vectors of $LSTM_L$ and $LSTM_R$ as alternatives. . from IPython.display import Image Image(filename=&#39;images/figure_1_image.png&#39;) . class TDLSTM(pl.LightningModule): def __init__(self, embeddings, hidden_size, num_layers=1, num_classes=3, batch_first=True, lr=1e-3, dropout=0, l2reg=0.01): super().__init__() embedding_dim = embeddings.shape[1] self.embedding = nn.Embedding.from_pretrained(embeddings) # load pre-trained word embeddings self.l_lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=batch_first, dropout=dropout) self.r_lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=batch_first, dropout=dropout) self.linear = nn.Linear(hidden_size*2, num_classes) self.lr = lr self.l2reg = l2reg # Define metrics self.train_acc = torchmetrics.Accuracy() self.val_acc = torchmetrics.Accuracy() self.val_f1 = torchmetrics.F1(num_classes=3, average=&#39;macro&#39;) self.test_acc = torchmetrics.Accuracy() self.test_f1 = torchmetrics.F1(num_classes=3, average=&#39;macro&#39;) def configure_optimizers(self): optim = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.l2reg) return optim def forward(self, data): cols = [&#39;padded_l_sequence&#39;, &#39;padded_r_sequence&#39;, &#39;l_len&#39;, &#39;r_len&#39;] padded_l_seqs, padded_r_seqs, l_lens, r_lens = [data[col] for col in cols] # convert seq to word vector padded_l_embeds = self.embedding(padded_l_seqs) padded_r_embeds = self.embedding(padded_r_seqs) # pack the embeds padded_l_seq_pack = pack_padded_sequence(padded_l_embeds, l_lens.cpu(), batch_first=True, enforce_sorted=False) padded_r_seq_pack = pack_padded_sequence(padded_r_embeds, r_lens.cpu(), batch_first=True, enforce_sorted=False) _, (h_l, _) = self.l_lstm(padded_l_seq_pack) _, (h_r, _) = self.r_lstm(padded_r_seq_pack) h = torch.cat((h_l[-1], h_r[-1]), -1) # B x 2H out = self.linear(h) return out def training_step(self, batch, batch_idx): # pylint: disable=unused-argument sentiments = batch[&#39;sentiment&#39;] logits = self.forward(batch) loss = F.cross_entropy(logits, sentiments) scores = F.softmax(logits, dim=-1) self.train_acc(scores, sentiments) self.log(&#39;train_loss&#39;, loss, on_step=True, on_epoch=True, prog_bar=True) self.log(&#39;train_acc&#39;, self.train_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True) return loss def validation_step(self, batch, batch_idx): # pylint: disable=unused-argument sentiments = batch[&#39;sentiment&#39;] logits = self.forward(batch) loss = F.cross_entropy(logits, sentiments) scores = F.softmax(logits, dim=-1) self.val_acc(scores, sentiments) self.val_f1(scores, sentiments) self.log(&#39;val_loss&#39;, loss, on_step=True, on_epoch=True, prog_bar=True) self.log(&#39;val_acc&#39;, self.val_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True) self.log(&#39;val_f1&#39;, self.val_f1, on_step=False, on_epoch=True, prog_bar=True, logger=True) def test_step(self, batch, batch_idx): # pylint: disable=unused-argument sentiments = batch[&#39;sentiment&#39;] logits = self.forward(batch) scores = F.softmax(logits, dim=-1) self.test_acc(scores, sentiments) self.test_f1(scores, sentiments) self.log(&#39;test_acc&#39;, self.test_acc, on_step=False, on_epoch=True, logger=True) self.log(&#39;test_f1&#39;, self.test_f1, on_step=False, on_epoch=True, logger=True) . TC-LSTM . The architecture has a embedding layer, 2 LSTM layers and 1 dense layer. . Embedding layer: | . Convert the sequences to word vectors using pre-trained Glove word embeddings . 2 LSTM layers: | . One layer is used for the [left context + target] sequences, and one is used for the [target + right context] sequences. . Dense layer: | . We concate the 2 hidden states from the LSTM layers and feed it into the Dense layer. . The only difference compared to the TD-LSTM is its input. The input of TC-LSTM is a concatenation of the input word vector and the $v_{target}$ vector. We calculate the $v_{target}$ vector by averaging the all the target word vector(s) of the sample. For example, if the target in the sentence is jimmy carter, we tokenizer the target to jimmy and carter then convert them to word vector. After that, we average those vector to get the $v_{target}$ vector. . An overview of TC-LSTM is illustrated in Figure 2. The model extends TD-LSTM by incorporating an target con- nection component, which explicitly utilizes the connections between target word and each context word when composing the representation of a sentence. . The input of TC-LSTM is a sentence consist- ing of n words { $w_1,w_2,...w_n$ } and a target string t occurs in the sentence. We represent target t as { $w_{l+1}, w_{l+2}...w_{r−1}$ } because a target could be a word sequence of variable length, such as “google” or “harry potter”. When processing a sentence, we split it into three components:target words, preceding context words and following context words. We obtain target vector $v_{target}$ by averaging the vectors of words it contains, which has been proven to be simple and effective in representing named entities (Socher et al., 2013a; Sun et al., 2015). When compute the hidden vectors of preceding and following context words, we use two separate long short-term memory models, which are similar with the strategy used in TD-LSTM. The difference is that in TC-LSTM the input at each position is the concatenation of word embedding and target vector vtarget, while in TD-LSTM the input at each position only includes only the embedding of current word. The input data has an additional element which is the $v_{target}$ vector. Let create a new Dataset class for TC-LSTM. . from IPython.display import Image Image(filename=&#39;images/figure_2_image.png&#39;) . class TCLSTM(pl.LightningModule): def __init__(self, embeddings, hidden_size, num_layers=1, num_classes=3, batch_first=True, lr=1e-3, dropout=0, l2reg=0.01): super().__init__() embedding_dim = embeddings.shape[1] self.embedding = nn.Embedding.from_pretrained(embeddings) # load pre-trained word embeddings self.l_lstm = nn.LSTM(embedding_dim*2, hidden_size, num_layers, batch_first=batch_first, dropout=dropout) self.r_lstm = nn.LSTM(embedding_dim*2, hidden_size, num_layers, batch_first=batch_first, dropout=dropout) self.linear = nn.Linear(hidden_size*2, num_classes) self.lr = lr self.l2reg = l2reg # log hyperparameters # self.save_hyperparameters() # Define metrics self.train_acc = torchmetrics.Accuracy() self.val_acc = torchmetrics.Accuracy() self.val_f1 = torchmetrics.F1(num_classes=3, average=&#39;macro&#39;) self.test_acc = torchmetrics.Accuracy() self.test_f1 = torchmetrics.F1(num_classes=3, average=&#39;macro&#39;) def configure_optimizers(self): optim = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.l2reg) return optim def forward(self, data): cols = [&#39;padded_l_sequence&#39;, &#39;padded_r_sequence&#39;, &#39;l_len&#39;, &#39;r_len&#39;, &#39;padded_target_sequence&#39;] padded_l_seqs, padded_r_seqs, l_lens, r_lens, padded_target_seqs = [data[col] for col in cols] # convert seq to word vector padded_l_embeds = self.embedding(padded_l_seqs) padded_r_embeds = self.embedding(padded_r_seqs) padded_target_embeds = self.embedding(padded_target_seqs) # BxLxH # create v_target vector and concat it to both l_embeds and r_embeds v_targets = torch.mean(padded_target_embeds, dim=1, keepdims=True) padded_l_embeds = torch.cat((padded_l_embeds, v_targets.expand((-1, padded_l_embeds.shape[1], -1))), dim=2) padded_r_embeds = torch.cat((padded_r_embeds, v_targets.expand((-1, padded_r_embeds.shape[1], -1))), dim=2) # pack the embeds padded_l_seq_pack = pack_padded_sequence(padded_l_embeds, l_lens.cpu(), batch_first=True, enforce_sorted=False) padded_r_seq_pack = pack_padded_sequence(padded_r_embeds, r_lens.cpu(), batch_first=True, enforce_sorted=False) _, (h_l, _) = self.l_lstm(padded_l_seq_pack) _, (h_r, _) = self.r_lstm(padded_r_seq_pack) h = torch.cat((h_l[-1], h_r[-1]), -1) # B x 2H out = self.linear(h) return out def training_step(self, batch, batch_idx): # pylint: disable=unused-argument sentiments = batch[&#39;sentiment&#39;] logits = self.forward(batch) loss = F.cross_entropy(logits, sentiments) scores = F.softmax(logits, dim=-1) self.train_acc(scores, sentiments) self.log(&#39;train_loss&#39;, loss, on_step=True, on_epoch=True, prog_bar=True, logger=True) self.log(&#39;train_acc&#39;, self.train_acc, on_step=True, on_epoch=True, prog_bar=True, logger=True) return loss def validation_step(self, batch, batch_idx): # pylint: disable=unused-argument sentiments = batch[&#39;sentiment&#39;] logits = self.forward(batch) loss = F.cross_entropy(logits, sentiments) scores = F.softmax(logits, dim=-1) self.val_acc(scores, sentiments) self.val_f1(scores, sentiments) self.log(&#39;val_loss&#39;, loss, on_step=True, on_epoch=True, prog_bar=True) self.log(&#39;val_acc&#39;, self.val_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True) self.log(&#39;val_f1&#39;, self.val_f1, on_step=False, on_epoch=True, prog_bar=True, logger=True) def test_step(self, batch, batch_idx): # pylint: disable=unused-argument sentiments = batch[&#39;sentiment&#39;] logits = self.forward(batch) scores = F.softmax(logits, dim=-1) self.test_acc(scores, sentiments) self.test_f1(scores, sentiments) self.log(&#39;test_acc&#39;, self.test_acc, on_step=False, on_epoch=True, logger=True) self.log(&#39;test_f1&#39;, self.test_f1, on_step=False, on_epoch=True, logger=True) . LSTM . This is just a simple LSTM model with a embedding layer, 1 LSTM layers and 1 dense layer. . For the input data, we simply feed all the input word vector to the LSTM without informing the model any information of the target words. . The LSTM model solves target-dependent sentiment classification in a target- independent way. That is to say, the feature representation used for sentiment classification remains the same without considering the target words. Let us again take “I bought a new camera. The picture quality is amazing but the battery life is too short” as an example. The representations of this sentence with regard to picture quality and battery life are identical. This is evidently problematic as the sentiment polarity labels towards these two targets are different. . from IPython.display import Image Image(filename=&#39;images/figure_3_image.png&#39;) . class LSTM(pl.LightningModule): def __init__(self, embeddings, hidden_size, num_layers=1, num_classes=3, batch_first=True, lr=1e-3, dropout=0, l2reg=0.01): super().__init__() embedding_dim = embeddings.shape[1] self.embedding = nn.Embedding.from_pretrained(embeddings) # load pre-trained word embeddings self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=batch_first, dropout=dropout) self.linear = nn.Linear(hidden_size, num_classes) self.lr = lr self.l2reg = l2reg # Define metrics self.train_acc = torchmetrics.Accuracy() self.val_acc = torchmetrics.Accuracy() self.val_f1 = torchmetrics.F1(num_classes=3, average=&#39;macro&#39;) self.test_acc = torchmetrics.Accuracy() self.test_f1 = torchmetrics.F1(num_classes=3, average=&#39;macro&#39;) def configure_optimizers(self): optim = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.l2reg) return optim def forward(self, data): cols = [&#39;padded_sequence&#39;, &#39;len&#39;] padded_seqs, lens = [data[col] for col in cols] # convert seq to word vector padded_embeds = self.embedding(padded_seqs) # pack the embeds padded_seq_pack = pack_padded_sequence(padded_embeds, lens.cpu(), batch_first=True, enforce_sorted=False) _, (h, _) = self.lstm(padded_seq_pack) out = self.linear(h[-1]) return out def training_step(self, batch, batch_idx): # pylint: disable=unused-argument sentiments = batch[&#39;sentiment&#39;] logits = self.forward(batch) loss = F.cross_entropy(logits, sentiments) scores = F.softmax(logits, dim=-1) self.train_acc(scores, sentiments) self.log(&#39;train_loss&#39;, loss, on_step=True, on_epoch=True, prog_bar=True) self.log(&#39;train_acc&#39;, self.train_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True) return loss def validation_step(self, batch, batch_idx): # pylint: disable=unused-argument sentiments = batch[&#39;sentiment&#39;] logits = self.forward(batch) loss = F.cross_entropy(logits, sentiments) scores = F.softmax(logits, dim=-1) self.val_acc(scores, sentiments) self.val_f1(scores, sentiments) self.log(&#39;val_loss&#39;, loss, on_step=True, on_epoch=True, prog_bar=True) self.log(&#39;val_acc&#39;, self.val_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True) self.log(&#39;val_f1&#39;, self.val_f1, on_step=False, on_epoch=True, prog_bar=True, logger=True) def test_step(self, batch, batch_idx): # pylint: disable=unused-argument sentiments = batch[&#39;sentiment&#39;] logits = self.forward(batch) scores = F.softmax(logits, dim=-1) self.test_acc(scores, sentiments) self.test_f1(scores, sentiments) self.log(&#39;test_acc&#39;, self.test_acc, on_step=False, on_epoch=True, logger=True) self.log(&#39;test_f1&#39;, self.test_f1, on_step=False, on_epoch=True, logger=True) . Training . First of all we will load the pre-trained word embedding Glove. We use the same one with the author. . We use 100-dimensional Glove vectors learned from Twitter, randomize the parameters with uniform distribution U(−0.003,0.003), set the clipping threshold of softmax layer as 200 and set learning rate as 0.01. . Since the author does not provide explicitly the hyper-parameters he used, we have to fine-tune a bit to get good result. . word_embeddings = load_pretrained_word_embeddings({&quot;name&quot;: &quot;twitter.27B&quot;, &quot;dim&quot;: 100}) . .vector_cache/glove.twitter.27B.zip: 1.52GB [04:53, 5.18MB/s] 100%|█████████▉| 1191916/1193514 [00:43&lt;00:00, 27135.96it/s] . download_url(TRAIN_DS_URL, &quot;train.raw&quot;, &quot;download/raw_data&quot;) download_url(TEST_DS_URL, &quot;test.raw&quot;, &quot;download/raw_data&quot;) train_data = _load_data_from(&quot;download/raw_data/train.raw&quot;) test_data = _load_data_from(&quot;download/raw_data/test.raw&quot;) # Build vocabulary for the dataset all_sentences = train_data[0] + test_data[0] all_targets = train_data[1] + test_data[1] tokenizer = Tokenizer(get_tokenizer(&quot;basic_english&quot;)) build_vocab(tokenizer, [all_sentences, all_targets]) # Create datamodule options = { &quot;on_gpu&quot;: True, &quot;batch_size&quot;: 64, &quot;num_workers&quot;: 2 } datamodule = Twitter(tokenizer, options) # Create embedding matrix embedding_matrix = create_embedding_matrix(word_embeddings, tokenizer.vocab, &quot;embedding_matrix.dat&quot;) . TD-LSTM . checkpoint_callback = ModelCheckpoint( monitor=&#39;val_acc&#39;, # save the model with the best validation accuracy dirpath=&#39;checkpoints&#39;, mode=&#39;max&#39;, ) tb_logger = pl_loggers.TensorBoardLogger(&#39;logs/&#39;) # create logger for tensorboard # Set hyper-parameters lr = 1e-3 hidden_size = 300 num_epochs = 30 l2reg = 0.0 trainer = pl.Trainer(gpus=1, max_epochs=num_epochs, logger=tb_logger, callbacks=[checkpoint_callback], deterministic=True) # trainer = pl.Trainer(fast_dev_run=True) #Debug # trainer = pl.Trainer(overfit_batches=0.1, max_epochs=30) #Debug model = TDLSTM(embedding_matrix, hidden_size, lr=lr, l2reg=l2reg) trainer.fit(model, datamodule) . GPU available: True, used: True TPU available: False, using: 0 TPU cores . loading embedding matrix from embedding_matrix.dat . LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params - 0 | embedding | Embedding | 1.3 M 1 | l_lstm | LSTM | 482 K 2 | r_lstm | LSTM | 482 K 3 | linear | Linear | 1.8 K 4 | train_acc | Accuracy | 0 5 | val_acc | Accuracy | 0 6 | val_f1 | F1 | 0 7 | test_acc | Accuracy | 0 8 | test_f1 | F1 | 0 - 966 K Trainable params 1.3 M Non-trainable params 2.3 M Total params 9.235 Total estimated model params size (MB) Global seed set to 2401 . . new_model = TDLSTM.load_from_checkpoint(checkpoint_callback.best_model_path, embeddings=embedding_matrix, hidden_size=300) trainer.test(new_model, datamodule.test_dataloader()) . LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] . -- DATALOADER:0 TEST RESULTS {&#39;test_acc&#39;: 0.6979768872261047, &#39;test_f1&#39;: 0.6850955486297607} -- . [{&#39;test_acc&#39;: 0.6979768872261047, &#39;test_f1&#39;: 0.6850955486297607}] . TC-LSTM . checkpoint_callback_2 = ModelCheckpoint( monitor=&#39;val_acc&#39;, # save the model with the best validation accuracy dirpath=&#39;checkpoints&#39;, mode=&#39;max&#39;, ) tb_logger = pl_loggers.TensorBoardLogger(&#39;logs/&#39;) # create logger for tensorboard # Set hyper-parameters lr = 1e-3 hidden_size = 300 num_epochs = 30 l2reg = 0.0 trainer = pl.Trainer(gpus=1, max_epochs=num_epochs, logger=tb_logger, callbacks=[checkpoint_callback_2]) # trainer = pl.Trainer(fast_dev_run=True) #Debug # trainer = pl.Trainer(overfit_batches=0.1, max_epochs=30) #Debug model = TCLSTM(embedding_matrix, hidden_size, lr=lr, l2reg=l2reg) trainer.fit(model, datamodule) . GPU available: True, used: True TPU available: False, using: 0 TPU cores LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params - 0 | embedding | Embedding | 1.3 M 1 | l_lstm | LSTM | 602 K 2 | r_lstm | LSTM | 602 K 3 | linear | Linear | 1.8 K 4 | train_acc | Accuracy | 0 5 | val_acc | Accuracy | 0 6 | val_f1 | F1 | 0 7 | test_acc | Accuracy | 0 8 | test_f1 | F1 | 0 - 1.2 M Trainable params 1.3 M Non-trainable params 2.5 M Total params 10.195 Total estimated model params size (MB) Global seed set to 2401 . . new_model = TCLSTM.load_from_checkpoint(checkpoint_callback_2.best_model_path, embeddings=embedding_matrix, hidden_size=300) trainer.test(new_model, datamodule.test_dataloader()) . LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] . -- DATALOADER:0 TEST RESULTS {&#39;test_acc&#39;: 0.7008670568466187, &#39;test_f1&#39;: 0.6788402199745178} -- . [{&#39;test_acc&#39;: 0.7008670568466187, &#39;test_f1&#39;: 0.6788402199745178}] . LSTM . checkpoint_callback_3 = ModelCheckpoint( monitor=&#39;val_acc&#39;, # save the model with the best validation accuracy dirpath=&#39;checkpoints&#39;, mode=&#39;max&#39;, ) tb_logger = pl_loggers.TensorBoardLogger(&#39;logs/&#39;) # create logger for tensorboard # Set hyper-parameters lr = 1e-3 hidden_size = 300 num_epochs = 30 l2reg = 0.0 trainer = pl.Trainer(gpus=1, max_epochs=num_epochs, logger=tb_logger, callbacks=[checkpoint_callback_3]) # trainer = pl.Trainer(fast_dev_run=True) #Debug # trainer = pl.Trainer(overfit_batches=0.1, max_epochs=30) #Debug model = LSTM(embedding_matrix, hidden_size, lr=lr, l2reg=l2reg) trainer.fit(model, datamodule) . GPU available: True, used: True TPU available: False, using: 0 TPU cores LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params - 0 | embedding | Embedding | 1.3 M 1 | lstm | LSTM | 482 K 2 | linear | Linear | 903 3 | train_acc | Accuracy | 0 4 | val_acc | Accuracy | 0 5 | val_f1 | F1 | 0 6 | test_acc | Accuracy | 0 7 | test_f1 | F1 | 0 - 483 K Trainable params 1.3 M Non-trainable params 1.8 M Total params 7.302 Total estimated model params size (MB) Global seed set to 2401 . . new_model = LSTM.load_from_checkpoint(checkpoint_callback_3.best_model_path, embeddings=embedding_matrix, hidden_size=300) trainer.test(new_model, datamodule.test_dataloader()) . LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] . -- DATALOADER:0 TEST RESULTS {&#39;test_acc&#39;: 0.6878612637519836, &#39;test_f1&#39;: 0.6633064150810242} -- . [{&#39;test_acc&#39;: 0.6878612637519836, &#39;test_f1&#39;: 0.6633064150810242}] . Discussion . Our result: . Method Accuracy Macro-F1 . LSTM | 0.687 | 0.66 | . TD-LSTM | 0.697 | 0.685 | . TC-LSTM | 0.7 | 0.679 | . Paper result: . Method Accuracy Macro-F1 . LSTM | 0.665 | 0.647 | . TD-LSTM | 0.708 | 0.690 | . TC-LSTM | 0.715 | 0.695 | . Firstly, compared to the result from the paper, our implementation gets very close results. You can try to tune the model to get a better result. . Secondly, it is surprising that we can get a much better result with the simple LSTM model compared to the paper result. The reason that the LSTM can get a very close result compared to TD-LSTM and TC-LSTM is explainable. Even though this is the target-dependent sentiment classification task, there is only one target per sentence in the dataset. Therefore, the target information is redundant in this case. The LSTM model can use the surrounding words to classify the sentence. . You can read more about the paper here . from IPython.display import Image Image(filename=&#39;images/results.png&#39;) . Lessons . Even though the embedding layer is frozen during traning (parameters not updated), using the corpus vocab to create embedding matrix from pretrained Glove yield better result than using the whole word embeddings for the embedding layer. . | Using pad_sequence and pack_padded_sequence assure the LSTM/RNN/GRU not processing the padding token. It is better than padding with max length. The result of 2 methods are the same. From what I search, padding with max length will adversely affect the performance of the model. Even though, we can set the loss function to not to account for the padding token, the padding token still have affect on the input tokens. The reason may be that the latter will process the padding token together with the input ones. . | Consider the structure of the project before coding it to save refactoring time. . |",
            "url": "https://minhdang241.github.io/minhdg-blog/implementation/2021/06/20/NLP_2_Effective_LSTMs_for_Target_Dependent_Sentiment_Classification-Part-2.html",
            "relUrl": "/implementation/2021/06/20/NLP_2_Effective_LSTMs_for_Target_Dependent_Sentiment_Classification-Part-2.html",
            "date": " • Jun 20, 2021"
        }
        
    
  
    
        ,"post14": {
            "title": "Effective LSTMs for Target Dependent Sentiment Classification [Part 1]",
            "content": "from IPython.display import Image Image(filename=&#39;images/paper_image.png&#39;) . Target-Dependent Sentiment Classification is one of the text classification problems in the field of sentiment analysis. Given a sentence and a target to the model, it has to output the sentiment polarity (e.g positive, negative, neutral) of the sentence towards that target. For example, we have a sentence &quot;I bout a new camera. The pucture quality is amazing but the battery life is too short&quot;. If we input the target picture quality, we expect the sentiment to be &quot;positive&quot;. On the other hand, if we input the target battery life, we expect the sentiment to be &quot;negative&quot;. . The author argues that the Target-Dependent sentiment classification is challenging since it is hard to effectively model the sentiment relatedness of a target word with its context words in a sentence. Doing feature engineerings are clumsy, so they propose a neural network approach with 2 models Target-Dependent LSTM (TD-LSTM) and Target-Connection LSTM(TC-LSTM). . In this post, I will implement those models and compare it with the plain LSTM model, just like they did. Yet, I will not cover other approaches using SVM and RNN. Since in the original paper, the author did not provide the specific hyper-parameters they used for their models, I will fine-tune it on my own. . This post covers the data processing step and the implementation of TD-LSTM. The second post will cover the implementation of TC-LSTM and comparision between three models: TC-LSTM, TD-LSTM, and LSTM. . The full notebook is available here. . Install required packages . %%capture !pip install pytorch-lightning !pip install torchmetrics # !pip install transformers . Download dataset and pretrained word-embedding . First of all you should download the dataset. The dataset used in the paper is from the Twitter (Dong et al., 2014). You can download from here. After downloading, you should unzip the dataset file in the same folder with the notebook. They should be in the same folder to run properly. . %%capture !unzip acl-14-short-data.zip . In the paper, the author used the 100-dimensional Glove vectors learned from Twitter. Download the word embedding file and unzip it in the same folder with the notebook. . %%capture !wget https://nlp.stanford.edu/data/glove.twitter.27B.zip !unzip glove.twitter.27B.zip . Import required packages . import numpy as np import pytorch_lightning as pl import torch import torch.nn as nn import torch.nn.functional as F import torchmetrics from pytorch_lightning import loggers as pl_loggers from pytorch_lightning.callbacks import ModelCheckpoint from torch.utils.data import DataLoader, Dataset, random_split from torchtext.data import get_tokenizer . Load dataset from file and create dataloaders . =====Dataset File Format===== . Each instance consists three lines: . sentence (the target is replaced with $T$) | target | polarity label (0: neutral, 1:positive, -1:negative) | . Example: . i agree about arafat . i mean , shit , they even gave one to $T$ ha . it should be called &#39;&#39; the worst president &#39;&#39; prize . . jimmy carter . -1 . Target-Dependent LSTM (TD-LSTM) . The LSTM model solves target-dependent sentiment classification in a target- independent way. That is to say, the feature representation used for sentiment classification remains the same without considering the target words. Let us again take “I bought a new camera. The picture quality is amazing but the battery life is too short” as an example. The representations of this sentence with regard to picture quality and battery life are identical. This is evidently problematic as the sentiment polarity labels towards these two targets are different. . To take into account of the target information, we make a slight modification on the aforementioned LSTM model and introduce a target-dependent LSTM (TD-LSTM) in this subsection. The basic idea is to model the preceding and following contexts surrounding the target string, so that contexts in both directions could be used as feature representations for sentiment classification. We believe that capturing such target-dependent context information could improve the accuracy of target-dependent sentiment classification. . Specifically, we use two LSTM neural networks, a left one LSTML and a right one LSTMR, to model the preceding and following contexts respectively. An illustration of the model is shown in Figure 1. The input of LSTML is the preceding contexts plus target string, and the input of LSTMR is the following contexts plus target string. We run LSTML from left to right, and run LSTMR from right to left. We favor this strategy as we believe that regarding target string as the last unit could better utilize the semantics of target string when using the composed representation for sentiment classification. Afterwards, we concatenate the last hidden vectors of LSTML and LSTMR , and feed them to a sof tmax layer to classify the sentiment polarity label. One could also try averaging or summing the last hidden vectors of LSTML and LSTMR as alternatives. . from IPython.display import Image Image(filename=&#39;images/firgure_1_image.png&#39;) . class TwitterTDLSTMDataset(Dataset): def __init__(self, l_sequences, r_sequences, l_lens, r_lens, sentiments): self.l_sequences = l_sequences self.r_sequences = r_sequences self.l_lens = l_lens self.r_lens = r_lens self.sentiments = sentiments def __len__(self): return len(self.sentiments) def __getitem__(self, idx): return (self.l_sequences[idx], self.l_lens[idx]), (self.r_sequences[idx], self.r_lens[idx]), self.sentiments[idx] . def create_dataset_from(path: str): &quot;&quot;&quot; Create a dataset from a file path Return: a TwitterDataset object &quot;&quot;&quot; sentences = [] targets = [] sentiments = [] with open(path) as f: lines = f.readlines() # Read the file line by line and # check the relative index to parse the data according to the format. for i, line in enumerate(lines): index = i % 3 # compute the relative index if index == 0: sentences.append(line[:-1]) elif index == 1: targets.append(line[:-1]) elif index == 2: sentiments.append(line.strip()) #Load tokenizer tokenizer = get_tokenizer(&quot;basic_english&quot;) #Tokenize and Lower sentence and target text tokenized_sentences = list(map(lambda x: tokenizer(x), sentences)) targets = list(map(lambda x: tokenizer(x), targets)) #Convert sentiment text to number sentiments = list(map(lambda x: int(x), sentiments)) #Generate sequence_l, sequence_r l_sequences = [] r_sequences = [] for i, sent in enumerate(tokenized_sentences): seq_l, seq_r = [], [] flag = True for token in sent: if word_2_id.get(token) == len(word_2_id) - 1: flag = False continue if flag: # get the index of the token in the vocab # if the token does not exists in the vocab, return index of &lt;UNK&gt; token seq_l.append(word_2_id.get(token, 1)) else: seq_r.append(word_2_id.get(token, 1)) target_seq = [word_2_id.get(token, 1) for token in targets[i]] seq_l = torch.tensor(seq_l + target_seq) seq_r = torch.tensor((target_seq + seq_r)[::-1]) # reverse the seq_r l_sequences.append(seq_l) r_sequences.append(seq_r) l_lens = torch.tensor([len(seq) for seq in l_sequences]) r_lens = torch.tensor([len(seq) for seq in r_sequences]) sentiments = torch.tensor(sentiments) + 1 assert len(l_lens) == len(l_sequences) assert len(r_lens) == len(r_sequences) assert len(l_lens) == len(sentiments) return TwitterTDLSTMDataset(l_sequences, r_sequences, l_lens, r_lens, sentiments) . def load_w2v(embedding_file_path: str): &quot;&quot;&quot; Load pretrained word-embeddings from a file path Return a word_2_id dictionary and a embedding matrix &quot;&quot;&quot; word_2_id = {&#39;&lt;PAD&gt;&#39;: 0, &#39;&lt;UNK&gt;&#39;: 1} embeddings = [torch.zeros(100), torch.zeros(100)] with open(embedding_file_path) as f: for i, line in enumerate(f.readlines()): tokens = line.split() word, vec = &#39; &#39;.join(tokens[:-100]), tokens[-100:] word_2_id[word] = i + 2 # convert list of str to float float_tokens = np.array(vec, dtype=float) embeddings.append(torch.tensor(float_tokens, dtype=torch.float)) embeddings = torch.stack(embeddings) embeddings[word_2_id[&#39;&lt;UNK&gt;&#39;]] = torch.mean(embeddings[2:], dim=0) word_2_id[&#39;$t$&#39;] = len(word_2_id) return word_2_id, embeddings . word_2_id, embeddings = load_w2v(&quot;glove.twitter.27B.100d.txt&quot;) . from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence def collate_batch(batch): &quot;&quot;&quot; Combine samples from dataset into a batch &quot;&quot;&quot; l_sequences = [] l_lens = [] r_sequences = [] r_lens = [] sentiments = [] for (l_sequence, l_len), (r_sequence, r_len), sentiment in batch: l_sequences.append(l_sequence) l_lens.append(l_len) r_sequences.append(r_sequence) r_lens.append(r_len) sentiments.append(sentiment) padded_l_seq = pad_sequence(l_sequences, batch_first=True, padding_value=0) padded_r_seq = pad_sequence(r_sequences, batch_first=True, padding_value=0) return (padded_l_seq, l_lens), (padded_r_seq, r_lens), torch.tensor(sentiments) . In the paper, the author trained the model on training set, and evaluated the performance on test set . dataset = create_dataset_from(&quot;/content/acl-14-short-data/train.raw&quot;) dataloaders = DataLoader(dataset, batch_size=128, collate_fn=collate_batch) . test_dataset = create_dataset_from(&quot;/content/acl-14-short-data/test.raw&quot;) test_dataloaders = DataLoader(test_dataset, batch_size=64, collate_fn=collate_batch) . Implement Model Architecture . The architecture has a embedding layer, 2 LSTM layers and 1 dense layer. . Embedding layer: | . Convert the sequences to word vectors using pre-trained Glove word embeddings . 2 LSTM layers: | . One layer is used for the [left context + target] sequences, and one is used for the [target + right context] sequences. . Dense layer: | . We concate the 2 hidden states from the LSTM layers and feed it into the Dense layer. . Notes: . We use Adam as our optimizer and using accuracy and f1 as our evaluating metrics, just like in the original paper. . class TDLSTM(pl.LightningModule): def __init__(self, embeddings, hidden_size, num_layers=1, num_classes=3, batch_first=True, lr=1e-3, dropout=0, l2reg=0.01): super().__init__() embedding_dim = embeddings.shape[1] self.embedding = nn.Embedding.from_pretrained(embeddings) # load pre-trained word embeddings self.l_lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=batch_first, dropout=dropout) self.r_lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=batch_first, dropout=dropout) self.linear = nn.Linear(hidden_size*2, num_classes) self.lr = lr self.l2reg = l2reg # Define metrics self.train_acc = torchmetrics.Accuracy() self.val_acc = torchmetrics.Accuracy() self.val_f1 = torchmetrics.F1(num_classes=3, average=&#39;macro&#39;) self.test_acc = torchmetrics.Accuracy() self.test_f1 = torchmetrics.F1(num_classes=3, average=&#39;macro&#39;) def configure_optimizers(self): optim = torch.optim.AdamW(self.parameters(), lr=self.lr, weight_decay=self.l2reg) return optim def forward(self, padded_l_seqs, l_lens, padded_r_seqs, r_lens): # convert seq to word vector padded_l_embeds = self.embedding(padded_l_seqs) padded_r_embeds = self.embedding(padded_r_seqs) # pack the embeds padded_l_seq_pack = pack_padded_sequence(padded_l_embeds, l_lens, batch_first=True, enforce_sorted=False) padded_r_seq_pack = pack_padded_sequence(padded_r_embeds, r_lens, batch_first=True, enforce_sorted=False) _, (h_l, _) = self.l_lstm(padded_l_seq_pack) _, (h_r, _) = self.r_lstm(padded_r_seq_pack) h = torch.cat((h_l[-1], h_r[-1]), -1) # B x 2H out = self.linear(h) return out def training_step(self, batch, batch_idx): # pylint: disable=unused-argument (padded_l_seqs, l_lens), (padded_r_seqs, r_lens), sentiments = batch logits = self.forward(padded_l_seqs, l_lens, padded_r_seqs, r_lens) loss = F.cross_entropy(logits, sentiments) scores = F.softmax(logits, dim=-1) self.train_acc(scores, sentiments) self.log(&#39;train_loss&#39;, loss, on_step=True, on_epoch=True, prog_bar=True) self.log(&#39;train_acc&#39;, self.train_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True) return loss def validation_step(self, batch, batch_idx): # pylint: disable=unused-argument (padded_l_seqs, l_lens), (padded_r_seqs, r_lens), sentiments = batch logits = self.forward(padded_l_seqs, l_lens, padded_r_seqs, r_lens) loss = F.cross_entropy(logits, sentiments) scores = F.softmax(logits, dim=-1) self.val_acc(scores, sentiments) self.val_f1(scores, sentiments) self.log(&#39;val_loss&#39;, loss, on_step=True, on_epoch=True, prog_bar=True) self.log(&#39;val_acc&#39;, self.val_acc, on_step=False, on_epoch=True, prog_bar=True, logger=True) self.log(&#39;val_f1&#39;, self.val_f1, on_step=False, on_epoch=True, prog_bar=True, logger=True) def test_step(self, batch, batch_idx): # pylint: disable=unused-argument (padded_l_seqs, l_lens), (padded_r_seqs, r_lens), sentiments = batch logits = self.forward(padded_l_seqs, l_lens, padded_r_seqs, r_lens) scores = F.softmax(logits, dim=-1) self.test_acc(scores, sentiments) self.test_f1(scores, sentiments) self.log(&#39;test_acc&#39;, self.test_acc, on_step=False, on_epoch=True, logger=True) self.log(&#39;test_f1&#39;, self.test_f1, on_step=False, on_epoch=True, logger=True) . Training . checkpoint_callback = ModelCheckpoint( monitor=&#39;val_acc&#39;, # save the model with the best validation accuracy dirpath=&#39;checkpoints&#39;, filename=&#39;best_model&#39;, mode=&#39;max&#39;, ) tb_logger = pl_loggers.TensorBoardLogger(&#39;logs/&#39;) # create logger for tensorboard # hyper-parameters lr = 1e-3 hidden_size = 500 num_epochs = 60 l2reg = 0.5 trainer = pl.Trainer(gpus=1, max_epochs=num_epochs, logger=tb_logger, callbacks=[checkpoint_callback]) model = TDLSTM(embeddings, hidden_size, lr=lr, l2reg=l2reg) trainer.fit(model, dataloaders, test_dataloaders) . GPU available: True, used: True TPU available: False, using: 0 TPU cores LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] | Name | Type | Params - 0 | embedding | Embedding | 119 M 1 | l_lstm | LSTM | 1.2 M 2 | r_lstm | LSTM | 1.2 M 3 | linear | Linear | 3.0 K 4 | train_acc | Accuracy | 0 5 | val_acc | Accuracy | 0 6 | val_f1 | F1 | 0 7 | test_acc | Accuracy | 0 8 | test_f1 | F1 | 0 - 2.4 M Trainable params 119 M Non-trainable params 121 M Total params 487.050 Total estimated model params size (MB) . . new_model = TDLSTM.load_from_checkpoint(checkpoint_callback.best_model_path, embeddings=embeddings, hidden_size=500) trainer.test(new_model, test_dataloaders) . LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0] . -- DATALOADER:0 TEST RESULTS {&#39;test_acc&#39;: 0.7037572264671326, &#39;test_f1&#39;: 0.6847572326660156} -- . [{&#39;test_acc&#39;: 0.7037572264671326, &#39;test_f1&#39;: 0.6847572326660156}] . from IPython.display import Image Image(filename=&#39;images/results.png&#39;) . Compare to the result from the paper, our implementation gets very close results. You can try to tune the model to get better result. .",
            "url": "https://minhdang241.github.io/minhdg-blog/implementation/2021/06/18/NLP_1_Effective_LSTMs_for_Target_Dependent_Sentiment_Classification-Part-1.html",
            "relUrl": "/implementation/2021/06/18/NLP_1_Effective_LSTMs_for_Target_Dependent_Sentiment_Classification-Part-1.html",
            "date": " • Jun 18, 2021"
        }
        
    
  
    
        ,"post15": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://minhdang241.github.io/minhdg-blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post16": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://minhdang241.github.io/minhdg-blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hi, I’m Minh. Welcome to my BLOG365 project. This is where I document all the things I have learned and researched about Engineering and ML in general. . Linkedin: https://www.linkedin.com/in/minh-dang-60406b17b/ GitHub: https://github.com/minhdang241 .",
          "url": "https://minhdang241.github.io/minhdg-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  

  
  

  
      ,"page12": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://minhdang241.github.io/minhdg-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}